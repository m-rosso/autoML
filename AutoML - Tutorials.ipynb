{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdsMp-XXXFrD"
   },
   "source": [
    "## AutoML\n",
    "## Tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2psv99jLXFrW"
   },
   "source": [
    "This project aims to explore some of the main **AutoML tools** available, which involves the following tasks:\n",
    "1. Reading of technical articles concerning the automated machine learning field.\n",
    "2. Discussion about machine learning pipelines and the automation of some of their components.\n",
    "3. Identification of the most interesting Python libraries for automatic ML pipeline construction.\n",
    "4. Quick implementation of the selected tools with simulated data.\n",
    "5. Careful exploration of the APIs of the selected tools.\n",
    "6. Comparison among selected tools concerning: model performance, computation time, and usability.\n",
    "\n",
    "All of these activities derive from the **objectives** of this project, which are: i) reflection about ML pipeline components; ii) discussion and analysis of AutoML tools; iii) identification of key-points of AutoML frameworks; iv) definition of: the advantages and disadvantages of main AutoML tools, and, first of all, the relavance and adequacy of implementing AutoML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PiuxVZ83XFrn"
   },
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUui_-KCXFrr"
   },
   "source": [
    "This notebook brings codes for implementing the following selected AutoML tools: Auto-sklearn, TPOT, Hyperopt-sklearn, MLJAR, PyCaret and AutoKeras. In order to make use of these Python libraries, the demonstration relies on simulated data of a binary classification task with two unbalanced classes, 1000 observations and 50 features. After reading about those libraries, here the APIs are explored, so characteristics of the tools and their usages can be presented and compared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYwz8EaYXFr4"
   },
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6klSsLAXFsI"
   },
   "source": [
    "**Summary:**\n",
    "1. [Libraries](#libraries)<a href='#libraries'></a>.\n",
    "2. [Functions and classes](#functions_classes)<a href='#functions_classes'></a>.\n",
    "3. [Settings](#settings)<a href='#settings'></a>.\n",
    "4. [Demonstration](#demonstration)<a href='#demonstration'></a>.\n",
    "    * [Data generating process](#data_gen_proc)<a href='#data_gen_proc'></a>.\n",
    "    * [Auto-sklearn](#auto_sklearn)<a href='#auto_sklearn'></a>.\n",
    "    * [TPOT](#tpot)<a href='#tpot'></a>.\n",
    "    * [Hyperopt-sklearn](#hyperopt_sklearn)<a href='#hyperopt_sklearn'></a>.\n",
    "    * [MLJAR](#mljar)<a href='#mljar'></a>.\n",
    "    * [PyCaret](#pycaret)<a href='#pycaret'></a>.\n",
    "    * [AutoKeras](#autokeras)<a href='#autokeras'></a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ju5Y_GP_XFsN"
   },
   "source": [
    "<a id='libraries'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43qC5e8mXFsW"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 471,
     "status": "ok",
     "timestamp": 1629055514315,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "s3Q5Vz_fXRJ0",
    "outputId": "bbfe116e-9204-495a-eda9-c9071987afc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1629055514670,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "KrGoigUMXQ3I",
    "outputId": "d287bc0e-41b2-4c18-f9fc-8bcd53fcbbe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/MyDrive/Studies/autoML/Codes\n"
     ]
    }
   ],
   "source": [
    "cd \"/content/gdrive/MyDrive/Studies/autoML/Codes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8GiMHPxuEFc"
   },
   "outputs": [],
   "source": [
    "# !curl https://raw.githubusercontent.com/automl/auto-sklearn/master/requirements.txt | xargs -n 1 -L 1 pip3 install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OljxpPihudlf"
   },
   "outputs": [],
   "source": [
    "# pip install auto-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ziB8YOY61SON"
   },
   "outputs": [],
   "source": [
    "# pip install tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tm7XbNAWz5Ss"
   },
   "outputs": [],
   "source": [
    "# pip install git+https://github.com/hyperopt/hyperopt-sklearn.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ImQQQNLFxgxT"
   },
   "outputs": [],
   "source": [
    "# pip install mljar-supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zpLGAb0D7pCa"
   },
   "outputs": [],
   "source": [
    "# pip install pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XIth4gx0mfpX"
   },
   "outputs": [],
   "source": [
    "# pip install autokeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9ZeaaWK1_a0"
   },
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eQm0NIaifmx6"
   },
   "outputs": [],
   "source": [
    "# pip uninstall scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rh_UPT118HAr"
   },
   "outputs": [],
   "source": [
    "# pip install scikit-learn==0.24.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IjOJB1U3XFsa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# sudo apt-get install build-essential swig\n",
    "# curl https://raw.githubusercontent.com/automl/auto-sklearn/master/requirements.txt | xargs -n 1 -L 1 pip3 install\n",
    "# pip install auto-sklearn\n",
    "import autosklearn # Auto-sklearn\n",
    "\n",
    "# pip install tpot\n",
    "import tpot # TPOT\n",
    "\n",
    "# pip install git+https://github.com/hyperopt/hyperopt-sklearn.git\n",
    "import hyperopt # Hyperopt-sklearn\n",
    "\n",
    "# pip install mljar-supervised\n",
    "from supervised import AutoML # MLJAR\n",
    "\n",
    "# pip install pycaret\n",
    "import pycaret # PyCaret\n",
    "\n",
    "# pip install autokeras\n",
    "import autokeras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EY5vR9VjXFsj"
   },
   "source": [
    "<a id='functions_classes'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xLBuTleXFss"
   },
   "source": [
    "## Functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 1016,
     "status": "ok",
     "timestamp": 1629055519044,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "LyVQzshRXFst",
    "outputId": "a4c06c9a-9e6b-4462-aa5d-58cf581cd599"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import running_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMJ7WDAbXFsw"
   },
   "source": [
    "<a id='settings'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvPthP8NXFsy"
   },
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWAU3vliXFsz"
   },
   "source": [
    "### Data management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gGl-bwyHXFs5"
   },
   "outputs": [],
   "source": [
    "# Declare whether to export results:\n",
    "export = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQcsjYwFXFs7"
   },
   "source": [
    "<a id='demonstration'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdeP3W1oXFs9"
   },
   "source": [
    "## Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjPfXLnTXFs-"
   },
   "source": [
    "<a id='data_gen_proc'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yvPjfZKXFs_"
   },
   "source": [
    "### Data generating process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MJlxC1laXFtA"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sXeFCN5PXFtB"
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_classes=2, weights=[0.8, 0.2], n_samples=1000, n_features=50, n_informative=22, n_redundant=2,\n",
    "                           random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xocbq3BhXFtC"
   },
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ZgeK1G6XFtD"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLR_NvocXFtE"
   },
   "source": [
    "<a id='auto_sklearn'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRQ33UBpXFtI"
   },
   "source": [
    "### Auto-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QpZflPvXFtJ"
   },
   "outputs": [],
   "source": [
    "from autosklearn.classification import AutoSklearnClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuNia7REXFtK"
   },
   "source": [
    "#### AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 119485,
     "status": "ok",
     "timestamp": 1628730748436,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "g58h6Dv8XFtL",
    "outputId": "43637fd0-224f-4d56-82c5-bd6913144a27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mRunning time:\u001b[0m 1.99 minutes.\n",
      "Start time: 2021-08-12, 01:10:25\n",
      "End time: 2021-08-12, 01:12:24\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "# Creating the AutoML object:\n",
    "model1 = AutoSklearnClassifier(ensemble_size=50, metric=autosklearn.metrics.roc_auc, # Estimation parameters\n",
    "                               time_left_for_this_task=2*60, per_run_time_limit=30, # Search complexity parameters\n",
    "                               n_jobs=1 # Computation parameters\n",
    "                              )\n",
    "\n",
    "# Running the search:\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# Total elapsed time:\n",
    "end_time = datetime.now()\n",
    "autosklearn_time = running_time(start_time=start_time, end_time=end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9v5kvr7zXFtN"
   },
   "source": [
    "#### Assessing the outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B05DSfg7XFtN"
   },
   "source": [
    "Search process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 400,
     "status": "ok",
     "timestamp": 1628730760365,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "EoLUelbxXFtO",
    "outputId": "cabdf985-ac54-4397-8ea3-6c5ac9a296e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto-sklearn results:\n",
      "  Dataset name: 12ec8b82-fb0a-11eb-870a-0242ac1c0002\n",
      "  Metric: roc_auc\n",
      "  Best validation score: 0.927001\n",
      "  Number of target algorithm runs: 29\n",
      "  Number of successful target algorithm runs: 29\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 0\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model1.sprint_statistics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yW7XhQ8XFtO"
   },
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1628731012744,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "C27zIbr5XFtP",
    "outputId": "12863be7-b407-4c18-aeb2-79ccd1ef3be2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC-AUC: 0.9729.\n"
     ]
    }
   ],
   "source": [
    "# Predictions for hold-out data:\n",
    "y_hat = [p[1] for p in model1.predict_proba(X_test)]\n",
    "\n",
    "# Test ROC-AUC of the best model:\n",
    "test_roc_auc1 = roc_auc_score(y_test, y_hat)\n",
    "print(f'Test ROC-AUC: {test_roc_auc1:.4f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y36QaGi6XFtQ"
   },
   "source": [
    "<a id='tpot'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6UU1L2RXFtR"
   },
   "source": [
    "### TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z0CWpdkWXFtR"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4UIwx17XFtS"
   },
   "source": [
    "#### AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306,
     "referenced_widgets": [
      "0e84817599224e368ac57f58841fe231",
      "32736d014182465ab2c7f54e95ae5020",
      "62958e68fe6d4be88db9df858628e7a7",
      "53f0a06f36f24c62ba66a1075b02bde8",
      "3ba789c85c85469ebacb7c3939b71a0c",
      "e303117ca8c643b39d0335c42571e466",
      "180feac02c5d48399ae9fb2339fc6d05",
      "a836b54fe0d7439d8027cd9bdec7bc31"
     ]
    },
    "executionInfo": {
     "elapsed": 333611,
     "status": "ok",
     "timestamp": 1628725646323,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "Js5bfYafXFtT",
    "outputId": "38aee92e-d9dc-4d55-f979-d595253d6e37"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e84817599224e368ac57f58841fe231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=300.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.9582834821828533\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.9582834821828533\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.9582834821828533\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.9598686079818154\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.9598686079818154\n",
      "\n",
      "Best pipeline: KNeighborsClassifier(input_matrix, n_neighbors=18, p=2, weights=distance)\n",
      "------------------------------------\n",
      "\u001b[1mRunning time:\u001b[0m 33.77 minutes.\n",
      "Start time: 2021-08-11, 23:13:35\n",
      "End time: 2021-08-11, 23:47:21\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "# Definition of cross-validation technique:\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Creating the AutoML object:\n",
    "model2 = TPOTClassifier(cv=cv, scoring='roc_auc', # Estimation parameters\n",
    "                        generations=5, population_size=50, # Search complexity parameters\n",
    "                        verbosity=2, random_state=1, n_jobs=-1 # Computation parameters\n",
    "                       )\n",
    "\n",
    "# Running the search:\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# Exporting the ML pipeline chosen after the search:\n",
    "model2.export('tpot_best_model.py')\n",
    "\n",
    "# Total elapsed time:\n",
    "end_time = datetime.now()\n",
    "tpot_time = running_time(start_time=start_time, end_time=end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nvoG41bXFtU"
   },
   "source": [
    "#### Assessing the outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1K1_p6qXFtW"
   },
   "source": [
    "ML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1628730243788,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "nGP7WcmQXFtX",
    "outputId": "32ec9d29-d351-4532-8fdf-c45e877f8eaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBest ML pipeline:\u001b[0m\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "\n",
      "# NOTE: Make sure that the outcome column is labeled 'target' in the data file\n",
      "tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n",
      "features = tpot_data.drop('target', axis=1)\n",
      "training_features, testing_features, training_target, testing_target = \\\n",
      "            train_test_split(features, tpot_data['target'], random_state=1)\n",
      "\n",
      "# Average CV score on the training set was: 0.9598686079818154\n",
      "exported_pipeline = KNeighborsClassifier(n_neighbors=18, p=2, weights=\"distance\")\n",
      "# Fix random state in exported estimator\n",
      "if hasattr(exported_pipeline, 'random_state'):\n",
      "    setattr(exported_pipeline, 'random_state', 1)\n",
      "\n",
      "exported_pipeline.fit(training_features, training_target)\n",
      "results = exported_pipeline.predict(testing_features)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('tpot_best_model.py', 'r') as file:\n",
    "  lines = file.readlines()\n",
    "\n",
    "print('\\033[1mBest ML pipeline:\\033[0m')\n",
    "print(''.join(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qckoK8SoXFtc"
   },
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1628729389515,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "v1Cz3JWUXFtc",
    "outputId": "3cec6235-ba26-4ce1-9008-60f05bc6b859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC-AUC: 0.9763.\n"
     ]
    }
   ],
   "source": [
    "# Predictions for hold-out data:\n",
    "y_hat = [p[1] for p in model2.predict_proba(X_test)]\n",
    "\n",
    "# Test ROC-AUC of the best model:\n",
    "test_roc_auc2 = roc_auc_score(y_test, y_hat)\n",
    "print(f'Test ROC-AUC: {test_roc_auc2:.4f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1628729577534,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "zufCmmdM1mW7",
    "outputId": "2b1df799-bc82-4b64-d590-f3b08ffc01b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.9763\n"
     ]
    }
   ],
   "source": [
    "# More direct presentation of metric evaluated on test set:\n",
    "print(f'{model2.scoring} = {model2.score(X_test, y_test):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgK0XWV3z5TC"
   },
   "source": [
    "<a id='hyperopt_sklearn'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zWst3fi88-b"
   },
   "source": [
    "### Hyperopt-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1909,
     "status": "ok",
     "timestamp": 1628810188673,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "-ggxt40J8_Rv",
    "outputId": "74174036-c5a5-43c4-c340-54696d02a413"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    }
   ],
   "source": [
    "from hpsklearn import HyperoptEstimator\n",
    "from hpsklearn import any_classifier\n",
    "from hpsklearn import any_preprocessing\n",
    "from hyperopt import tpe\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FT7_d-gVyg0a"
   },
   "outputs": [],
   "source": [
    "def roc_auc_loss(y_true, y_pred):\n",
    "  return 1 - roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIF0uNU6Dqs6"
   },
   "source": [
    "#### AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 159655,
     "status": "ok",
     "timestamp": 1628812012406,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "lJ0pa_EH-G9a",
    "outputId": "71137db4-4a58-4199-84b1-59b7b0ba346b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.58it/s, best loss: -0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/it, best loss: -0.5]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.13it/s, best loss: -0.5]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.01it/s, best loss: -0.5]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:12] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.04s/it, best loss: -0.5]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:13] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.26s/it, best loss: -0.8132313231323132]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:19] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.78it/s, best loss: -0.8132313231323132]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.85s/it, best loss: -0.8132313231323132]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.87s/it, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.65it/s, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.12it/s, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.96it/s, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.84it/s, best loss: -0.8132313231323132]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:31] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.51s/it, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.63it/s, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.04it/s, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.40s/it, best loss: -0.8132313231323132]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.43s/it, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.73s/it, best loss: -0.8132313231323132]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:47] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.93s/it, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.15it/s, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.51it/s, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.36it/s, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.23it/s, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.83it/s, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.92s/it, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.52it/s, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.07it/s, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:30<00:00, 30.19s/it, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.00s/it, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.10it/s, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/it, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.00it/s, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:30<00:00, 30.21s/it, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.50it/s, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.52it/s, best loss: -0.8132313231323132]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:09] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.50s/it, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.69it/s, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.24it/s, best loss: -0.8132313231323132]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.37s/it, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.93it/s, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.61it/s, best loss: -0.8132313231323132]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 1/1 [00:12<00:00, 12.31s/it, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.26it/s, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.81it/s, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.84it/s, best loss: -0.8132313231323132]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:34] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/it, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.26it/s, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.21s/it, best loss: -0.8132313231323132]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.05it/s, best loss: -0.8132313231323132]\n",
      "[23:46:42] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mRunning time:\u001b[0m 2.66 minutes.\n",
      "Start time: 2021-08-12, 23:44:09\n",
      "End time: 2021-08-12, 23:46:48\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "# Creating the AutoML object:\n",
    "model3 = HyperoptEstimator(\n",
    "    classifier=any_classifier('cla'), preprocessing=any_preprocessing('pre'), algo=tpe.suggest, loss_fn=roc_auc_loss, # Estimation parameters\n",
    "    max_evals=50, trial_timeout=30 # Search complexity parameters\n",
    "    )\n",
    "\n",
    "# Running the search:\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "# Total elapsed time:\n",
    "end_time = datetime.now()\n",
    "hyperopt_time = running_time(start_time=start_time, end_time=end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxsZt24Qqzop"
   },
   "source": [
    "#### Assessing the outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glxgP9cEwcuZ"
   },
   "source": [
    "ML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 385,
     "status": "ok",
     "timestamp": 1628812013508,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "iKJ38gsuweAk",
    "outputId": "7e2a83f4-2121-483b-8089-73b380ed0259"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learner': XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              colsample_bylevel=0.7168097803940385, colsample_bynode=1,\n",
      "              colsample_bytree=0.9346910816306739, gamma=0.009795108535675551,\n",
      "              gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.011467807605934782, max_delta_step=0,\n",
      "              max_depth=10, min_child_weight=2, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=5800, n_jobs=1,\n",
      "              num_parallel_tree=1, random_state=4,\n",
      "              reg_alpha=0.43859784870214646, reg_lambda=1.3265094478508068,\n",
      "              scale_pos_weight=1, seed=4, subsample=0.8408933990792793,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None), 'preprocs': (PCA(n_components=24),), 'ex_preprocs': ()}\n"
     ]
    }
   ],
   "source": [
    "print(model3.best_model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tP7t-UBvrBTt"
   },
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1628812177315,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "ecZ4RU8irP8C",
    "outputId": "ad5cdd32-3afd-4f3d-9144-276fa2dd3bb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC-AUC: 0.8697.\n"
     ]
    }
   ],
   "source": [
    "# Predictions for hold-out data:\n",
    "y_hat = model3.predict(X_test)\n",
    "\n",
    "# Test ROC-AUC of the best model:\n",
    "test_roc_auc3 = roc_auc_score(y_test, y_hat)\n",
    "print(f'Test ROC-AUC: {test_roc_auc3:.4f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1628812172320,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "nzPZ9nRt-HBG",
    "outputId": "3a2f87a7-172d-4e28-fc1c-5db4714a7ad2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9394.\n"
     ]
    }
   ],
   "source": [
    "# Inherited metric (accuracy) evaluated on test set:\n",
    "print(f'Accuracy: {model3.score(X_test, y_test):.4f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsJg2xbyz5TH"
   },
   "source": [
    "<a id='mljar'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnFdoyYnyTq2"
   },
   "source": [
    "### MLJAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t2nrMZ8-yjxX"
   },
   "outputs": [],
   "source": [
    "from supervised import AutoML\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIJB6dsTyTdD"
   },
   "source": [
    "#### AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJ1Xl2QJOfRk"
   },
   "source": [
    "Perform mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 128561,
     "status": "ok",
     "timestamp": 1628876567118,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "gNTE4wGzOcV9",
    "outputId": "adaf275c-bdb3-41d6-e04c-0530076e8723"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: AutoML_7\n",
      "The task is binary_classification with evaluation metric auc\n",
      "AutoML will use algorithms: ['Linear', 'Random Forest', 'LightGBM', 'Xgboost', 'CatBoost', 'Neural Network']\n",
      "AutoML will ensemble availabe models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'golden_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "* Step simple_algorithms will try to check up to 1 model\n",
      "1_Linear auc 0.860369 trained in 26.22 seconds (1-sample predict time 0.1307 seconds)\n",
      "* Step default_algorithms will try to check up to 5 models\n",
      "2_Default_LightGBM auc 0.897411 trained in 19.96 seconds (1-sample predict time 0.0954 seconds)\n",
      "* Step not_so_random will try to check up to 20 models\n",
      "7_LightGBM auc 0.907694 trained in 11.81 seconds (1-sample predict time 0.0948 seconds)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3_Xgboost auc 0.904266 trained in 29.76 seconds (1-sample predict time 0.1044 seconds)\n",
      "Skip golden_features because no parameters were generated.\n",
      "Skip insert_random_feature because no parameters were generated.\n",
      "Skip features_selection because no parameters were generated.\n",
      "* Step hill_climbing_1 will try to check up to 5 models\n",
      "8_LightGBM auc 0.907694 trained in 20.63 seconds (1-sample predict time 0.1009 seconds)\n",
      "Skip hill_climbing_2 because of the time limit.\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble auc 0.910946 trained in 0.87 seconds (1-sample predict time 0.1815 seconds)\n",
      "AutoML fit time: 128.13 seconds\n",
      "AutoML best model: Ensemble\n",
      "------------------------------------\n",
      "\u001b[1mRunning time:\u001b[0m 2.14 minutes.\n",
      "Start time: 2021-08-13, 17:40:33\n",
      "End time: 2021-08-13, 17:42:42\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "# Creating the AutoML object:\n",
    "model4a = AutoML(mode=\"Perform\", total_time_limit=2*60, # Search complexity parameters\n",
    "                 eval_metric='auc' # Estimation metrics\n",
    "                 )\n",
    "\n",
    "# Running the search:\n",
    "model4a.fit(X_train, y_train)\n",
    "\n",
    "# Total elapsed time:\n",
    "end_time = datetime.now()\n",
    "mljar_time = running_time(start_time=start_time, end_time=end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "se3PB0eTPfv7"
   },
   "source": [
    "Compete mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 130226,
     "status": "ok",
     "timestamp": 1628877066842,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "q9cUvd9ZPgnM",
    "outputId": "5761269e-8090-4ba7-f2d5-ba0762b71984"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: AutoML_8\n",
      "The task is binary_classification with evaluation metric auc\n",
      "AutoML will use algorithms: ['Decision Tree', 'Linear', 'Random Forest', 'Extra Trees', 'LightGBM', 'Xgboost', 'CatBoost', 'Neural Network', 'Nearest Neighbors']\n",
      "AutoML will stack models\n",
      "AutoML will ensemble availabe models\n",
      "AutoML steps: ['adjust_validation', 'simple_algorithms', 'default_algorithms', 'not_so_random', 'golden_features', 'kmeans_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'boost_on_errors', 'ensemble', 'stack', 'ensemble_stacked']\n",
      "* Step adjust_validation will try to check up to 1 model\n",
      "1_DecisionTree auc 0.889488 trained in 2.69 seconds\n",
      "Disable stacking for split validation\n",
      "* Step simple_algorithms will try to check up to 3 models\n",
      "2_DecisionTree auc 0.781671 trained in 1.18 seconds\n",
      "3_DecisionTree auc 0.773585 trained in 1.18 seconds\n",
      "4_Linear auc 0.942049 trained in 2.29 seconds\n",
      "* Step default_algorithms will try to check up to 7 models\n",
      "5_Default_LightGBM auc 0.974394 trained in 2.03 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6_Default_Xgboost auc 0.97035 trained in 2.15 seconds\n",
      "7_Default_CatBoost auc 0.924528 trained in 2.93 seconds\n",
      "8_Default_NeuralNetwork auc 0.885445 trained in 1.69 seconds\n",
      "9_Default_RandomForest auc 0.881402 trained in 3.79 seconds\n",
      "* Step not_so_random will try to check up to 63 models\n",
      "19_LightGBM auc 0.939353 trained in 1.47 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10_Xgboost auc 0.942049 trained in 1.81 seconds\n",
      "28_CatBoost auc 0.97035 trained in 3.95 seconds\n",
      "37_RandomForest auc 0.909704 trained in 2.63 seconds\n",
      "46_ExtraTrees auc 0.902965 trained in 2.21 seconds\n",
      "55_NeuralNetwork auc 0.904313 trained in 1.76 seconds\n",
      "64_NearestNeighbors auc 0.960916 trained in 1.66 seconds\n",
      "20_LightGBM auc 0.974394 trained in 1.77 seconds\n",
      "* Step golden_features will try to check up to 3 models\n",
      "None 10\n",
      "Add Golden Feature: feature_3_diff_feature_14\n",
      "Add Golden Feature: feature_30_ratio_feature_44\n",
      "Add Golden Feature: feature_36_diff_feature_39\n",
      "Add Golden Feature: feature_46_sum_feature_27\n",
      "Add Golden Feature: feature_39_multiply_feature_2\n",
      "Add Golden Feature: feature_32_ratio_feature_42\n",
      "Add Golden Feature: feature_10_ratio_feature_48\n",
      "Add Golden Feature: feature_19_ratio_feature_5\n",
      "Add Golden Feature: feature_30_ratio_feature_26\n",
      "Add Golden Feature: feature_34_ratio_feature_32\n",
      "Created 10 Golden Features in 8.57 seconds.\n",
      "20_LightGBM_GoldenFeatures auc 0.95283 trained in 10.67 seconds\n",
      "Skip kmeans_features because of the time limit.\n",
      "Not enough time to perform features selection. Skip\n",
      "Time needed for features selection ~ 28.0 seconds\n",
      "Please increase total_time_limit to at least (338 seconds) to have features selection\n",
      "Skip insert_random_feature because no parameters were generated.\n",
      "Skip features_selection because no parameters were generated.\n",
      "* Step hill_climbing_1 will try to check up to 24 models\n",
      "65_LightGBM auc 0.973046 trained in 2.14 seconds\n",
      "66_LightGBM auc 0.974394 trained in 2.24 seconds\n",
      "67_LightGBM auc 0.959569 trained in 1.79 seconds\n",
      "68_LightGBM auc 0.974394 trained in 1.89 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69_Xgboost auc 0.967655 trained in 3.01 seconds\n",
      "* Step hill_climbing_2 will try to check up to 23 models\n",
      "70_LightGBM auc 0.987871 trained in 2.51 seconds\n",
      "71_LightGBM auc 0.977089 trained in 2.43 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble auc 0.993261 trained in 2.81 seconds\n",
      "AutoML fit time: 128.76 seconds\n",
      "AutoML best model: Ensemble\n",
      "------------------------------------\n",
      "\u001b[1mRunning time:\u001b[0m 2.15 minutes.\n",
      "Start time: 2021-08-13, 17:48:51\n",
      "End time: 2021-08-13, 17:51:00\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "# Creating the AutoML object:\n",
    "model4b = AutoML(mode=\"Compete\", total_time_limit=2*60, # Search complexity parameters\n",
    "                 eval_metric='auc' # Estimation metrics\n",
    "                 )\n",
    "\n",
    "# Running the search:\n",
    "model4b.fit(X_train, y_train)\n",
    "\n",
    "# Total elapsed time:\n",
    "end_time = datetime.now()\n",
    "mljar_time = running_time(start_time=start_time, end_time=end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-VQBq93PsUX"
   },
   "source": [
    "Optuna mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 468396,
     "status": "ok",
     "timestamp": 1628877551002,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "5hz9NajCPvGZ",
    "outputId": "158d8c03-7a32-44ee-85f3-c573565e6828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: AutoML_9\n",
      "Expected computing time:\n",
      "Time for tuning with Optuna: len(algorithms) * optuna_time_budget = 360 seconds\n",
      "There is no time limit for ML model training after Optuna tuning (total_time_limit parameter is ignored).\n",
      "The task is binary_classification with evaluation metric auc\n",
      "AutoML will use algorithms: ['CatBoost', 'LightGBM', 'Xgboost']\n",
      "AutoML will stack models\n",
      "AutoML will ensemble availabe models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'ensemble', 'stack', 'ensemble_stacked']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-13 17:51:17,944]\u001b[0m A new study created in memory with name: no-name-1958b651-cffa-44a6-9a3f-391114f263ac\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna optimizes LightGBM with time budget 120 seconds eval_metric auc (maximize)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-13 17:51:18,185]\u001b[0m Trial 0 finished with value: 0.9110512129380055 and parameters: {'learning_rate': 0.1, 'num_leaves': 1598, 'lambda_l1': 2.840098794801191e-06, 'lambda_l2': 3.0773599420974e-06, 'feature_fraction': 0.8613105322932351, 'bagging_fraction': 0.970697557159987, 'bagging_freq': 7, 'min_data_in_leaf': 36, 'extra_trees': False}. Best is trial 0 with value: 0.9110512129380055.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:18,269]\u001b[0m Trial 1 finished with value: 0.8746630727762803 and parameters: {'learning_rate': 0.0125, 'num_leaves': 30, 'lambda_l1': 0.09024841733204539, 'lambda_l2': 0.8785585624049705, 'feature_fraction': 0.5554201923798203, 'bagging_fraction': 0.7307773310574073, 'bagging_freq': 1, 'min_data_in_leaf': 37, 'extra_trees': True}. Best is trial 0 with value: 0.9110512129380055.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:18,574]\u001b[0m Trial 2 finished with value: 0.9002695417789758 and parameters: {'learning_rate': 0.025, 'num_leaves': 1781, 'lambda_l1': 8.42482357544477e-05, 'lambda_l2': 0.1657023923779856, 'feature_fraction': 0.4006367785978634, 'bagging_fraction': 0.7929826868254444, 'bagging_freq': 5, 'min_data_in_leaf': 22, 'extra_trees': True}. Best is trial 0 with value: 0.9110512129380055.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:18,708]\u001b[0m Trial 3 finished with value: 0.8814016172506738 and parameters: {'learning_rate': 0.0125, 'num_leaves': 1383, 'lambda_l1': 0.0022471032062799873, 'lambda_l2': 0.0006306544535695586, 'feature_fraction': 0.3303268443196031, 'bagging_fraction': 0.6930031616587092, 'bagging_freq': 3, 'min_data_in_leaf': 51, 'extra_trees': False}. Best is trial 0 with value: 0.9110512129380055.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:18,943]\u001b[0m Trial 4 finished with value: 0.7964959568733153 and parameters: {'learning_rate': 0.1, 'num_leaves': 1620, 'lambda_l1': 8.48658950043472, 'lambda_l2': 4.2581000284199, 'feature_fraction': 0.854374902623789, 'bagging_fraction': 0.4996756748696664, 'bagging_freq': 5, 'min_data_in_leaf': 48, 'extra_trees': False}. Best is trial 0 with value: 0.9110512129380055.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:19,035]\u001b[0m Trial 5 finished with value: 0.8180592991913747 and parameters: {'learning_rate': 0.05, 'num_leaves': 246, 'lambda_l1': 0.04433099767762488, 'lambda_l2': 0.0019307795983178134, 'feature_fraction': 0.6301427787405827, 'bagging_fraction': 0.37498877310697454, 'bagging_freq': 2, 'min_data_in_leaf': 90, 'extra_trees': False}. Best is trial 0 with value: 0.9110512129380055.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:19,270]\u001b[0m Trial 6 finished with value: 0.9043126684636119 and parameters: {'learning_rate': 0.1, 'num_leaves': 1881, 'lambda_l1': 0.004281836004345365, 'lambda_l2': 0.022593217631936842, 'feature_fraction': 0.4048836026912862, 'bagging_fraction': 0.8222443938563357, 'bagging_freq': 6, 'min_data_in_leaf': 64, 'extra_trees': True}. Best is trial 0 with value: 0.9110512129380055.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:19,532]\u001b[0m Trial 7 finished with value: 0.8867924528301887 and parameters: {'learning_rate': 0.05, 'num_leaves': 1030, 'lambda_l1': 0.000679053100205625, 'lambda_l2': 0.23594925128557553, 'feature_fraction': 0.33998094723335825, 'bagging_fraction': 0.7685952268464016, 'bagging_freq': 6, 'min_data_in_leaf': 71, 'extra_trees': True}. Best is trial 0 with value: 0.9110512129380055.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:19,618]\u001b[0m Trial 8 finished with value: 0.7897574123989218 and parameters: {'learning_rate': 0.0125, 'num_leaves': 235, 'lambda_l1': 3.608183787280691, 'lambda_l2': 8.538207987163786e-06, 'feature_fraction': 0.4355330850438309, 'bagging_fraction': 0.6204681588063157, 'bagging_freq': 7, 'min_data_in_leaf': 88, 'extra_trees': False}. Best is trial 0 with value: 0.9110512129380055.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:19,794]\u001b[0m Trial 9 finished with value: 0.784366576819407 and parameters: {'learning_rate': 0.025, 'num_leaves': 1844, 'lambda_l1': 0.1029139404015751, 'lambda_l2': 0.002468272050112134, 'feature_fraction': 0.5037876743397648, 'bagging_fraction': 0.4059766865991551, 'bagging_freq': 3, 'min_data_in_leaf': 66, 'extra_trees': True}. Best is trial 0 with value: 0.9110512129380055.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:21,407]\u001b[0m Trial 10 finished with value: 0.8908355795148248 and parameters: {'learning_rate': 0.1, 'num_leaves': 803, 'lambda_l1': 1.6916428822871494e-07, 'lambda_l2': 2.00132355372712e-08, 'feature_fraction': 0.991754841975438, 'bagging_fraction': 0.9635281141781353, 'bagging_freq': 7, 'min_data_in_leaf': 3, 'extra_trees': False}. Best is trial 0 with value: 0.9110512129380055.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:21,745]\u001b[0m Trial 11 finished with value: 0.9245283018867925 and parameters: {'learning_rate': 0.1, 'num_leaves': 1976, 'lambda_l1': 2.070751800311632e-06, 'lambda_l2': 3.651620612329416e-06, 'feature_fraction': 0.7759311463847254, 'bagging_fraction': 0.9780890963940101, 'bagging_freq': 6, 'min_data_in_leaf': 28, 'extra_trees': True}. Best is trial 11 with value: 0.9245283018867925.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:22,053]\u001b[0m Trial 12 finished with value: 0.9137466307277629 and parameters: {'learning_rate': 0.1, 'num_leaves': 1380, 'lambda_l1': 1.4638582459791967e-06, 'lambda_l2': 4.350753008505017e-06, 'feature_fraction': 0.7927584802154166, 'bagging_fraction': 0.9458533841257327, 'bagging_freq': 7, 'min_data_in_leaf': 21, 'extra_trees': True}. Best is trial 11 with value: 0.9245283018867925.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:22,577]\u001b[0m Trial 13 finished with value: 0.9474393530997305 and parameters: {'learning_rate': 0.1, 'num_leaves': 1220, 'lambda_l1': 1.514880626716043e-08, 'lambda_l2': 4.97504263564148e-06, 'feature_fraction': 0.7565227349625415, 'bagging_fraction': 0.8928001340586676, 'bagging_freq': 5, 'min_data_in_leaf': 12, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:23,868]\u001b[0m Trial 14 finished with value: 0.9285714285714286 and parameters: {'learning_rate': 0.1, 'num_leaves': 942, 'lambda_l1': 1.794041663342115e-08, 'lambda_l2': 7.51215964577831e-08, 'feature_fraction': 0.7133672978229351, 'bagging_fraction': 0.8796371422147634, 'bagging_freq': 5, 'min_data_in_leaf': 1, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:24,879]\u001b[0m Trial 15 finished with value: 0.9097035040431267 and parameters: {'learning_rate': 0.1, 'num_leaves': 847, 'lambda_l1': 1.328708910216853e-08, 'lambda_l2': 1.5830524931205286e-08, 'feature_fraction': 0.6695961505730843, 'bagging_fraction': 0.8635003684298755, 'bagging_freq': 4, 'min_data_in_leaf': 3, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:25,217]\u001b[0m Trial 16 finished with value: 0.9218328840970351 and parameters: {'learning_rate': 0.1, 'num_leaves': 1105, 'lambda_l1': 3.95443934132703e-08, 'lambda_l2': 2.9921394805268176e-07, 'feature_fraction': 0.6870435959141753, 'bagging_fraction': 0.6295178333232277, 'bagging_freq': 4, 'min_data_in_leaf': 11, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:26,303]\u001b[0m Trial 17 finished with value: 0.921832884097035 and parameters: {'learning_rate': 0.025, 'num_leaves': 551, 'lambda_l1': 2.342424030194495e-05, 'lambda_l2': 8.581104562837588e-05, 'feature_fraction': 0.9783254242689094, 'bagging_fraction': 0.8630980945877005, 'bagging_freq': 5, 'min_data_in_leaf': 12, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:26,631]\u001b[0m Trial 18 finished with value: 0.8935309973045822 and parameters: {'learning_rate': 0.05, 'num_leaves': 1235, 'lambda_l1': 1.8633819039734936e-07, 'lambda_l2': 1.7293482226442912e-07, 'feature_fraction': 0.7494099310470362, 'bagging_fraction': 0.5236587080089052, 'bagging_freq': 3, 'min_data_in_leaf': 14, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:26,933]\u001b[0m Trial 19 finished with value: 0.9258760107816711 and parameters: {'learning_rate': 0.1, 'num_leaves': 676, 'lambda_l1': 1.0001795678868887e-08, 'lambda_l2': 6.440680785917347e-05, 'feature_fraction': 0.8945600507982803, 'bagging_fraction': 0.8831068652918176, 'bagging_freq': 5, 'min_data_in_leaf': 33, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:27,909]\u001b[0m Trial 20 finished with value: 0.8908355795148248 and parameters: {'learning_rate': 0.1, 'num_leaves': 443, 'lambda_l1': 2.397349364891325e-07, 'lambda_l2': 1.5801665637145648e-07, 'feature_fraction': 0.5977294125336515, 'bagging_fraction': 0.9031484050711691, 'bagging_freq': 4, 'min_data_in_leaf': 1, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:28,105]\u001b[0m Trial 21 finished with value: 0.9245283018867925 and parameters: {'learning_rate': 0.1, 'num_leaves': 812, 'lambda_l1': 1.2439335159430769e-08, 'lambda_l2': 4.9253869871380355e-05, 'feature_fraction': 0.8915477548480093, 'bagging_fraction': 0.8982953170363727, 'bagging_freq': 5, 'min_data_in_leaf': 30, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:28,409]\u001b[0m Trial 22 finished with value: 0.8921832884097035 and parameters: {'learning_rate': 0.1, 'num_leaves': 682, 'lambda_l1': 7.397602397853634e-08, 'lambda_l2': 3.073302215731767e-05, 'feature_fraction': 0.7152396637010805, 'bagging_fraction': 0.8300392550550119, 'bagging_freq': 6, 'min_data_in_leaf': 19, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:28,672]\u001b[0m Trial 23 finished with value: 0.9326145552560647 and parameters: {'learning_rate': 0.1, 'num_leaves': 1156, 'lambda_l1': 6.228042273027429e-07, 'lambda_l2': 1.0060800434402567e-06, 'feature_fraction': 0.9200362181322281, 'bagging_fraction': 0.7017729276155881, 'bagging_freq': 5, 'min_data_in_leaf': 45, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:28,810]\u001b[0m Trial 24 finished with value: 0.8490566037735848 and parameters: {'learning_rate': 0.1, 'num_leaves': 1333, 'lambda_l1': 1.235680492640307e-05, 'lambda_l2': 5.533763737936004e-07, 'feature_fraction': 0.8256450087411193, 'bagging_fraction': 0.5718065015747161, 'bagging_freq': 4, 'min_data_in_leaf': 44, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:29,085]\u001b[0m Trial 25 finished with value: 0.9070080862533693 and parameters: {'learning_rate': 0.1, 'num_leaves': 1149, 'lambda_l1': 5.007333692995344e-07, 'lambda_l2': 8.269951015509691e-07, 'feature_fraction': 0.9250499028744497, 'bagging_fraction': 0.7205553931292314, 'bagging_freq': 5, 'min_data_in_leaf': 54, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:29,199]\u001b[0m Trial 26 finished with value: 0.8234501347708895 and parameters: {'learning_rate': 0.0125, 'num_leaves': 934, 'lambda_l1': 6.659170275137562e-06, 'lambda_l2': 6.543864099821569e-08, 'feature_fraction': 0.7467659199586183, 'bagging_fraction': 0.6620288275075468, 'bagging_freq': 6, 'min_data_in_leaf': 73, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:30,236]\u001b[0m Trial 27 finished with value: 0.9258760107816711 and parameters: {'learning_rate': 0.025, 'num_leaves': 1491, 'lambda_l1': 5.290084484812538e-08, 'lambda_l2': 1.2686077346717294e-06, 'feature_fraction': 0.8114142017610679, 'bagging_fraction': 0.7653187865923712, 'bagging_freq': 3, 'min_data_in_leaf': 9, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:30,339]\u001b[0m Trial 28 finished with value: 0.664420485175202 and parameters: {'learning_rate': 0.05, 'num_leaves': 1235, 'lambda_l1': 6.29033038651446e-05, 'lambda_l2': 1.690025715985349e-05, 'feature_fraction': 0.9453652211693706, 'bagging_fraction': 0.3086464095709928, 'bagging_freq': 4, 'min_data_in_leaf': 83, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:30,763]\u001b[0m Trial 29 finished with value: 0.9231805929919138 and parameters: {'learning_rate': 0.1, 'num_leaves': 1655, 'lambda_l1': 1.0801274745201006e-06, 'lambda_l2': 3.26564172159396e-08, 'feature_fraction': 0.6218637957902535, 'bagging_fraction': 0.9136876435883747, 'bagging_freq': 5, 'min_data_in_leaf': 38, 'extra_trees': False}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:31,064]\u001b[0m Trial 30 finished with value: 0.9123989218328841 and parameters: {'learning_rate': 0.1, 'num_leaves': 999, 'lambda_l1': 4.5425526448058115e-08, 'lambda_l2': 1.7178560357822955e-06, 'feature_fraction': 0.852698147839584, 'bagging_fraction': 0.9896425561158764, 'bagging_freq': 6, 'min_data_in_leaf': 57, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:31,731]\u001b[0m Trial 31 finished with value: 0.9164420485175202 and parameters: {'learning_rate': 0.025, 'num_leaves': 1494, 'lambda_l1': 6.359236247666078e-08, 'lambda_l2': 1.5317709172112303e-06, 'feature_fraction': 0.7935285909038392, 'bagging_fraction': 0.7731808240368885, 'bagging_freq': 2, 'min_data_in_leaf': 10, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:31,884]\u001b[0m Trial 32 finished with value: 0.8032345013477089 and parameters: {'learning_rate': 0.025, 'num_leaves': 1457, 'lambda_l1': 3.9586684601819395e-07, 'lambda_l2': 9.934571393638218e-08, 'feature_fraction': 0.7037411731655864, 'bagging_fraction': 0.7512538722810537, 'bagging_freq': 3, 'min_data_in_leaf': 99, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:33,107]\u001b[0m Trial 33 finished with value: 0.9164420485175202 and parameters: {'learning_rate': 0.025, 'num_leaves': 1179, 'lambda_l1': 3.06068335946868e-08, 'lambda_l2': 6.318779824810996e-07, 'feature_fraction': 0.828527583340559, 'bagging_fraction': 0.8143952831564424, 'bagging_freq': 2, 'min_data_in_leaf': 7, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:33,360]\u001b[0m Trial 34 finished with value: 0.9016172506738545 and parameters: {'learning_rate': 0.025, 'num_leaves': 1534, 'lambda_l1': 1.0458667444150881e-07, 'lambda_l2': 9.397918842228081e-06, 'feature_fraction': 0.575169397768444, 'bagging_fraction': 0.6962655481142267, 'bagging_freq': 1, 'min_data_in_leaf': 27, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:33,655]\u001b[0m Trial 35 finished with value: 0.8773584905660378 and parameters: {'learning_rate': 0.0125, 'num_leaves': 1701, 'lambda_l1': 7.980647915629979e-07, 'lambda_l2': 5.5871518927113795e-08, 'feature_fraction': 0.895159297112103, 'bagging_fraction': 0.725399249605098, 'bagging_freq': 5, 'min_data_in_leaf': 17, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:34,543]\u001b[0m Trial 36 finished with value: 0.9016172506738545 and parameters: {'learning_rate': 0.025, 'num_leaves': 1335, 'lambda_l1': 3.0649009594245823e-06, 'lambda_l2': 2.737898950143343e-06, 'feature_fraction': 0.7254829402880292, 'bagging_fraction': 0.8426618464895937, 'bagging_freq': 4, 'min_data_in_leaf': 6, 'extra_trees': False}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:34,838]\u001b[0m Trial 37 finished with value: 0.9150943396226416 and parameters: {'learning_rate': 0.1, 'num_leaves': 1023, 'lambda_l1': 2.562328640223529e-08, 'lambda_l2': 0.0008400476583191629, 'feature_fraction': 0.5095979247811218, 'bagging_fraction': 0.7987551442896474, 'bagging_freq': 3, 'min_data_in_leaf': 24, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:35,011]\u001b[0m Trial 38 finished with value: 0.8935309973045823 and parameters: {'learning_rate': 0.05, 'num_leaves': 1092, 'lambda_l1': 0.00015492558470733665, 'lambda_l2': 0.00017482171297953668, 'feature_fraction': 0.6615729552859372, 'bagging_fraction': 0.9348375261658556, 'bagging_freq': 4, 'min_data_in_leaf': 16, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:35,312]\u001b[0m Trial 39 finished with value: 0.9097035040431267 and parameters: {'learning_rate': 0.1, 'num_leaves': 624, 'lambda_l1': 1.0304791092109602e-08, 'lambda_l2': 0.006968065740747384, 'feature_fraction': 0.895696417340557, 'bagging_fraction': 0.8784688172497163, 'bagging_freq': 5, 'min_data_in_leaf': 39, 'extra_trees': False}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:35,463]\u001b[0m Trial 40 finished with value: 0.9002695417789758 and parameters: {'learning_rate': 0.1, 'num_leaves': 393, 'lambda_l1': 1.0572229377576921e-08, 'lambda_l2': 0.0005828336531926639, 'feature_fraction': 0.9633510106065477, 'bagging_fraction': 0.9959240911423652, 'bagging_freq': 5, 'min_data_in_leaf': 45, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:35,780]\u001b[0m Trial 41 finished with value: 0.9164420485175203 and parameters: {'learning_rate': 0.1, 'num_leaves': 916, 'lambda_l1': 8.227127043765862e-08, 'lambda_l2': 0.00011302528042110543, 'feature_fraction': 0.8244005817911618, 'bagging_fraction': 0.7788649416122265, 'bagging_freq': 5, 'min_data_in_leaf': 32, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:35,954]\u001b[0m Trial 42 finished with value: 0.862533692722372 and parameters: {'learning_rate': 0.0125, 'num_leaves': 719, 'lambda_l1': 3.047719121871837e-08, 'lambda_l2': 1.3477646691817868e-05, 'feature_fraction': 0.865190258500072, 'bagging_fraction': 0.667680345687168, 'bagging_freq': 6, 'min_data_in_leaf': 33, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:36,326]\u001b[0m Trial 43 finished with value: 0.9204851752021563 and parameters: {'learning_rate': 0.1, 'num_leaves': 927, 'lambda_l1': 2.654407287972193e-07, 'lambda_l2': 5.0532315407384745e-06, 'feature_fraction': 0.9224438990177665, 'bagging_fraction': 0.5965740966274882, 'bagging_freq': 4, 'min_data_in_leaf': 7, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:36,606]\u001b[0m Trial 44 finished with value: 0.9380053908355795 and parameters: {'learning_rate': 0.1, 'num_leaves': 1260, 'lambda_l1': 0.011214602597069596, 'lambda_l2': 3.7704862649703173e-07, 'feature_fraction': 0.7704652868464281, 'bagging_fraction': 0.9311367585236696, 'bagging_freq': 5, 'min_data_in_leaf': 24, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:37,205]\u001b[0m Trial 45 finished with value: 0.9150943396226415 and parameters: {'learning_rate': 0.025, 'num_leaves': 1269, 'lambda_l1': 0.006477952904238899, 'lambda_l2': 2.893059832354338e-07, 'feature_fraction': 0.7757036815046122, 'bagging_fraction': 0.9344117962673567, 'bagging_freq': 6, 'min_data_in_leaf': 24, 'extra_trees': False}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:37,495]\u001b[0m Trial 46 finished with value: 0.917789757412399 and parameters: {'learning_rate': 0.1, 'num_leaves': 1599, 'lambda_l1': 0.27353866807671523, 'lambda_l2': 1.2383464496960798e-08, 'feature_fraction': 0.7522496663865159, 'bagging_fraction': 0.8462417285523925, 'bagging_freq': 2, 'min_data_in_leaf': 19, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:37,711]\u001b[0m Trial 47 finished with value: 0.8746630727762803 and parameters: {'learning_rate': 0.1, 'num_leaves': 1311, 'lambda_l1': 0.01926879655664492, 'lambda_l2': 9.384091468038914, 'feature_fraction': 0.645912580372735, 'bagging_fraction': 0.7544306401389399, 'bagging_freq': 5, 'min_data_in_leaf': 8, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:39,216]\u001b[0m Trial 48 finished with value: 0.9218328840970351 and parameters: {'learning_rate': 0.05, 'num_leaves': 1492, 'lambda_l1': 0.0006752216535713674, 'lambda_l2': 1.1040715478771464e-06, 'feature_fraction': 0.7992178941152178, 'bagging_fraction': 0.9599430148394358, 'bagging_freq': 3, 'min_data_in_leaf': 1, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:39,498]\u001b[0m Trial 49 finished with value: 0.8908355795148247 and parameters: {'learning_rate': 0.025, 'num_leaves': 1440, 'lambda_l1': 0.4862859101510163, 'lambda_l2': 4.332709506879028e-07, 'feature_fraction': 0.6887750804572604, 'bagging_fraction': 0.9350299122965187, 'bagging_freq': 6, 'min_data_in_leaf': 15, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:40,051]\u001b[0m Trial 50 finished with value: 0.9272237196765498 and parameters: {'learning_rate': 0.1, 'num_leaves': 1818, 'lambda_l1': 0.0013387701502979887, 'lambda_l2': 3.315245314201304e-08, 'feature_fraction': 0.8544323671320491, 'bagging_fraction': 0.8013863865652885, 'bagging_freq': 7, 'min_data_in_leaf': 13, 'extra_trees': False}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:40,292]\u001b[0m Trial 51 finished with value: 0.9123989218328842 and parameters: {'learning_rate': 0.1, 'num_leaves': 82, 'lambda_l1': 0.0017943987974197828, 'lambda_l2': 2.8178575621838615e-08, 'feature_fraction': 0.862287457036843, 'bagging_fraction': 0.8800537539192508, 'bagging_freq': 6, 'min_data_in_leaf': 42, 'extra_trees': False}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:40,486]\u001b[0m Trial 52 finished with value: 0.889487870619946 and parameters: {'learning_rate': 0.1, 'num_leaves': 1734, 'lambda_l1': 0.010347107503792946, 'lambda_l2': 1.1298096547025529e-07, 'feature_fraction': 0.8773692214701515, 'bagging_fraction': 0.8113629842427225, 'bagging_freq': 7, 'min_data_in_leaf': 49, 'extra_trees': False}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:40,889]\u001b[0m Trial 53 finished with value: 0.894878706199461 and parameters: {'learning_rate': 0.1, 'num_leaves': 1837, 'lambda_l1': 0.002172109624192671, 'lambda_l2': 1.0157195407634831e-08, 'feature_fraction': 0.9264305730022186, 'bagging_fraction': 0.8997521064350976, 'bagging_freq': 7, 'min_data_in_leaf': 35, 'extra_trees': False}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:41,286]\u001b[0m Trial 54 finished with value: 0.9245283018867925 and parameters: {'learning_rate': 0.1, 'num_leaves': 2041, 'lambda_l1': 0.051860232845138646, 'lambda_l2': 2.5066393286442356e-07, 'feature_fraction': 0.9995982207329754, 'bagging_fraction': 0.8611921569858745, 'bagging_freq': 5, 'min_data_in_leaf': 25, 'extra_trees': False}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:41,658]\u001b[0m Trial 55 finished with value: 0.9097035040431267 and parameters: {'learning_rate': 0.1, 'num_leaves': 1082, 'lambda_l1': 0.0005657675476475609, 'lambda_l2': 2.567824356060825e-06, 'feature_fraction': 0.8209087452152531, 'bagging_fraction': 0.7047896419130413, 'bagging_freq': 3, 'min_data_in_leaf': 11, 'extra_trees': False}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:41,978]\u001b[0m Trial 56 finished with value: 0.9366576819407009 and parameters: {'learning_rate': 0.1, 'num_leaves': 712, 'lambda_l1': 0.00021338201947818181, 'lambda_l2': 6.084153011555182e-08, 'feature_fraction': 0.7652540662598695, 'bagging_fraction': 0.9151173171620518, 'bagging_freq': 5, 'min_data_in_leaf': 21, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:42,389]\u001b[0m Trial 57 finished with value: 0.9447439353099731 and parameters: {'learning_rate': 0.1, 'num_leaves': 768, 'lambda_l1': 0.00017405347197787458, 'lambda_l2': 5.149344072443574e-08, 'feature_fraction': 0.7646429713652165, 'bagging_fraction': 0.9529569005614758, 'bagging_freq': 5, 'min_data_in_leaf': 21, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:42,592]\u001b[0m Trial 58 finished with value: 0.9460916442048518 and parameters: {'learning_rate': 0.1, 'num_leaves': 786, 'lambda_l1': 5.443870211208787e-05, 'lambda_l2': 1.0998404228505228e-07, 'feature_fraction': 0.7706411961548534, 'bagging_fraction': 0.9662704307093787, 'bagging_freq': 5, 'min_data_in_leaf': 22, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:42,812]\u001b[0m Trial 59 finished with value: 0.9164420485175202 and parameters: {'learning_rate': 0.1, 'num_leaves': 784, 'lambda_l1': 4.616495937793298e-05, 'lambda_l2': 0.9230818023989366, 'feature_fraction': 0.7691776262644996, 'bagging_fraction': 0.9660236258804717, 'bagging_freq': 5, 'min_data_in_leaf': 60, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:43,031]\u001b[0m Trial 60 finished with value: 0.9312668463611861 and parameters: {'learning_rate': 0.1, 'num_leaves': 522, 'lambda_l1': 0.0001704944060794362, 'lambda_l2': 1.7060718826226568e-07, 'feature_fraction': 0.7337387368787385, 'bagging_fraction': 0.46023052080622756, 'bagging_freq': 4, 'min_data_in_leaf': 20, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:43,169]\u001b[0m Trial 61 finished with value: 0.9110512129380054 and parameters: {'learning_rate': 0.1, 'num_leaves': 305, 'lambda_l1': 0.0003704767454087505, 'lambda_l2': 1.6122196182312362e-07, 'feature_fraction': 0.7408819647313589, 'bagging_fraction': 0.480260930152201, 'bagging_freq': 4, 'min_data_in_leaf': 21, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:43,400]\u001b[0m Trial 62 finished with value: 0.9285714285714286 and parameters: {'learning_rate': 0.1, 'num_leaves': 517, 'lambda_l1': 0.00015925893208258853, 'lambda_l2': 5.3050787265153756e-08, 'feature_fraction': 0.7688296905177524, 'bagging_fraction': 0.5329532687407718, 'bagging_freq': 4, 'min_data_in_leaf': 28, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:43,572]\u001b[0m Trial 63 finished with value: 0.8921832884097035 and parameters: {'learning_rate': 0.1, 'num_leaves': 584, 'lambda_l1': 1.872019869894983e-05, 'lambda_l2': 3.156664708291967e-07, 'feature_fraction': 0.6854278735886074, 'bagging_fraction': 0.36928884878167273, 'bagging_freq': 5, 'min_data_in_leaf': 19, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:43,887]\u001b[0m Trial 64 finished with value: 0.9137466307277629 and parameters: {'learning_rate': 0.1, 'num_leaves': 861, 'lambda_l1': 0.00015276370891369772, 'lambda_l2': 1.0715983775420659e-07, 'feature_fraction': 0.7287305301819196, 'bagging_fraction': 0.9217458698376545, 'bagging_freq': 5, 'min_data_in_leaf': 27, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:44,052]\u001b[0m Trial 65 finished with value: 0.9137466307277629 and parameters: {'learning_rate': 0.1, 'num_leaves': 746, 'lambda_l1': 5.297794561344193e-06, 'lambda_l2': 3.063073786358409e-08, 'feature_fraction': 0.7916753100464321, 'bagging_fraction': 0.462816030844459, 'bagging_freq': 5, 'min_data_in_leaf': 21, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:44,279]\u001b[0m Trial 66 finished with value: 0.8827493261455526 and parameters: {'learning_rate': 0.0125, 'num_leaves': 491, 'lambda_l1': 3.177493031551507e-05, 'lambda_l2': 6.449872820211626e-07, 'feature_fraction': 0.704389649980418, 'bagging_fraction': 0.9741071896676258, 'bagging_freq': 4, 'min_data_in_leaf': 30, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:44,503]\u001b[0m Trial 67 finished with value: 0.9245283018867925 and parameters: {'learning_rate': 0.1, 'num_leaves': 635, 'lambda_l1': 0.00010927892541465294, 'lambda_l2': 1.7936883480688965e-07, 'feature_fraction': 0.7569122233697606, 'bagging_fraction': 0.9519229270838693, 'bagging_freq': 6, 'min_data_in_leaf': 24, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:44,881]\u001b[0m Trial 68 finished with value: 0.8975741239892184 and parameters: {'learning_rate': 0.1, 'num_leaves': 1174, 'lambda_l1': 0.00033990546994602496, 'lambda_l2': 6.428104865758839e-06, 'feature_fraction': 0.6101280325829987, 'bagging_fraction': 0.9092030665696087, 'bagging_freq': 5, 'min_data_in_leaf': 18, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:45,376]\u001b[0m Trial 69 finished with value: 0.9258760107816711 and parameters: {'learning_rate': 0.1, 'num_leaves': 993, 'lambda_l1': 9.410329183095897e-06, 'lambda_l2': 5.678722784340912e-08, 'feature_fraction': 0.8377097476267764, 'bagging_fraction': 0.9987037997676269, 'bagging_freq': 4, 'min_data_in_leaf': 14, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:45,520]\u001b[0m Trial 70 finished with value: 0.8504043126684636 and parameters: {'learning_rate': 0.05, 'num_leaves': 841, 'lambda_l1': 7.356563967371491e-05, 'lambda_l2': 2.1251303607622708e-08, 'feature_fraction': 0.8029742541775551, 'bagging_fraction': 0.6361833574037232, 'bagging_freq': 6, 'min_data_in_leaf': 69, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:45,883]\u001b[0m Trial 71 finished with value: 0.8975741239892183 and parameters: {'learning_rate': 0.1, 'num_leaves': 749, 'lambda_l1': 0.00023248677086238552, 'lambda_l2': 8.020955168425777e-08, 'feature_fraction': 0.7243365619050829, 'bagging_fraction': 0.4403228007125675, 'bagging_freq': 5, 'min_data_in_leaf': 3, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:46,334]\u001b[0m Trial 72 finished with value: 0.898921832884097 and parameters: {'learning_rate': 0.1, 'num_leaves': 1134, 'lambda_l1': 0.001004428271088934, 'lambda_l2': 4.65649224819851e-07, 'feature_fraction': 0.6510668110068425, 'bagging_fraction': 0.8925208054878626, 'bagging_freq': 5, 'min_data_in_leaf': 12, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:46,500]\u001b[0m Trial 73 finished with value: 0.9150943396226415 and parameters: {'learning_rate': 0.1, 'num_leaves': 877, 'lambda_l1': 1.6705641133856373, 'lambda_l2': 1.922555974097254e-06, 'feature_fraction': 0.7836697870732714, 'bagging_fraction': 0.9263148701024196, 'bagging_freq': 4, 'min_data_in_leaf': 22, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:46,689]\u001b[0m Trial 74 finished with value: 0.9110512129380055 and parameters: {'learning_rate': 0.1, 'num_leaves': 391, 'lambda_l1': 0.0037947033585295597, 'lambda_l2': 4.8654201415736206e-08, 'feature_fraction': 0.7697837893846409, 'bagging_fraction': 0.51942274691217, 'bagging_freq': 4, 'min_data_in_leaf': 28, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:46,818]\u001b[0m Trial 75 finished with value: 0.8679245283018868 and parameters: {'learning_rate': 0.1, 'num_leaves': 461, 'lambda_l1': 0.00022796767348955444, 'lambda_l2': 9.588424874958267e-07, 'feature_fraction': 0.3503741128924074, 'bagging_fraction': 0.5561369563006122, 'bagging_freq': 4, 'min_data_in_leaf': 31, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:47,008]\u001b[0m Trial 76 finished with value: 0.8827493261455526 and parameters: {'learning_rate': 0.1, 'num_leaves': 551, 'lambda_l1': 3.395887060937881e-05, 'lambda_l2': 2.1385955645679212e-07, 'feature_fraction': 0.6737324368873803, 'bagging_fraction': 0.3893878390007948, 'bagging_freq': 5, 'min_data_in_leaf': 52, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:47,290]\u001b[0m Trial 77 finished with value: 0.8773584905660377 and parameters: {'learning_rate': 0.0125, 'num_leaves': 671, 'lambda_l1': 2.6609652847604512e-06, 'lambda_l2': 4.452184803555817e-08, 'feature_fraction': 0.740420611277436, 'bagging_fraction': 0.5403608722618332, 'bagging_freq': 4, 'min_data_in_leaf': 16, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:47,435]\u001b[0m Trial 78 finished with value: 0.8773584905660378 and parameters: {'learning_rate': 0.1, 'num_leaves': 538, 'lambda_l1': 0.00010556183915833887, 'lambda_l2': 1.1222056822779599e-07, 'feature_fraction': 0.8410217996117175, 'bagging_fraction': 0.431294141804109, 'bagging_freq': 5, 'min_data_in_leaf': 37, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:48,068]\u001b[0m Trial 79 finished with value: 0.9231805929919138 and parameters: {'learning_rate': 0.1, 'num_leaves': 1388, 'lambda_l1': 1.6451269331858456e-07, 'lambda_l2': 4.605748277841611e-07, 'feature_fraction': 0.7149284388136062, 'bagging_fraction': 0.8682185737226706, 'bagging_freq': 5, 'min_data_in_leaf': 5, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:48,250]\u001b[0m Trial 80 finished with value: 0.8827493261455526 and parameters: {'learning_rate': 0.1, 'num_leaves': 1234, 'lambda_l1': 1.6497967439698476e-05, 'lambda_l2': 1.6899075423387416e-08, 'feature_fraction': 0.7548995187653024, 'bagging_fraction': 0.9505978760065186, 'bagging_freq': 4, 'min_data_in_leaf': 27, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:48,568]\u001b[0m Trial 81 finished with value: 0.9191374663072778 and parameters: {'learning_rate': 0.1, 'num_leaves': 967, 'lambda_l1': 2.0628920056990187e-08, 'lambda_l2': 7.00540461620666e-08, 'feature_fraction': 0.6943438138842173, 'bagging_fraction': 0.6040077312930398, 'bagging_freq': 5, 'min_data_in_leaf': 19, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:48,886]\u001b[0m Trial 82 finished with value: 0.917789757412399 and parameters: {'learning_rate': 0.1, 'num_leaves': 788, 'lambda_l1': 0.0005576409765889918, 'lambda_l2': 1.5533343987989545e-07, 'feature_fraction': 0.8071698107900713, 'bagging_fraction': 0.9761226002928831, 'bagging_freq': 5, 'min_data_in_leaf': 23, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:49,429]\u001b[0m Trial 83 finished with value: 0.9420485175202158 and parameters: {'learning_rate': 0.1, 'num_leaves': 1076, 'lambda_l1': 0.00017512256423627155, 'lambda_l2': 3.1944910472847877e-07, 'feature_fraction': 0.768919654739139, 'bagging_fraction': 0.8392068520016224, 'bagging_freq': 5, 'min_data_in_leaf': 9, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:49,607]\u001b[0m Trial 84 finished with value: 0.9029649595687332 and parameters: {'learning_rate': 0.1, 'num_leaves': 1076, 'lambda_l1': 5.2058849440011835e-05, 'lambda_l2': 8.578844103464614e-07, 'feature_fraction': 0.7749385073860828, 'bagging_fraction': 0.507115715082567, 'bagging_freq': 6, 'min_data_in_leaf': 41, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:49,938]\u001b[0m Trial 85 finished with value: 0.9433962264150944 and parameters: {'learning_rate': 0.05, 'num_leaves': 1047, 'lambda_l1': 0.0009642481813053624, 'lambda_l2': 3.3137256162667315e-07, 'feature_fraction': 0.7163390164259429, 'bagging_fraction': 0.8586079892461922, 'bagging_freq': 5, 'min_data_in_leaf': 10, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:50,480]\u001b[0m Trial 86 finished with value: 0.9110512129380055 and parameters: {'learning_rate': 0.05, 'num_leaves': 1032, 'lambda_l1': 0.003927039976536402, 'lambda_l2': 3.360900843861147e-07, 'feature_fraction': 0.7378979661380127, 'bagging_fraction': 0.8531380846469824, 'bagging_freq': 5, 'min_data_in_leaf': 9, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:50,789]\u001b[0m Trial 87 finished with value: 0.8854447439353099 and parameters: {'learning_rate': 0.05, 'num_leaves': 1218, 'lambda_l1': 0.018024483147982422, 'lambda_l2': 3.034302051642317e-05, 'feature_fraction': 0.6343316230640604, 'bagging_fraction': 0.8336474875524296, 'bagging_freq': 5, 'min_data_in_leaf': 76, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:51,092]\u001b[0m Trial 88 finished with value: 0.9056603773584906 and parameters: {'learning_rate': 0.05, 'num_leaves': 1299, 'lambda_l1': 0.001177472952234918, 'lambda_l2': 3.193416142369581e-06, 'feature_fraction': 0.6712925800751655, 'bagging_fraction': 0.9124320469369035, 'bagging_freq': 5, 'min_data_in_leaf': 14, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:51,325]\u001b[0m Trial 89 finished with value: 0.8935309973045822 and parameters: {'learning_rate': 0.05, 'num_leaves': 1374, 'lambda_l1': 0.00043539857679072844, 'lambda_l2': 0.0312827572331592, 'feature_fraction': 0.5301966250587543, 'bagging_fraction': 0.3033562213862412, 'bagging_freq': 6, 'min_data_in_leaf': 5, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:51,684]\u001b[0m Trial 90 finished with value: 0.9433962264150944 and parameters: {'learning_rate': 0.05, 'num_leaves': 1050, 'lambda_l1': 6.949179197424415e-07, 'lambda_l2': 1.5115311505819593e-06, 'feature_fraction': 0.7161607200915593, 'bagging_fraction': 0.33830600447575193, 'bagging_freq': 5, 'min_data_in_leaf': 11, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:52,028]\u001b[0m Trial 91 finished with value: 0.9070080862533693 and parameters: {'learning_rate': 0.05, 'num_leaves': 1064, 'lambda_l1': 4.1788282034092275e-06, 'lambda_l2': 1.6573853079628448e-06, 'feature_fraction': 0.7066057523664293, 'bagging_fraction': 0.32553835154122873, 'bagging_freq': 5, 'min_data_in_leaf': 11, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:52,490]\u001b[0m Trial 92 finished with value: 0.9204851752021563 and parameters: {'learning_rate': 0.05, 'num_leaves': 1130, 'lambda_l1': 4.479622714849198e-07, 'lambda_l2': 7.325807481364853e-07, 'feature_fraction': 0.7247719468987731, 'bagging_fraction': 0.9398553108886903, 'bagging_freq': 5, 'min_data_in_leaf': 17, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:52,718]\u001b[0m Trial 93 finished with value: 0.8800539083557951 and parameters: {'learning_rate': 0.05, 'num_leaves': 1196, 'lambda_l1': 1.4817941082288371e-06, 'lambda_l2': 2.780958331036543e-07, 'feature_fraction': 0.7548290622205438, 'bagging_fraction': 0.3399782377655331, 'bagging_freq': 5, 'min_data_in_leaf': 9, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:53,220]\u001b[0m Trial 94 finished with value: 0.8975741239892183 and parameters: {'learning_rate': 0.05, 'num_leaves': 901, 'lambda_l1': 0.00022879409489721882, 'lambda_l2': 4.2016727487955e-06, 'feature_fraction': 0.7888466862130925, 'bagging_fraction': 0.8850527291562719, 'bagging_freq': 5, 'min_data_in_leaf': 13, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:53,497]\u001b[0m Trial 95 finished with value: 0.9258760107816711 and parameters: {'learning_rate': 0.05, 'num_leaves': 972, 'lambda_l1': 7.268240660302411e-07, 'lambda_l2': 1.2000103903715797e-06, 'feature_fraction': 0.761578314866569, 'bagging_fraction': 0.9854441998994801, 'bagging_freq': 6, 'min_data_in_leaf': 21, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:54,023]\u001b[0m Trial 96 finished with value: 0.9083557951482479 and parameters: {'learning_rate': 0.0125, 'num_leaves': 1273, 'lambda_l1': 0.0008293052146905589, 'lambda_l2': 1.2469560423343216e-07, 'feature_fraction': 0.4670250787071496, 'bagging_fraction': 0.8234575867617362, 'bagging_freq': 5, 'min_data_in_leaf': 4, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:54,297]\u001b[0m Trial 97 finished with value: 0.9070080862533693 and parameters: {'learning_rate': 0.1, 'num_leaves': 1034, 'lambda_l1': 0.11331943549807771, 'lambda_l2': 4.3083640237061644e-07, 'feature_fraction': 0.8201695891760148, 'bagging_fraction': 0.7841712322760687, 'bagging_freq': 5, 'min_data_in_leaf': 16, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:54,803]\u001b[0m Trial 98 finished with value: 0.9137466307277629 and parameters: {'learning_rate': 0.1, 'num_leaves': 1148, 'lambda_l1': 9.066781257371788e-06, 'lambda_l2': 2.2696253572932612e-06, 'feature_fraction': 0.6922626289310382, 'bagging_fraction': 0.8688679368337063, 'bagging_freq': 5, 'min_data_in_leaf': 8, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:55,022]\u001b[0m Trial 99 finished with value: 0.9299191374663073 and parameters: {'learning_rate': 0.1, 'num_leaves': 618, 'lambda_l1': 8.057126576647317e-05, 'lambda_l2': 2.1102482851743105e-07, 'feature_fraction': 0.7328960189609351, 'bagging_fraction': 0.9614344956337904, 'bagging_freq': 4, 'min_data_in_leaf': 20, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:55,403]\u001b[0m Trial 100 finished with value: 0.9218328840970351 and parameters: {'learning_rate': 0.05, 'num_leaves': 700, 'lambda_l1': 0.006634488674601647, 'lambda_l2': 1.0001551066010528e-05, 'feature_fraction': 0.7852544342467564, 'bagging_fraction': 0.7428725153540393, 'bagging_freq': 6, 'min_data_in_leaf': 35, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:55,730]\u001b[0m Trial 101 finished with value: 0.908355795148248 and parameters: {'learning_rate': 0.1, 'num_leaves': 630, 'lambda_l1': 8.569521437435694e-05, 'lambda_l2': 2.0451928346927894e-07, 'feature_fraction': 0.7349787935691372, 'bagging_fraction': 0.9206712780130155, 'bagging_freq': 4, 'min_data_in_leaf': 26, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:56,025]\u001b[0m Trial 102 finished with value: 0.9191374663072777 and parameters: {'learning_rate': 0.1, 'num_leaves': 822, 'lambda_l1': 3.4655587155927495e-05, 'lambda_l2': 8.548668870592795e-08, 'feature_fraction': 0.7194354319835261, 'bagging_fraction': 0.9535334614984364, 'bagging_freq': 4, 'min_data_in_leaf': 20, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:56,235]\u001b[0m Trial 103 finished with value: 0.9164420485175202 and parameters: {'learning_rate': 0.1, 'num_leaves': 385, 'lambda_l1': 0.00016898801622751544, 'lambda_l2': 5.960902538490017e-07, 'feature_fraction': 0.7457764438186358, 'bagging_fraction': 0.9689685486243973, 'bagging_freq': 5, 'min_data_in_leaf': 18, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:57,016]\u001b[0m Trial 104 finished with value: 0.9272237196765499 and parameters: {'learning_rate': 0.1, 'num_leaves': 596, 'lambda_l1': 2.3221712598865302e-05, 'lambda_l2': 3.21274712437132e-08, 'feature_fraction': 0.8086731753185551, 'bagging_fraction': 0.9013131866787031, 'bagging_freq': 4, 'min_data_in_leaf': 12, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:57,270]\u001b[0m Trial 105 finished with value: 0.9245283018867925 and parameters: {'learning_rate': 0.1, 'num_leaves': 747, 'lambda_l1': 5.7249187005647215e-05, 'lambda_l2': 2.527551424726284e-07, 'feature_fraction': 0.7045413714068334, 'bagging_fraction': 0.9343872465281557, 'bagging_freq': 5, 'min_data_in_leaf': 15, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:57,706]\u001b[0m Trial 106 finished with value: 0.9380053908355797 and parameters: {'learning_rate': 0.1, 'num_leaves': 660, 'lambda_l1': 0.0026211999955709185, 'lambda_l2': 2.121448460624888e-08, 'feature_fraction': 0.6787007536318069, 'bagging_fraction': 0.9844591878451912, 'bagging_freq': 4, 'min_data_in_leaf': 22, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:57,980]\u001b[0m Trial 107 finished with value: 0.9326145552560647 and parameters: {'learning_rate': 0.1, 'num_leaves': 1106, 'lambda_l1': 0.0025843080396027807, 'lambda_l2': 1.6589054009212024e-08, 'feature_fraction': 0.6534391911527703, 'bagging_fraction': 0.9436768583607857, 'bagging_freq': 5, 'min_data_in_leaf': 23, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:58,255]\u001b[0m Trial 108 finished with value: 0.9285714285714286 and parameters: {'learning_rate': 0.1, 'num_leaves': 1116, 'lambda_l1': 0.002246898854894603, 'lambda_l2': 2.1482476963552907e-08, 'feature_fraction': 0.5776774995840189, 'bagging_fraction': 0.9872882418439296, 'bagging_freq': 5, 'min_data_in_leaf': 23, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:58,454]\u001b[0m Trial 109 finished with value: 0.9204851752021563 and parameters: {'learning_rate': 0.1, 'num_leaves': 931, 'lambda_l1': 0.014728314775612043, 'lambda_l2': 1.3611829932404567e-08, 'feature_fraction': 0.6552143830222283, 'bagging_fraction': 0.6812885649197231, 'bagging_freq': 5, 'min_data_in_leaf': 29, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:58,765]\u001b[0m Trial 110 finished with value: 0.9070080862533693 and parameters: {'learning_rate': 0.025, 'num_leaves': 1168, 'lambda_l1': 0.026427326480338343, 'lambda_l2': 2.4217801312984396e-08, 'feature_fraction': 0.6359452089839157, 'bagging_fraction': 0.9255707130619958, 'bagging_freq': 5, 'min_data_in_leaf': 33, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:59,212]\u001b[0m Trial 111 finished with value: 0.9110512129380054 and parameters: {'learning_rate': 0.1, 'num_leaves': 1066, 'lambda_l1': 0.006195992369556746, 'lambda_l2': 4.6080594311534506e-08, 'feature_fraction': 0.6188794509180138, 'bagging_fraction': 0.9483681087762249, 'bagging_freq': 5, 'min_data_in_leaf': 25, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:59,606]\u001b[0m Trial 112 finished with value: 0.9245283018867925 and parameters: {'learning_rate': 0.1, 'num_leaves': 1261, 'lambda_l1': 0.002533450768873183, 'lambda_l2': 8.066676469065565e-08, 'feature_fraction': 0.6721507523236209, 'bagging_fraction': 0.8904936212517038, 'bagging_freq': 5, 'min_data_in_leaf': 10, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:51:59,926]\u001b[0m Trial 113 finished with value: 0.9097035040431267 and parameters: {'learning_rate': 0.1, 'num_leaves': 1008, 'lambda_l1': 0.01025196484588326, 'lambda_l2': 1.4419755568205563e-07, 'feature_fraction': 0.6840820289654153, 'bagging_fraction': 0.9800468972702953, 'bagging_freq': 5, 'min_data_in_leaf': 18, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:00,094]\u001b[0m Trial 114 finished with value: 0.8881401617250674 and parameters: {'learning_rate': 0.1, 'num_leaves': 677, 'lambda_l1': 0.0014032398418547848, 'lambda_l2': 1.4382126733270159e-08, 'feature_fraction': 0.7662484586978229, 'bagging_fraction': 0.354066227767291, 'bagging_freq': 4, 'min_data_in_leaf': 22, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:00,388]\u001b[0m Trial 115 finished with value: 0.9245283018867926 and parameters: {'learning_rate': 0.1, 'num_leaves': 1211, 'lambda_l1': 0.03365691251512277, 'lambda_l2': 3.609572066219254e-08, 'feature_fraction': 0.7089707071445311, 'bagging_fraction': 0.9997470585111999, 'bagging_freq': 4, 'min_data_in_leaf': 7, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:00,820]\u001b[0m Trial 116 finished with value: 0.9083557951482479 and parameters: {'learning_rate': 0.1, 'num_leaves': 1341, 'lambda_l1': 0.0004429424004563796, 'lambda_l2': 7.654847554483472e-08, 'feature_fraction': 0.6015273604413739, 'bagging_fraction': 0.4238681638365031, 'bagging_freq': 5, 'min_data_in_leaf': 15, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:01,191]\u001b[0m Trial 117 finished with value: 0.9150943396226415 and parameters: {'learning_rate': 0.0125, 'num_leaves': 1099, 'lambda_l1': 0.0029942783316826774, 'lambda_l2': 1.0745419950270937e-08, 'feature_fraction': 0.6637092574422853, 'bagging_fraction': 0.911999821617054, 'bagging_freq': 5, 'min_data_in_leaf': 26, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:01,472]\u001b[0m Trial 118 finished with value: 0.921832884097035 and parameters: {'learning_rate': 0.1, 'num_leaves': 953, 'lambda_l1': 0.0003148915833989387, 'lambda_l2': 1.0247857136954804e-06, 'feature_fraction': 0.9669201812068557, 'bagging_fraction': 0.8385080003987654, 'bagging_freq': 4, 'min_data_in_leaf': 61, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:02,051]\u001b[0m Trial 119 finished with value: 0.9150943396226415 and parameters: {'learning_rate': 0.1, 'num_leaves': 778, 'lambda_l1': 0.0007148628240249972, 'lambda_l2': 3.6928072652397926e-07, 'feature_fraction': 0.7456526361669041, 'bagging_fraction': 0.9416317803784934, 'bagging_freq': 5, 'min_data_in_leaf': 13, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:03,024]\u001b[0m Trial 120 finished with value: 0.9407008086253369 and parameters: {'learning_rate': 0.05, 'num_leaves': 862, 'lambda_l1': 0.00011798770531399173, 'lambda_l2': 2.16734225179626e-08, 'feature_fraction': 0.7758604945746762, 'bagging_fraction': 0.8550250335892791, 'bagging_freq': 5, 'min_data_in_leaf': 1, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:04,166]\u001b[0m Trial 121 finished with value: 0.9137466307277627 and parameters: {'learning_rate': 0.05, 'num_leaves': 838, 'lambda_l1': 0.00024689896371619236, 'lambda_l2': 1.797802962168149e-08, 'feature_fraction': 0.7818401529112678, 'bagging_fraction': 0.8529954182754216, 'bagging_freq': 5, 'min_data_in_leaf': 1, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:05,059]\u001b[0m Trial 122 finished with value: 0.9150943396226415 and parameters: {'learning_rate': 0.05, 'num_leaves': 902, 'lambda_l1': 0.0001306615078979275, 'lambda_l2': 5.796220055437651e-08, 'feature_fraction': 0.7969001612594361, 'bagging_fraction': 0.9020481561884555, 'bagging_freq': 5, 'min_data_in_leaf': 3, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:05,338]\u001b[0m Trial 123 finished with value: 0.931266846361186 and parameters: {'learning_rate': 0.05, 'num_leaves': 728, 'lambda_l1': 0.0009748940525146246, 'lambda_l2': 1.187916772901672e-07, 'feature_fraction': 0.8395037199179742, 'bagging_fraction': 0.8770712211354577, 'bagging_freq': 5, 'min_data_in_leaf': 23, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:06,024]\u001b[0m Trial 124 finished with value: 0.9299191374663074 and parameters: {'learning_rate': 0.05, 'num_leaves': 1046, 'lambda_l1': 0.001535974097716648, 'lambda_l2': 2.4848344377222502e-08, 'feature_fraction': 0.7605966088722186, 'bagging_fraction': 0.8053266441971609, 'bagging_freq': 5, 'min_data_in_leaf': 6, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:06,341]\u001b[0m Trial 125 finished with value: 0.9083557951482479 and parameters: {'learning_rate': 0.05, 'num_leaves': 877, 'lambda_l1': 1.0121725436448383e-07, 'lambda_l2': 6.202457272361072e-07, 'feature_fraction': 0.71670995433848, 'bagging_fraction': 0.9722443151399687, 'bagging_freq': 5, 'min_data_in_leaf': 17, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:07,180]\u001b[0m Trial 126 finished with value: 0.9433962264150944 and parameters: {'learning_rate': 0.1, 'num_leaves': 799, 'lambda_l1': 0.005573625113685365, 'lambda_l2': 4.1592355891016195e-08, 'feature_fraction': 0.6797427390673423, 'bagging_fraction': 0.3913816980669117, 'bagging_freq': 6, 'min_data_in_leaf': 3, 'extra_trees': False}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:08,779]\u001b[0m Trial 127 finished with value: 0.9083557951482479 and parameters: {'learning_rate': 0.1, 'num_leaves': 997, 'lambda_l1': 2.5771954469995954e-07, 'lambda_l2': 3.8643040503239476e-08, 'feature_fraction': 0.6818695574288509, 'bagging_fraction': 0.38627928254487676, 'bagging_freq': 6, 'min_data_in_leaf': 1, 'extra_trees': False}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:08,917]\u001b[0m Trial 128 finished with value: 0.8328840970350404 and parameters: {'learning_rate': 0.1, 'num_leaves': 784, 'lambda_l1': 0.005352233610382696, 'lambda_l2': 1.792075691979426e-08, 'feature_fraction': 0.648928134729852, 'bagging_fraction': 0.31878067141074085, 'bagging_freq': 6, 'min_data_in_leaf': 46, 'extra_trees': False}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:09,436]\u001b[0m Trial 129 finished with value: 0.8948787061994609 and parameters: {'learning_rate': 0.05, 'num_leaves': 665, 'lambda_l1': 0.009688230194303428, 'lambda_l2': 5.307924290682781e-08, 'feature_fraction': 0.773380644997582, 'bagging_fraction': 0.9250388448358369, 'bagging_freq': 6, 'min_data_in_leaf': 8, 'extra_trees': False}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:09,967]\u001b[0m Trial 130 finished with value: 0.9029649595687331 and parameters: {'learning_rate': 0.1, 'num_leaves': 823, 'lambda_l1': 0.08323883835718732, 'lambda_l2': 9.960654364246465e-08, 'feature_fraction': 0.6951632195283665, 'bagging_fraction': 0.9573812076512237, 'bagging_freq': 6, 'min_data_in_leaf': 3, 'extra_trees': False}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:10,339]\u001b[0m Trial 131 finished with value: 0.8962264150943396 and parameters: {'learning_rate': 0.1, 'num_leaves': 1168, 'lambda_l1': 0.000503982098298692, 'lambda_l2': 1.6571954019676896e-07, 'feature_fraction': 0.7333211110918275, 'bagging_fraction': 0.35442561605364514, 'bagging_freq': 5, 'min_data_in_leaf': 11, 'extra_trees': False}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:10,720]\u001b[0m Trial 132 finished with value: 0.9043126684636118 and parameters: {'learning_rate': 0.1, 'num_leaves': 712, 'lambda_l1': 0.004134739492609048, 'lambda_l2': 3.0659187907423697e-08, 'feature_fraction': 0.7531615359711753, 'bagging_fraction': 0.4009829710584617, 'bagging_freq': 5, 'min_data_in_leaf': 5, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:11,179]\u001b[0m Trial 133 finished with value: 0.9420485175202157 and parameters: {'learning_rate': 0.1, 'num_leaves': 582, 'lambda_l1': 0.00019285787825620786, 'lambda_l2': 3.513943981173147e-07, 'feature_fraction': 0.913548986662541, 'bagging_fraction': 0.5831859811562216, 'bagging_freq': 4, 'min_data_in_leaf': 10, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:11,498]\u001b[0m Trial 134 finished with value: 0.8962264150943396 and parameters: {'learning_rate': 0.1, 'num_leaves': 1105, 'lambda_l1': 0.00010831209796706011, 'lambda_l2': 3.7340301261797154e-07, 'feature_fraction': 0.9156155178696598, 'bagging_fraction': 0.5663507851513605, 'bagging_freq': 5, 'min_data_in_leaf': 10, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:12,522]\u001b[0m Trial 135 finished with value: 0.9029649595687331 and parameters: {'learning_rate': 0.1, 'num_leaves': 569, 'lambda_l1': 0.00033212392036598474, 'lambda_l2': 1.5352081067559368e-06, 'feature_fraction': 0.9271542161025352, 'bagging_fraction': 0.7114804266298387, 'bagging_freq': 7, 'min_data_in_leaf': 6, 'extra_trees': False}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:13,557]\u001b[0m Trial 136 finished with value: 0.9083557951482479 and parameters: {'learning_rate': 0.025, 'num_leaves': 757, 'lambda_l1': 0.0007531553046052463, 'lambda_l2': 1.1474359636173301e-08, 'feature_fraction': 0.9072025376083008, 'bagging_fraction': 0.6521435476599184, 'bagging_freq': 4, 'min_data_in_leaf': 3, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:14,414]\u001b[0m Trial 137 finished with value: 0.9218328840970351 and parameters: {'learning_rate': 0.1, 'num_leaves': 645, 'lambda_l1': 4.654868423921506e-08, 'lambda_l2': 7.179181535469676e-07, 'feature_fraction': 0.9463273010665162, 'bagging_fraction': 0.6012689039764402, 'bagging_freq': 5, 'min_data_in_leaf': 8, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:14,973]\u001b[0m Trial 138 finished with value: 0.9231805929919137 and parameters: {'learning_rate': 0.1, 'num_leaves': 881, 'lambda_l1': 0.0017739087702437484, 'lambda_l2': 6.219983893936672e-08, 'feature_fraction': 0.795884191901668, 'bagging_fraction': 0.8586949282775732, 'bagging_freq': 5, 'min_data_in_leaf': 13, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:15,188]\u001b[0m Trial 139 finished with value: 0.8530997304582211 and parameters: {'learning_rate': 0.05, 'num_leaves': 1252, 'lambda_l1': 4.6313290108842435e-05, 'lambda_l2': 0.00026118160533266776, 'feature_fraction': 0.8660469339478123, 'bagging_fraction': 0.8247584713756573, 'bagging_freq': 4, 'min_data_in_leaf': 91, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:15,667]\u001b[0m Trial 140 finished with value: 0.931266846361186 and parameters: {'learning_rate': 0.1, 'num_leaves': 948, 'lambda_l1': 0.0002244333206592581, 'lambda_l2': 2.587462085141199e-07, 'feature_fraction': 0.9825982569574792, 'bagging_fraction': 0.8877670708972285, 'bagging_freq': 5, 'min_data_in_leaf': 10, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:15,795]\u001b[0m Trial 141 finished with value: 0.9043126684636119 and parameters: {'learning_rate': 0.1, 'num_leaves': 447, 'lambda_l1': 0.00016740523474603741, 'lambda_l2': 1.5255199811839858e-07, 'feature_fraction': 0.7231323819517226, 'bagging_fraction': 0.479379950681924, 'bagging_freq': 3, 'min_data_in_leaf': 21, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:15,925]\u001b[0m Trial 142 finished with value: 0.8396226415094339 and parameters: {'learning_rate': 0.1, 'num_leaves': 582, 'lambda_l1': 0.00275813419375983, 'lambda_l2': 5.363791593955572e-07, 'feature_fraction': 0.7002532740799666, 'bagging_fraction': 0.4129745365938194, 'bagging_freq': 4, 'min_data_in_leaf': 15, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:16,138]\u001b[0m Trial 143 finished with value: 0.9218328840970351 and parameters: {'learning_rate': 0.1, 'num_leaves': 477, 'lambda_l1': 8.043603408163573e-05, 'lambda_l2': 1.0759831825574425e-06, 'feature_fraction': 0.8148686022837637, 'bagging_fraction': 0.36831204484583246, 'bagging_freq': 1, 'min_data_in_leaf': 19, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:16,295]\u001b[0m Trial 144 finished with value: 0.8746630727762803 and parameters: {'learning_rate': 0.1, 'num_leaves': 702, 'lambda_l1': 0.00012776409627798875, 'lambda_l2': 9.906690124628046e-08, 'feature_fraction': 0.7438288890788288, 'bagging_fraction': 0.44540927212867515, 'bagging_freq': 4, 'min_data_in_leaf': 24, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:16,548]\u001b[0m Trial 145 finished with value: 0.9164420485175202 and parameters: {'learning_rate': 0.1, 'num_leaves': 1191, 'lambda_l1': 1.4894035926155348e-06, 'lambda_l2': 3.4247148872360427e-08, 'feature_fraction': 0.9412527215033593, 'bagging_fraction': 0.6186033985435997, 'bagging_freq': 3, 'min_data_in_leaf': 30, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:16,731]\u001b[0m Trial 146 finished with value: 0.8840970350404314 and parameters: {'learning_rate': 0.0125, 'num_leaves': 527, 'lambda_l1': 0.000348876702969924, 'lambda_l2': 3.3872519560846305e-07, 'feature_fraction': 0.8794710289967629, 'bagging_fraction': 0.5827937541852595, 'bagging_freq': 4, 'min_data_in_leaf': 16, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:17,249]\u001b[0m Trial 147 finished with value: 0.9002695417789757 and parameters: {'learning_rate': 0.1, 'num_leaves': 1149, 'lambda_l1': 0.007276811244002406, 'lambda_l2': 2.348229460381575e-06, 'feature_fraction': 0.7683190696675435, 'bagging_fraction': 0.9391126545582464, 'bagging_freq': 5, 'min_data_in_leaf': 4, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:17,541]\u001b[0m Trial 148 finished with value: 0.9393530997304582 and parameters: {'learning_rate': 0.1, 'num_leaves': 816, 'lambda_l1': 0.014510834951211315, 'lambda_l2': 0.0035178795246063603, 'feature_fraction': 0.7818701741599885, 'bagging_fraction': 0.9120526728957455, 'bagging_freq': 4, 'min_data_in_leaf': 25, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:17,863]\u001b[0m Trial 149 finished with value: 0.9164420485175203 and parameters: {'learning_rate': 0.05, 'num_leaves': 806, 'lambda_l1': 0.012051166301832623, 'lambda_l2': 0.2498580335999798, 'feature_fraction': 0.783888299277625, 'bagging_fraction': 0.9155073109937968, 'bagging_freq': 5, 'min_data_in_leaf': 28, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:18,136]\u001b[0m Trial 150 finished with value: 0.8854447439353099 and parameters: {'learning_rate': 0.1, 'num_leaves': 850, 'lambda_l1': 0.003550502060995995, 'lambda_l2': 0.0034443120879272216, 'feature_fraction': 0.803962808873413, 'bagging_fraction': 0.8972571735205827, 'bagging_freq': 4, 'min_data_in_leaf': 54, 'extra_trees': False}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:18,474]\u001b[0m Trial 151 finished with value: 0.9326145552560647 and parameters: {'learning_rate': 0.1, 'num_leaves': 725, 'lambda_l1': 1.6294284161519774e-08, 'lambda_l2': 0.00861554702528722, 'feature_fraction': 0.7550414294035269, 'bagging_fraction': 0.9643238006963802, 'bagging_freq': 4, 'min_data_in_leaf': 25, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:18,727]\u001b[0m Trial 152 finished with value: 0.9326145552560647 and parameters: {'learning_rate': 0.1, 'num_leaves': 743, 'lambda_l1': 1.591719561201894e-08, 'lambda_l2': 0.014659768134222238, 'feature_fraction': 0.7588541739638802, 'bagging_fraction': 0.9672271448129831, 'bagging_freq': 5, 'min_data_in_leaf': 25, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:18,964]\u001b[0m Trial 153 finished with value: 0.9137466307277629 and parameters: {'learning_rate': 0.1, 'num_leaves': 772, 'lambda_l1': 3.224552029066316e-08, 'lambda_l2': 0.012362925747366336, 'feature_fraction': 0.7809030687207525, 'bagging_fraction': 0.9491808218170262, 'bagging_freq': 5, 'min_data_in_leaf': 22, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:19,338]\u001b[0m Trial 154 finished with value: 0.9110512129380055 and parameters: {'learning_rate': 0.1, 'num_leaves': 673, 'lambda_l1': 0.03342252233528263, 'lambda_l2': 0.05232168938952668, 'feature_fraction': 0.7634337440141966, 'bagging_fraction': 0.985152937659639, 'bagging_freq': 5, 'min_data_in_leaf': 7, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:19,588]\u001b[0m Trial 155 finished with value: 0.9326145552560647 and parameters: {'learning_rate': 0.1, 'num_leaves': 719, 'lambda_l1': 2.0531322611095517e-08, 'lambda_l2': 0.003965718757358426, 'feature_fraction': 0.7497503236450949, 'bagging_fraction': 0.9572045280574734, 'bagging_freq': 4, 'min_data_in_leaf': 25, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:19,871]\u001b[0m Trial 156 finished with value: 0.9339622641509434 and parameters: {'learning_rate': 0.1, 'num_leaves': 615, 'lambda_l1': 1.4371810522158328e-08, 'lambda_l2': 0.002194034053436771, 'feature_fraction': 0.7447503297693884, 'bagging_fraction': 0.931749216679969, 'bagging_freq': 4, 'min_data_in_leaf': 27, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:20,169]\u001b[0m Trial 157 finished with value: 0.9312668463611861 and parameters: {'learning_rate': 0.1, 'num_leaves': 628, 'lambda_l1': 0.01778666819507843, 'lambda_l2': 0.0019129722633184655, 'feature_fraction': 0.7103475870711471, 'bagging_fraction': 0.9274101527913928, 'bagging_freq': 5, 'min_data_in_leaf': 27, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:20,529]\u001b[0m Trial 158 finished with value: 0.9191374663072776 and parameters: {'learning_rate': 0.1, 'num_leaves': 1034, 'lambda_l1': 6.760190615112225e-08, 'lambda_l2': 0.0019154870333828718, 'feature_fraction': 0.6844901469415037, 'bagging_fraction': 0.8704823418423461, 'bagging_freq': 5, 'min_data_in_leaf': 12, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:20,722]\u001b[0m Trial 159 finished with value: 0.9097035040431267 and parameters: {'learning_rate': 0.05, 'num_leaves': 814, 'lambda_l1': 1.2985567201888877e-08, 'lambda_l2': 0.0008109082300043406, 'feature_fraction': 0.7342221373062546, 'bagging_fraction': 0.9123505711394653, 'bagging_freq': 4, 'min_data_in_leaf': 32, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:21,049]\u001b[0m Trial 160 finished with value: 0.9097035040431267 and parameters: {'learning_rate': 0.1, 'num_leaves': 692, 'lambda_l1': 3.915102143981996e-08, 'lambda_l2': 0.002335942104686813, 'feature_fraction': 0.7217007963689108, 'bagging_fraction': 0.846901768842366, 'bagging_freq': 4, 'min_data_in_leaf': 29, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:21,209]\u001b[0m Trial 161 finished with value: 0.9231805929919138 and parameters: {'learning_rate': 0.1, 'num_leaves': 735, 'lambda_l1': 1.612648498720713e-08, 'lambda_l2': 0.010134348635380451, 'feature_fraction': 0.7600674631302462, 'bagging_fraction': 0.9737457697889795, 'bagging_freq': 4, 'min_data_in_leaf': 25, 'extra_trees': True}. Best is trial 13 with value: 0.9474393530997305.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:21,491]\u001b[0m Trial 162 finished with value: 0.9528301886792454 and parameters: {'learning_rate': 0.1, 'num_leaves': 770, 'lambda_l1': 1.0387978798667349e-08, 'lambda_l2': 0.010102989878155449, 'feature_fraction': 0.7776744134364957, 'bagging_fraction': 0.9405927410804265, 'bagging_freq': 4, 'min_data_in_leaf': 22, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:21,743]\u001b[0m Trial 163 finished with value: 0.9245283018867925 and parameters: {'learning_rate': 0.1, 'num_leaves': 761, 'lambda_l1': 2.1234297993336427e-08, 'lambda_l2': 0.005690632731953505, 'feature_fraction': 0.7771589252073344, 'bagging_fraction': 0.9675656769220233, 'bagging_freq': 4, 'min_data_in_leaf': 19, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:22,023]\u001b[0m Trial 164 finished with value: 0.9272237196765499 and parameters: {'learning_rate': 0.1, 'num_leaves': 597, 'lambda_l1': 2.6182064426449583e-08, 'lambda_l2': 0.02731791069275137, 'feature_fraction': 0.8267823925027448, 'bagging_fraction': 0.9432608057634496, 'bagging_freq': 4, 'min_data_in_leaf': 24, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:22,241]\u001b[0m Trial 165 finished with value: 0.9339622641509434 and parameters: {'learning_rate': 0.1, 'num_leaves': 907, 'lambda_l1': 1.1376093835963711e-08, 'lambda_l2': 0.00698572422296455, 'feature_fraction': 0.7941718559358277, 'bagging_fraction': 0.9380851093132577, 'bagging_freq': 4, 'min_data_in_leaf': 23, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:22,463]\u001b[0m Trial 166 finished with value: 0.9029649595687331 and parameters: {'learning_rate': 0.1, 'num_leaves': 912, 'lambda_l1': 1.2561514947777356e-08, 'lambda_l2': 0.017784455523858683, 'feature_fraction': 0.7967866777661718, 'bagging_fraction': 0.9300631627835458, 'bagging_freq': 4, 'min_data_in_leaf': 22, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:22,763]\u001b[0m Trial 167 finished with value: 0.9097035040431267 and parameters: {'learning_rate': 0.1, 'num_leaves': 872, 'lambda_l1': 0.0010749829175503015, 'lambda_l2': 0.005116678478137223, 'feature_fraction': 0.6623317677115523, 'bagging_fraction': 0.8942912326985, 'bagging_freq': 4, 'min_data_in_leaf': 20, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:23,174]\u001b[0m Trial 168 finished with value: 0.9272237196765499 and parameters: {'learning_rate': 0.025, 'num_leaves': 844, 'lambda_l1': 1.027393021744169e-08, 'lambda_l2': 0.04751873059024366, 'feature_fraction': 0.7889438095146094, 'bagging_fraction': 0.910729221482266, 'bagging_freq': 4, 'min_data_in_leaf': 17, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:23,463]\u001b[0m Trial 169 finished with value: 0.9245283018867925 and parameters: {'learning_rate': 0.05, 'num_leaves': 987, 'lambda_l1': 1.267072787940319e-07, 'lambda_l2': 0.0013626703444272875, 'feature_fraction': 0.7723333763851521, 'bagging_fraction': 0.9250718550526088, 'bagging_freq': 3, 'min_data_in_leaf': 41, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:23,720]\u001b[0m Trial 170 finished with value: 0.9272237196765499 and parameters: {'learning_rate': 0.1, 'num_leaves': 797, 'lambda_l1': 0.007056250174688295, 'lambda_l2': 0.0005046123578215161, 'feature_fraction': 0.6392994909201581, 'bagging_fraction': 0.8793156936362824, 'bagging_freq': 4, 'min_data_in_leaf': 22, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:23,937]\u001b[0m Trial 171 finished with value: 0.898921832884097 and parameters: {'learning_rate': 0.1, 'num_leaves': 745, 'lambda_l1': 1.9533631559774144e-08, 'lambda_l2': 0.010106217588755611, 'feature_fraction': 0.749626056908812, 'bagging_fraction': 0.9681875962418831, 'bagging_freq': 4, 'min_data_in_leaf': 26, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:24,216]\u001b[0m Trial 172 finished with value: 0.9272237196765499 and parameters: {'learning_rate': 0.1, 'num_leaves': 653, 'lambda_l1': 2.6463869712287627e-08, 'lambda_l2': 0.001287128821547094, 'feature_fraction': 0.7392593156467223, 'bagging_fraction': 0.9499034052893334, 'bagging_freq': 4, 'min_data_in_leaf': 23, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:24,559]\u001b[0m Trial 173 finished with value: 0.9110512129380054 and parameters: {'learning_rate': 0.1, 'num_leaves': 708, 'lambda_l1': 1.682511694879502e-08, 'lambda_l2': 0.007342702689959544, 'feature_fraction': 0.7649227505101416, 'bagging_fraction': 0.9882960752632446, 'bagging_freq': 4, 'min_data_in_leaf': 27, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:25,490]\u001b[0m Trial 174 finished with value: 0.9231805929919138 and parameters: {'learning_rate': 0.1, 'num_leaves': 956, 'lambda_l1': 3.445126472958946e-08, 'lambda_l2': 0.003064838433718459, 'feature_fraction': 0.8170716786958625, 'bagging_fraction': 0.9365280876215665, 'bagging_freq': 5, 'min_data_in_leaf': 1, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:25,727]\u001b[0m Trial 175 finished with value: 0.9204851752021563 and parameters: {'learning_rate': 0.1, 'num_leaves': 810, 'lambda_l1': 1.1177065678658172e-08, 'lambda_l2': 0.004548404159686808, 'feature_fraction': 0.7500974823073222, 'bagging_fraction': 0.9575224974363883, 'bagging_freq': 4, 'min_data_in_leaf': 29, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:26,282]\u001b[0m Trial 176 finished with value: 0.9218328840970351 and parameters: {'learning_rate': 0.1, 'num_leaves': 859, 'lambda_l1': 5.3899870309089e-08, 'lambda_l2': 0.018991280865508133, 'feature_fraction': 0.7845012048684085, 'bagging_fraction': 0.9080008592473844, 'bagging_freq': 5, 'min_data_in_leaf': 20, 'extra_trees': False}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:26,621]\u001b[0m Trial 177 finished with value: 0.9231805929919137 and parameters: {'learning_rate': 0.1, 'num_leaves': 1075, 'lambda_l1': 0.00020238673967771346, 'lambda_l2': 0.004163567570171089, 'feature_fraction': 0.72587603614863, 'bagging_fraction': 0.9373901896804554, 'bagging_freq': 4, 'min_data_in_leaf': 23, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:27,331]\u001b[0m Trial 178 finished with value: 0.8962264150943396 and parameters: {'learning_rate': 0.0125, 'num_leaves': 676, 'lambda_l1': 8.772642387953245e-07, 'lambda_l2': 2.2216511490437538e-07, 'feature_fraction': 0.8059424064258583, 'bagging_fraction': 0.8664524338902112, 'bagging_freq': 7, 'min_data_in_leaf': 9, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:27,601]\u001b[0m Trial 179 finished with value: 0.917789757412399 and parameters: {'learning_rate': 0.05, 'num_leaves': 916, 'lambda_l1': 6.996583275936008e-05, 'lambda_l2': 0.006891840680043682, 'feature_fraction': 0.7683962021178972, 'bagging_fraction': 0.8890231890975286, 'bagging_freq': 4, 'min_data_in_leaf': 18, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:27,838]\u001b[0m Trial 180 finished with value: 0.8935309973045822 and parameters: {'learning_rate': 0.1, 'num_leaves': 782, 'lambda_l1': 1.5900158865462668e-08, 'lambda_l2': 0.011912153763218908, 'feature_fraction': 0.7584105329669849, 'bagging_fraction': 0.9635177305203756, 'bagging_freq': 5, 'min_data_in_leaf': 25, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:28,129]\u001b[0m Trial 181 finished with value: 0.9137466307277629 and parameters: {'learning_rate': 0.1, 'num_leaves': 621, 'lambda_l1': 1.0250244120585772e-08, 'lambda_l2': 2.7029327156553683e-08, 'feature_fraction': 0.7422935049497584, 'bagging_fraction': 0.998299586926743, 'bagging_freq': 5, 'min_data_in_leaf': 21, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:28,461]\u001b[0m Trial 182 finished with value: 0.9043126684636119 and parameters: {'learning_rate': 0.1, 'num_leaves': 1217, 'lambda_l1': 2.8601548953406563e-08, 'lambda_l2': 0.006643678895212956, 'feature_fraction': 0.77954420823008, 'bagging_fraction': 0.9517232528614912, 'bagging_freq': 4, 'min_data_in_leaf': 26, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:28,929]\u001b[0m Trial 183 finished with value: 0.9487870619946092 and parameters: {'learning_rate': 0.1, 'num_leaves': 734, 'lambda_l1': 0.0050582967379238335, 'lambda_l2': 4.788898376791259e-08, 'feature_fraction': 0.7076511338807264, 'bagging_fraction': 0.9817223823860581, 'bagging_freq': 5, 'min_data_in_leaf': 14, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:29,183]\u001b[0m Trial 184 finished with value: 0.898921832884097 and parameters: {'learning_rate': 0.1, 'num_leaves': 762, 'lambda_l1': 1.642775279853907e-08, 'lambda_l2': 0.01953237759310021, 'feature_fraction': 0.7125134230066653, 'bagging_fraction': 0.9794297863572735, 'bagging_freq': 5, 'min_data_in_leaf': 14, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:29,566]\u001b[0m Trial 185 finished with value: 0.9433962264150944 and parameters: {'learning_rate': 0.1, 'num_leaves': 1295, 'lambda_l1': 0.0039049738818578675, 'lambda_l2': 1.8083113183954678e-08, 'feature_fraction': 0.6755221596617784, 'bagging_fraction': 0.9296418058666374, 'bagging_freq': 5, 'min_data_in_leaf': 16, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:29,844]\u001b[0m Trial 186 finished with value: 0.9366576819407008 and parameters: {'learning_rate': 0.1, 'num_leaves': 1391, 'lambda_l1': 0.004393204217015478, 'lambda_l2': 4.361784945796594e-08, 'feature_fraction': 0.6770340713778221, 'bagging_fraction': 0.9197177218988557, 'bagging_freq': 5, 'min_data_in_leaf': 12, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:30,272]\u001b[0m Trial 187 finished with value: 0.9231805929919137 and parameters: {'learning_rate': 0.1, 'num_leaves': 1280, 'lambda_l1': 0.00836877540196512, 'lambda_l2': 4.6739287706954326e-08, 'feature_fraction': 0.6793719704138453, 'bagging_fraction': 0.9192645338842196, 'bagging_freq': 5, 'min_data_in_leaf': 12, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:30,585]\u001b[0m Trial 188 finished with value: 0.9380053908355795 and parameters: {'learning_rate': 0.1, 'num_leaves': 1413, 'lambda_l1': 0.013524033387664633, 'lambda_l2': 7.49634678166837e-08, 'feature_fraction': 0.692762420999987, 'bagging_fraction': 0.8973336262487044, 'bagging_freq': 5, 'min_data_in_leaf': 14, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:31,000]\u001b[0m Trial 189 finished with value: 0.9447439353099731 and parameters: {'learning_rate': 0.05, 'num_leaves': 1350, 'lambda_l1': 0.005264762867334095, 'lambda_l2': 4.0873068767662916e-08, 'feature_fraction': 0.7016861436866809, 'bagging_fraction': 0.9013704606238249, 'bagging_freq': 5, 'min_data_in_leaf': 14, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:31,682]\u001b[0m Trial 190 finished with value: 0.9191374663072777 and parameters: {'learning_rate': 0.05, 'num_leaves': 1334, 'lambda_l1': 0.00478103347373728, 'lambda_l2': 2.23421257687048e-08, 'feature_fraction': 0.6977742216109434, 'bagging_fraction': 0.896508862443081, 'bagging_freq': 5, 'min_data_in_leaf': 14, 'extra_trees': False}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:32,043]\u001b[0m Trial 191 finished with value: 0.9150943396226415 and parameters: {'learning_rate': 0.05, 'num_leaves': 1412, 'lambda_l1': 0.022219075597487776, 'lambda_l2': 6.551857819728439e-08, 'feature_fraction': 0.6702130059472956, 'bagging_fraction': 0.9070015246733671, 'bagging_freq': 5, 'min_data_in_leaf': 16, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:32,345]\u001b[0m Trial 192 finished with value: 0.917789757412399 and parameters: {'learning_rate': 0.05, 'num_leaves': 1448, 'lambda_l1': 0.012973517591569471, 'lambda_l2': 4.013382817768511e-08, 'feature_fraction': 0.6911140369652848, 'bagging_fraction': 0.9245189291132635, 'bagging_freq': 5, 'min_data_in_leaf': 11, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:32,736]\u001b[0m Trial 193 finished with value: 0.9083557951482479 and parameters: {'learning_rate': 0.05, 'num_leaves': 1559, 'lambda_l1': 0.004017256586073924, 'lambda_l2': 7.123778351394055e-08, 'feature_fraction': 0.7011379282264113, 'bagging_fraction': 0.8826155476992976, 'bagging_freq': 5, 'min_data_in_leaf': 13, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:33,198]\u001b[0m Trial 194 finished with value: 0.9285714285714286 and parameters: {'learning_rate': 0.05, 'num_leaves': 1363, 'lambda_l1': 0.010928302988341437, 'lambda_l2': 1.1069149246626646e-07, 'feature_fraction': 0.6680985288034066, 'bagging_fraction': 0.9009621460460905, 'bagging_freq': 5, 'min_data_in_leaf': 16, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:33,408]\u001b[0m Trial 195 finished with value: 0.9204851752021564 and parameters: {'learning_rate': 0.1, 'num_leaves': 1391, 'lambda_l1': 0.004707127898157001, 'lambda_l2': 1.967562186027067e-08, 'feature_fraction': 0.684406775976989, 'bagging_fraction': 0.3344865704909951, 'bagging_freq': 5, 'min_data_in_leaf': 10, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:33,819]\u001b[0m Trial 196 finished with value: 0.9097035040431267 and parameters: {'learning_rate': 0.1, 'num_leaves': 1417, 'lambda_l1': 0.0019027091525305676, 'lambda_l2': 3.000019343283165e-08, 'feature_fraction': 0.710646055817145, 'bagging_fraction': 0.8657800248543401, 'bagging_freq': 5, 'min_data_in_leaf': 14, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:34,125]\u001b[0m Trial 197 finished with value: 0.9110512129380054 and parameters: {'learning_rate': 0.1, 'num_leaves': 1335, 'lambda_l1': 0.06161038284754725, 'lambda_l2': 5.5902575973058176e-08, 'feature_fraction': 0.7236316289125696, 'bagging_fraction': 0.9196167619460945, 'bagging_freq': 5, 'min_data_in_leaf': 7, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:34,511]\u001b[0m Trial 198 finished with value: 0.9110512129380054 and parameters: {'learning_rate': 0.05, 'num_leaves': 1472, 'lambda_l1': 0.006362981015255486, 'lambda_l2': 1.0198296013095619e-08, 'feature_fraction': 0.657442097687328, 'bagging_fraction': 0.8490321759520367, 'bagging_freq': 5, 'min_data_in_leaf': 12, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:34,793]\u001b[0m Trial 199 finished with value: 0.9353099730458221 and parameters: {'learning_rate': 0.1, 'num_leaves': 1263, 'lambda_l1': 0.0165860598924964, 'lambda_l2': 9.131840693439526e-08, 'feature_fraction': 0.6980467898873965, 'bagging_fraction': 0.8854033017175668, 'bagging_freq': 5, 'min_data_in_leaf': 18, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:35,111]\u001b[0m Trial 200 finished with value: 0.9245283018867925 and parameters: {'learning_rate': 0.1, 'num_leaves': 1296, 'lambda_l1': 0.026249551516038794, 'lambda_l2': 8.603460109997004e-08, 'feature_fraction': 0.6946068008874863, 'bagging_fraction': 0.8336002890558447, 'bagging_freq': 5, 'min_data_in_leaf': 17, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:35,355]\u001b[0m Trial 201 finished with value: 0.9366576819407009 and parameters: {'learning_rate': 0.1, 'num_leaves': 1294, 'lambda_l1': 0.015067089834757118, 'lambda_l2': 4.032923378823382e-08, 'feature_fraction': 0.6753049082929194, 'bagging_fraction': 0.8870144435861909, 'bagging_freq': 5, 'min_data_in_leaf': 15, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:35,617]\u001b[0m Trial 202 finished with value: 0.9258760107816711 and parameters: {'learning_rate': 0.1, 'num_leaves': 1292, 'lambda_l1': 0.016408949971918486, 'lambda_l2': 3.046638362754251e-08, 'feature_fraction': 0.6654317525078299, 'bagging_fraction': 0.884385897819525, 'bagging_freq': 5, 'min_data_in_leaf': 15, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:36,035]\u001b[0m Trial 203 finished with value: 0.8962264150943396 and parameters: {'learning_rate': 0.1, 'num_leaves': 1251, 'lambda_l1': 0.008987224816176354, 'lambda_l2': 4.650563867156804e-08, 'feature_fraction': 0.6848497238792624, 'bagging_fraction': 0.8707842784950575, 'bagging_freq': 5, 'min_data_in_leaf': 18, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:36,371]\u001b[0m Trial 204 finished with value: 0.9326145552560647 and parameters: {'learning_rate': 0.1, 'num_leaves': 1369, 'lambda_l1': 0.041296748812419445, 'lambda_l2': 1.2931704764238545e-07, 'feature_fraction': 0.7026579609430738, 'bagging_fraction': 0.9008114421552835, 'bagging_freq': 5, 'min_data_in_leaf': 10, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:36,780]\u001b[0m Trial 205 finished with value: 0.9258760107816711 and parameters: {'learning_rate': 0.1, 'num_leaves': 1313, 'lambda_l1': 0.01697852189783939, 'lambda_l2': 1.874051864947053e-08, 'feature_fraction': 0.6466499887530883, 'bagging_fraction': 0.8789421841891172, 'bagging_freq': 5, 'min_data_in_leaf': 13, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:37,271]\u001b[0m Trial 206 finished with value: 0.8975741239892183 and parameters: {'learning_rate': 0.025, 'num_leaves': 1419, 'lambda_l1': 0.0027459771288933952, 'lambda_l2': 7.151907897539699e-08, 'feature_fraction': 0.6752161507058836, 'bagging_fraction': 0.8560595041629006, 'bagging_freq': 5, 'min_data_in_leaf': 8, 'extra_trees': True}. Best is trial 162 with value: 0.9528301886792454.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:37,736]\u001b[0m Trial 207 finished with value: 0.9595687331536389 and parameters: {'learning_rate': 0.1, 'num_leaves': 1344, 'lambda_l1': 0.012237145687772776, 'lambda_l2': 4.535434581882262e-08, 'feature_fraction': 0.7112946244810727, 'bagging_fraction': 0.9072766957036704, 'bagging_freq': 5, 'min_data_in_leaf': 5, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:38,281]\u001b[0m Trial 208 finished with value: 0.9299191374663074 and parameters: {'learning_rate': 0.1, 'num_leaves': 1366, 'lambda_l1': 0.005582529735183347, 'lambda_l2': 4.077554813222546e-08, 'feature_fraction': 0.7183136238236144, 'bagging_fraction': 0.9141692752783354, 'bagging_freq': 5, 'min_data_in_leaf': 4, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:38,831]\u001b[0m Trial 209 finished with value: 0.9137466307277629 and parameters: {'learning_rate': 0.05, 'num_leaves': 1325, 'lambda_l1': 0.01052409755654648, 'lambda_l2': 1.4815945933349898e-08, 'feature_fraction': 0.6285941533461983, 'bagging_fraction': 0.9048674656659763, 'bagging_freq': 5, 'min_data_in_leaf': 6, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:39,468]\u001b[0m Trial 210 finished with value: 0.931266846361186 and parameters: {'learning_rate': 0.1, 'num_leaves': 1526, 'lambda_l1': 0.003997298831800186, 'lambda_l2': 3.8607252429944366e-08, 'feature_fraction': 0.6756936031662343, 'bagging_fraction': 0.9219903110355766, 'bagging_freq': 5, 'min_data_in_leaf': 11, 'extra_trees': False}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:39,847]\u001b[0m Trial 211 finished with value: 0.9272237196765499 and parameters: {'learning_rate': 0.1, 'num_leaves': 1231, 'lambda_l1': 0.022052952378053936, 'lambda_l2': 1.0692186128477881e-07, 'feature_fraction': 0.6976078525466299, 'bagging_fraction': 0.8905369393729988, 'bagging_freq': 5, 'min_data_in_leaf': 9, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:40,177]\u001b[0m Trial 212 finished with value: 0.9339622641509434 and parameters: {'learning_rate': 0.1, 'num_leaves': 1272, 'lambda_l1': 0.008684599938862095, 'lambda_l2': 2.506768167353311e-08, 'feature_fraction': 0.6899954906749604, 'bagging_fraction': 0.8757839821734777, 'bagging_freq': 5, 'min_data_in_leaf': 15, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:40,463]\u001b[0m Trial 213 finished with value: 0.917789757412399 and parameters: {'learning_rate': 0.1, 'num_leaves': 1335, 'lambda_l1': 0.005819596451776574, 'lambda_l2': 5.717557087559065e-08, 'feature_fraction': 0.7065362334235236, 'bagging_fraction': 0.8946977151374372, 'bagging_freq': 5, 'min_data_in_leaf': 19, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:40,871]\u001b[0m Trial 214 finished with value: 0.9353099730458222 and parameters: {'learning_rate': 0.1, 'num_leaves': 1444, 'lambda_l1': 0.011620882011113708, 'lambda_l2': 8.550327602274572e-08, 'feature_fraction': 0.6611431741660672, 'bagging_fraction': 0.9084868109553198, 'bagging_freq': 5, 'min_data_in_leaf': 5, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:41,371]\u001b[0m Trial 215 finished with value: 0.9164420485175203 and parameters: {'learning_rate': 0.1, 'num_leaves': 1487, 'lambda_l1': 0.0029144586486345115, 'lambda_l2': 4.372796867285878e-08, 'feature_fraction': 0.6624281947286411, 'bagging_fraction': 0.9448613206481263, 'bagging_freq': 5, 'min_data_in_leaf': 5, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:41,889]\u001b[0m Trial 216 finished with value: 0.9191374663072777 and parameters: {'learning_rate': 0.1, 'num_leaves': 1404, 'lambda_l1': 0.012504147251606906, 'lambda_l2': 1.666938524529804e-07, 'feature_fraction': 0.6440074920221442, 'bagging_fraction': 0.9099632385394313, 'bagging_freq': 5, 'min_data_in_leaf': 3, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:42,492]\u001b[0m Trial 217 finished with value: 0.931266846361186 and parameters: {'learning_rate': 0.1, 'num_leaves': 1452, 'lambda_l1': 0.00012134532514360271, 'lambda_l2': 3.050702192856849e-08, 'feature_fraction': 0.6787186537833875, 'bagging_fraction': 0.9337906935041117, 'bagging_freq': 5, 'min_data_in_leaf': 7, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:43,779]\u001b[0m Trial 218 finished with value: 0.9029649595687332 and parameters: {'learning_rate': 0.0125, 'num_leaves': 1372, 'lambda_l1': 0.00028630218459899906, 'lambda_l2': 2.080797822036293e-05, 'feature_fraction': 0.7296044291314523, 'bagging_fraction': 0.9195282338662624, 'bagging_freq': 5, 'min_data_in_leaf': 2, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:44,106]\u001b[0m Trial 219 finished with value: 0.9029649595687331 and parameters: {'learning_rate': 0.1, 'num_leaves': 1431, 'lambda_l1': 0.030422675682770683, 'lambda_l2': 6.644521183240063e-08, 'feature_fraction': 0.7148619520825996, 'bagging_fraction': 0.9829016218353168, 'bagging_freq': 5, 'min_data_in_leaf': 6, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:44,401]\u001b[0m Trial 220 finished with value: 0.9191374663072777 and parameters: {'learning_rate': 0.1, 'num_leaves': 831, 'lambda_l1': 0.0076041927857471835, 'lambda_l2': 0.00010563089706679092, 'feature_fraction': 0.66051896966367, 'bagging_fraction': 0.8988372136178047, 'bagging_freq': 5, 'min_data_in_leaf': 11, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:44,651]\u001b[0m Trial 221 finished with value: 0.9204851752021563 and parameters: {'learning_rate': 0.1, 'num_leaves': 1299, 'lambda_l1': 0.014395675645983244, 'lambda_l2': 8.457508575975653e-08, 'feature_fraction': 0.6897052051312329, 'bagging_fraction': 0.8804867201728214, 'bagging_freq': 5, 'min_data_in_leaf': 17, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:44,958]\u001b[0m Trial 222 finished with value: 0.9029649595687331 and parameters: {'learning_rate': 0.1, 'num_leaves': 1205, 'lambda_l1': 0.021467474879350117, 'lambda_l2': 2.819184000731637e-07, 'feature_fraction': 0.677438509577709, 'bagging_fraction': 0.8906286985832692, 'bagging_freq': 5, 'min_data_in_leaf': 9, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:45,223]\u001b[0m Trial 223 finished with value: 0.931266846361186 and parameters: {'learning_rate': 0.1, 'num_leaves': 1259, 'lambda_l1': 0.011044390531206516, 'lambda_l2': 9.866052987391319e-08, 'feature_fraction': 0.7096838355175857, 'bagging_fraction': 0.8660308878741567, 'bagging_freq': 5, 'min_data_in_leaf': 14, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:45,637]\u001b[0m Trial 224 finished with value: 0.9258760107816711 and parameters: {'learning_rate': 0.1, 'num_leaves': 1514, 'lambda_l1': 0.014378791654816833, 'lambda_l2': 1.7947764127799233e-07, 'feature_fraction': 0.7316140467541032, 'bagging_fraction': 0.9105165116029976, 'bagging_freq': 5, 'min_data_in_leaf': 12, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:45,823]\u001b[0m Trial 225 finished with value: 0.8490566037735849 and parameters: {'learning_rate': 0.1, 'num_leaves': 1372, 'lambda_l1': 0.006129313896718417, 'lambda_l2': 2.1751585503133235e-08, 'feature_fraction': 0.683183684983553, 'bagging_fraction': 0.30032658263374795, 'bagging_freq': 5, 'min_data_in_leaf': 20, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:47,021]\u001b[0m Trial 226 finished with value: 0.9110512129380054 and parameters: {'learning_rate': 0.05, 'num_leaves': 1322, 'lambda_l1': 0.0001650017044557924, 'lambda_l2': 4.9526696749124065e-08, 'feature_fraction': 0.6962164772992057, 'bagging_fraction': 0.8421441693743343, 'bagging_freq': 5, 'min_data_in_leaf': 5, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:47,410]\u001b[0m Trial 227 finished with value: 0.9339622641509434 and parameters: {'learning_rate': 0.1, 'num_leaves': 798, 'lambda_l1': 0.0017901124732262572, 'lambda_l2': 1.315666587222154e-07, 'feature_fraction': 0.7743013644488301, 'bagging_fraction': 0.9294862303989868, 'bagging_freq': 5, 'min_data_in_leaf': 18, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:48,251]\u001b[0m Trial 228 finished with value: 0.9272237196765499 and parameters: {'learning_rate': 0.1, 'num_leaves': 1156, 'lambda_l1': 0.00045599026840557286, 'lambda_l2': 5.822422960968171e-06, 'feature_fraction': 0.6687859289083082, 'bagging_fraction': 0.8601513784598451, 'bagging_freq': 5, 'min_data_in_leaf': 1, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:48,501]\u001b[0m Trial 229 finished with value: 0.8975741239892183 and parameters: {'learning_rate': 0.1, 'num_leaves': 1251, 'lambda_l1': 0.0038947883432149883, 'lambda_l2': 4.3487172422010986e-07, 'feature_fraction': 0.7201376917728441, 'bagging_fraction': 0.6762621008038888, 'bagging_freq': 5, 'min_data_in_leaf': 16, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:49,570]\u001b[0m Trial 230 finished with value: 0.9177897574123989 and parameters: {'learning_rate': 0.05, 'num_leaves': 701, 'lambda_l1': 0.008649682878816595, 'lambda_l2': 3.3810924861697886e-08, 'feature_fraction': 0.6506626979949889, 'bagging_fraction': 0.9468414543812039, 'bagging_freq': 6, 'min_data_in_leaf': 8, 'extra_trees': False}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:49,834]\u001b[0m Trial 231 finished with value: 0.9110512129380054 and parameters: {'learning_rate': 0.1, 'num_leaves': 572, 'lambda_l1': 0.046400589472415196, 'lambda_l2': 7.268787078279008e-08, 'feature_fraction': 0.7388089776780814, 'bagging_fraction': 0.9353918351411417, 'bagging_freq': 5, 'min_data_in_leaf': 13, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:50,082]\u001b[0m Trial 232 finished with value: 0.9164420485175203 and parameters: {'learning_rate': 0.1, 'num_leaves': 795, 'lambda_l1': 0.0032412646456317596, 'lambda_l2': 1.3195272896563287e-07, 'feature_fraction': 0.775161610249024, 'bagging_fraction': 0.9235112887852249, 'bagging_freq': 5, 'min_data_in_leaf': 19, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:50,364]\u001b[0m Trial 233 finished with value: 0.9460916442048518 and parameters: {'learning_rate': 0.1, 'num_leaves': 779, 'lambda_l1': 0.0018369217908592093, 'lambda_l2': 2.3517061971241175e-07, 'feature_fraction': 0.7908616208136117, 'bagging_fraction': 0.9041022198533999, 'bagging_freq': 5, 'min_data_in_leaf': 18, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:50,599]\u001b[0m Trial 234 finished with value: 0.908355795148248 and parameters: {'learning_rate': 0.1, 'num_leaves': 757, 'lambda_l1': 0.0018729082906711182, 'lambda_l2': 2.4500291032805264e-07, 'feature_fraction': 0.7948357156470937, 'bagging_fraction': 0.903054463144713, 'bagging_freq': 5, 'min_data_in_leaf': 21, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:51,114]\u001b[0m Trial 235 finished with value: 0.9474393530997305 and parameters: {'learning_rate': 0.1, 'num_leaves': 1297, 'lambda_l1': 0.0012639492621360094, 'lambda_l2': 3.3065438826391953e-07, 'feature_fraction': 0.7633043041087931, 'bagging_fraction': 0.8849479663944337, 'bagging_freq': 5, 'min_data_in_leaf': 15, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:51,704]\u001b[0m Trial 236 finished with value: 0.9204851752021563 and parameters: {'learning_rate': 0.1, 'num_leaves': 1341, 'lambda_l1': 0.000989991358358261, 'lambda_l2': 3.5823323516824534e-07, 'feature_fraction': 0.7669960457255699, 'bagging_fraction': 0.9079017461424909, 'bagging_freq': 5, 'min_data_in_leaf': 15, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:52,194]\u001b[0m Trial 237 finished with value: 0.9582210242587602 and parameters: {'learning_rate': 0.1, 'num_leaves': 1404, 'lambda_l1': 0.0021056973397413957, 'lambda_l2': 5.117017170779247e-07, 'feature_fraction': 0.7860361071831647, 'bagging_fraction': 0.8889840577918624, 'bagging_freq': 5, 'min_data_in_leaf': 11, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:52,614]\u001b[0m Trial 238 finished with value: 0.921832884097035 and parameters: {'learning_rate': 0.1, 'num_leaves': 834, 'lambda_l1': 0.0011633658624605058, 'lambda_l2': 5.987543263663544e-07, 'feature_fraction': 0.7878434316968583, 'bagging_fraction': 0.8794515305383427, 'bagging_freq': 5, 'min_data_in_leaf': 11, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:52,804]\u001b[0m Trial 239 finished with value: 0.9070080862533693 and parameters: {'learning_rate': 0.1, 'num_leaves': 725, 'lambda_l1': 0.001478902261878429, 'lambda_l2': 8.402151698472717e-07, 'feature_fraction': 0.7513448037233947, 'bagging_fraction': 0.35810078367446596, 'bagging_freq': 5, 'min_data_in_leaf': 14, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:53,513]\u001b[0m Trial 240 finished with value: 0.9460916442048518 and parameters: {'learning_rate': 0.05, 'num_leaves': 1392, 'lambda_l1': 0.0006432667541150178, 'lambda_l2': 3.306154195873395e-07, 'feature_fraction': 0.8053870782020641, 'bagging_fraction': 0.8957924726474606, 'bagging_freq': 5, 'min_data_in_leaf': 13, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:54,118]\u001b[0m Trial 241 finished with value: 0.9555256064690028 and parameters: {'learning_rate': 0.05, 'num_leaves': 1407, 'lambda_l1': 0.0006871813048215593, 'lambda_l2': 3.6519471643151454e-07, 'feature_fraction': 0.7827937588688416, 'bagging_fraction': 0.8949634816405263, 'bagging_freq': 5, 'min_data_in_leaf': 13, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:54,625]\u001b[0m Trial 242 finished with value: 0.9110512129380054 and parameters: {'learning_rate': 0.05, 'num_leaves': 1368, 'lambda_l1': 0.0005731954218800656, 'lambda_l2': 5.092883538746387e-07, 'feature_fraction': 0.8008513043520441, 'bagging_fraction': 0.8893361389012548, 'bagging_freq': 5, 'min_data_in_leaf': 16, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:55,076]\u001b[0m Trial 243 finished with value: 0.9258760107816711 and parameters: {'learning_rate': 0.05, 'num_leaves': 1305, 'lambda_l1': 0.00047910058342608543, 'lambda_l2': 3.5785808030303755e-07, 'feature_fraction': 0.8082494937127576, 'bagging_fraction': 0.8950132638524564, 'bagging_freq': 5, 'min_data_in_leaf': 10, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:55,768]\u001b[0m Trial 244 finished with value: 0.9016172506738545 and parameters: {'learning_rate': 0.05, 'num_leaves': 1032, 'lambda_l1': 0.0006627905896565415, 'lambda_l2': 3.082419431838309e-07, 'feature_fraction': 0.7817624766851775, 'bagging_fraction': 0.8620921091929407, 'bagging_freq': 5, 'min_data_in_leaf': 14, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:56,228]\u001b[0m Trial 245 finished with value: 0.9258760107816713 and parameters: {'learning_rate': 0.05, 'num_leaves': 1407, 'lambda_l1': 0.000882222799751976, 'lambda_l2': 2.204143876038617e-07, 'feature_fraction': 0.787654952504296, 'bagging_fraction': 0.8787527031148763, 'bagging_freq': 5, 'min_data_in_leaf': 12, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:56,769]\u001b[0m Trial 246 finished with value: 0.9231805929919138 and parameters: {'learning_rate': 0.05, 'num_leaves': 768, 'lambda_l1': 0.00028850794175804744, 'lambda_l2': 5.432569999800323e-07, 'feature_fraction': 0.7671723814267406, 'bagging_fraction': 0.8967113396043345, 'bagging_freq': 5, 'min_data_in_leaf': 16, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:57,241]\u001b[0m Trial 247 finished with value: 0.9407008086253369 and parameters: {'learning_rate': 0.05, 'num_leaves': 1358, 'lambda_l1': 0.0023572641010388322, 'lambda_l2': 8.199155522941524e-07, 'feature_fraction': 0.307293269512213, 'bagging_fraction': 0.8715676713601311, 'bagging_freq': 5, 'min_data_in_leaf': 9, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:57,822]\u001b[0m Trial 248 finished with value: 0.9056603773584906 and parameters: {'learning_rate': 0.05, 'num_leaves': 1349, 'lambda_l1': 0.0013763785687055494, 'lambda_l2': 1.3377939931255043e-06, 'feature_fraction': 0.32011231132214246, 'bagging_fraction': 0.851354733191988, 'bagging_freq': 5, 'min_data_in_leaf': 8, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:58,279]\u001b[0m Trial 249 finished with value: 0.9137466307277629 and parameters: {'learning_rate': 0.05, 'num_leaves': 1474, 'lambda_l1': 0.0023828107505025845, 'lambda_l2': 8.904333651759634e-07, 'feature_fraction': 0.3663031128751397, 'bagging_fraction': 0.9574698733803575, 'bagging_freq': 5, 'min_data_in_leaf': 10, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:58,587]\u001b[0m Trial 250 finished with value: 0.8975741239892184 and parameters: {'learning_rate': 0.05, 'num_leaves': 1398, 'lambda_l1': 0.002154530914340642, 'lambda_l2': 7.27974198962906e-07, 'feature_fraction': 0.7798070130262255, 'bagging_fraction': 0.8673235152042373, 'bagging_freq': 5, 'min_data_in_leaf': 13, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:52:59,534]\u001b[0m Trial 251 finished with value: 0.9258760107816713 and parameters: {'learning_rate': 0.05, 'num_leaves': 705, 'lambda_l1': 0.000801657781149025, 'lambda_l2': 4.6840419107184014e-07, 'feature_fraction': 0.8114215969360774, 'bagging_fraction': 0.9806756846265781, 'bagging_freq': 5, 'min_data_in_leaf': 11, 'extra_trees': False}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:00,026]\u001b[0m Trial 252 finished with value: 0.908355795148248 and parameters: {'learning_rate': 0.05, 'num_leaves': 1320, 'lambda_l1': 0.002663872815122527, 'lambda_l2': 3.3255534477033634e-07, 'feature_fraction': 0.47963995824904193, 'bagging_fraction': 0.873501155168118, 'bagging_freq': 5, 'min_data_in_leaf': 9, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:00,380]\u001b[0m Trial 253 finished with value: 0.9150943396226415 and parameters: {'learning_rate': 0.05, 'num_leaves': 1910, 'lambda_l1': 0.001414583093395456, 'lambda_l2': 2.622811510510594e-07, 'feature_fraction': 0.759554403792592, 'bagging_fraction': 0.9164655140634899, 'bagging_freq': 5, 'min_data_in_leaf': 22, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:00,725]\u001b[0m Trial 254 finished with value: 0.9245283018867925 and parameters: {'learning_rate': 0.05, 'num_leaves': 787, 'lambda_l1': 0.0001941237952314869, 'lambda_l2': 4.668079666001029e-07, 'feature_fraction': 0.7938166677305966, 'bagging_fraction': 0.8125945889738961, 'bagging_freq': 6, 'min_data_in_leaf': 20, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:00,954]\u001b[0m Trial 255 finished with value: 0.8827493261455526 and parameters: {'learning_rate': 0.05, 'num_leaves': 1450, 'lambda_l1': 0.00010900292873576298, 'lambda_l2': 2.375610787338783e-07, 'feature_fraction': 0.8293528974430474, 'bagging_fraction': 0.3165277703390002, 'bagging_freq': 5, 'min_data_in_leaf': 13, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:01,636]\u001b[0m Trial 256 finished with value: 0.9204851752021563 and parameters: {'learning_rate': 0.05, 'num_leaves': 667, 'lambda_l1': 0.00045017601819021647, 'lambda_l2': 6.460806019099134e-07, 'feature_fraction': 0.43226169943862863, 'bagging_fraction': 0.9021275046889936, 'bagging_freq': 5, 'min_data_in_leaf': 7, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:02,138]\u001b[0m Trial 257 finished with value: 0.9245283018867925 and parameters: {'learning_rate': 0.025, 'num_leaves': 868, 'lambda_l1': 0.0010094258221262063, 'lambda_l2': 1.7951474021264795e-07, 'feature_fraction': 0.7697436233571637, 'bagging_fraction': 0.9924404269951502, 'bagging_freq': 2, 'min_data_in_leaf': 10, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:02,631]\u001b[0m Trial 258 finished with value: 0.9258760107816711 and parameters: {'learning_rate': 0.05, 'num_leaves': 1371, 'lambda_l1': 0.0034158858619402726, 'lambda_l2': 1.2161013340840086e-06, 'feature_fraction': 0.7859083396634016, 'bagging_fraction': 0.8861045360045054, 'bagging_freq': 7, 'min_data_in_leaf': 14, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:03,004]\u001b[0m Trial 259 finished with value: 0.9218328840970351 and parameters: {'learning_rate': 0.0125, 'num_leaves': 1283, 'lambda_l1': 0.0017099523885688304, 'lambda_l2': 4.317005203609349e-07, 'feature_fraction': 0.7443314835494838, 'bagging_fraction': 0.8348016920985514, 'bagging_freq': 5, 'min_data_in_leaf': 17, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:03,531]\u001b[0m Trial 260 finished with value: 0.9164420485175202 and parameters: {'learning_rate': 0.05, 'num_leaves': 1416, 'lambda_l1': 0.00030333226227145343, 'lambda_l2': 2.029632082393326e-07, 'feature_fraction': 0.753416722275334, 'bagging_fraction': 0.970831165879694, 'bagging_freq': 5, 'min_data_in_leaf': 12, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:03,784]\u001b[0m Trial 261 finished with value: 0.921832884097035 and parameters: {'learning_rate': 0.1, 'num_leaves': 1211, 'lambda_l1': 3.303043680092815e-07, 'lambda_l2': 1.4782446903655839e-08, 'feature_fraction': 0.7953843837194048, 'bagging_fraction': 0.5500910176205751, 'bagging_freq': 5, 'min_data_in_leaf': 15, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:04,693]\u001b[0m Trial 262 finished with value: 0.9043126684636118 and parameters: {'learning_rate': 0.05, 'num_leaves': 1311, 'lambda_l1': 0.0055705878258978095, 'lambda_l2': 8.674570091072699e-07, 'feature_fraction': 0.7754692383610261, 'bagging_fraction': 0.8514930979468014, 'bagging_freq': 5, 'min_data_in_leaf': 3, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:05,038]\u001b[0m Trial 263 finished with value: 0.8935309973045823 and parameters: {'learning_rate': 0.1, 'num_leaves': 1065, 'lambda_l1': 0.0007216334927094297, 'lambda_l2': 0.10982373299338608, 'feature_fraction': 0.5443532084268906, 'bagging_fraction': 0.38595675437945715, 'bagging_freq': 5, 'min_data_in_leaf': 9, 'extra_trees': False}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:05,274]\u001b[0m Trial 264 finished with value: 0.9123989218328841 and parameters: {'learning_rate': 0.1, 'num_leaves': 42, 'lambda_l1': 0.0021140426928692646, 'lambda_l2': 3.3189714231450763e-07, 'feature_fraction': 0.8161521902054123, 'bagging_fraction': 0.8895390797243654, 'bagging_freq': 5, 'min_data_in_leaf': 76, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:05,401]\u001b[0m Trial 265 finished with value: 0.8281671159029649 and parameters: {'learning_rate': 0.1, 'num_leaves': 1004, 'lambda_l1': 9.103164325335452, 'lambda_l2': 2.3461988009744196e-08, 'feature_fraction': 0.761967118537827, 'bagging_fraction': 0.8635456298526608, 'bagging_freq': 5, 'min_data_in_leaf': 16, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:06,081]\u001b[0m Trial 266 finished with value: 0.9245283018867925 and parameters: {'learning_rate': 0.05, 'num_leaves': 1287, 'lambda_l1': 0.001167695081946039, 'lambda_l2': 2.1309473251201712e-07, 'feature_fraction': 0.800261718176501, 'bagging_fraction': 0.8781037529444958, 'bagging_freq': 5, 'min_data_in_leaf': 13, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:06,364]\u001b[0m Trial 267 finished with value: 0.9164420485175202 and parameters: {'learning_rate': 0.1, 'num_leaves': 1340, 'lambda_l1': 3.7851433818707995e-06, 'lambda_l2': 1.7487106517759064e-06, 'feature_fraction': 0.7363308921468977, 'bagging_fraction': 0.9058463116151103, 'bagging_freq': 6, 'min_data_in_leaf': 18, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:06,696]\u001b[0m Trial 268 finished with value: 0.9218328840970351 and parameters: {'learning_rate': 0.1, 'num_leaves': 739, 'lambda_l1': 0.00020930822887220554, 'lambda_l2': 5.402974128978183e-07, 'feature_fraction': 0.772245304021508, 'bagging_fraction': 0.7409697141059006, 'bagging_freq': 5, 'min_data_in_leaf': 21, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:07,048]\u001b[0m Trial 269 finished with value: 0.931266846361186 and parameters: {'learning_rate': 0.1, 'num_leaves': 1238, 'lambda_l1': 0.005087321619147154, 'lambda_l2': 1.6103728023363801, 'feature_fraction': 0.8414398840712451, 'bagging_fraction': 0.9526871388750615, 'bagging_freq': 5, 'min_data_in_leaf': 11, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:07,423]\u001b[0m Trial 270 finished with value: 0.9191374663072778 and parameters: {'learning_rate': 0.05, 'num_leaves': 820, 'lambda_l1': 0.0034734014956067623, 'lambda_l2': 1.7964355483496278e-08, 'feature_fraction': 0.7138329053585283, 'bagging_fraction': 0.8726715038606371, 'bagging_freq': 5, 'min_data_in_leaf': 15, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:08,107]\u001b[0m Trial 271 finished with value: 0.9204851752021563 and parameters: {'learning_rate': 0.1, 'num_leaves': 1113, 'lambda_l1': 8.13866676139712e-05, 'lambda_l2': 1.4164693740051776e-07, 'feature_fraction': 0.7538732946931923, 'bagging_fraction': 0.930497822889747, 'bagging_freq': 4, 'min_data_in_leaf': 7, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:08,373]\u001b[0m Trial 272 finished with value: 0.8867924528301887 and parameters: {'learning_rate': 0.025, 'num_leaves': 768, 'lambda_l1': 0.00032861768698304187, 'lambda_l2': 5.3285845418208044e-05, 'feature_fraction': 0.7832876232457633, 'bagging_fraction': 0.9412716246815764, 'bagging_freq': 5, 'min_data_in_leaf': 20, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:09,110]\u001b[0m Trial 273 finished with value: 0.9312668463611861 and parameters: {'learning_rate': 0.1, 'num_leaves': 638, 'lambda_l1': 4.642480153725171e-05, 'lambda_l2': 6.927452843826255e-07, 'feature_fraction': 0.7684740672482198, 'bagging_fraction': 0.9181371478189796, 'bagging_freq': 5, 'min_data_in_leaf': 4, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:09,678]\u001b[0m Trial 274 finished with value: 0.8935309973045823 and parameters: {'learning_rate': 0.1, 'num_leaves': 1375, 'lambda_l1': 0.008155100085320294, 'lambda_l2': 3.1102675650375054e-08, 'feature_fraction': 0.7040964036690573, 'bagging_fraction': 0.48863286683359647, 'bagging_freq': 5, 'min_data_in_leaf': 12, 'extra_trees': False}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:09,852]\u001b[0m Trial 275 finished with value: 0.8867924528301887 and parameters: {'learning_rate': 0.05, 'num_leaves': 703, 'lambda_l1': 0.00014383548099784394, 'lambda_l2': 2.982398338439724e-07, 'feature_fraction': 0.7250977174456592, 'bagging_fraction': 0.6428534886562818, 'bagging_freq': 4, 'min_data_in_leaf': 18, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:10,124]\u001b[0m Trial 276 finished with value: 0.9070080862533694 and parameters: {'learning_rate': 0.1, 'num_leaves': 1563, 'lambda_l1': 0.0026841579366632764, 'lambda_l2': 0.000192302386365528, 'feature_fraction': 0.7452996666122548, 'bagging_fraction': 0.9043087215927019, 'bagging_freq': 4, 'min_data_in_leaf': 23, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:10,964]\u001b[0m Trial 277 finished with value: 0.8962264150943396 and parameters: {'learning_rate': 0.1, 'num_leaves': 824, 'lambda_l1': 0.00044572099861064153, 'lambda_l2': 1.4262883838302332e-07, 'feature_fraction': 0.8049207884295482, 'bagging_fraction': 0.959360685775992, 'bagging_freq': 5, 'min_data_in_leaf': 1, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:11,376]\u001b[0m Trial 278 finished with value: 0.9204851752021563 and parameters: {'learning_rate': 0.05, 'num_leaves': 1419, 'lambda_l1': 0.0005798561330950176, 'lambda_l2': 5.63627352677524e-08, 'feature_fraction': 0.7869939180877763, 'bagging_fraction': 0.9274775371473476, 'bagging_freq': 5, 'min_data_in_leaf': 9, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:11,660]\u001b[0m Trial 279 finished with value: 0.9016172506738545 and parameters: {'learning_rate': 0.1, 'num_leaves': 862, 'lambda_l1': 3.2941437103754345, 'lambda_l2': 3.6503300324486814e-07, 'feature_fraction': 0.7640011264734708, 'bagging_fraction': 0.8962480824324778, 'bagging_freq': 5, 'min_data_in_leaf': 6, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:11,968]\u001b[0m Trial 280 finished with value: 0.9056603773584906 and parameters: {'learning_rate': 0.0125, 'num_leaves': 761, 'lambda_l1': 0.0015544275839408114, 'lambda_l2': 9.774630276329985e-07, 'feature_fraction': 0.7778476677536464, 'bagging_fraction': 0.9733280760255946, 'bagging_freq': 5, 'min_data_in_leaf': 21, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:12,268]\u001b[0m Trial 281 finished with value: 0.9164420485175202 and parameters: {'learning_rate': 0.1, 'num_leaves': 1478, 'lambda_l1': 2.030803045849824e-06, 'lambda_l2': 1.0296316160668859e-08, 'feature_fraction': 0.7308455533336187, 'bagging_fraction': 0.914332292739899, 'bagging_freq': 5, 'min_data_in_leaf': 10, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:12,656]\u001b[0m Trial 282 finished with value: 0.9043126684636119 and parameters: {'learning_rate': 0.1, 'num_leaves': 1333, 'lambda_l1': 1.2620957732176102e-05, 'lambda_l2': 4.0481548133232e-06, 'feature_fraction': 0.6967530879566025, 'bagging_fraction': 0.8869073183270325, 'bagging_freq': 5, 'min_data_in_leaf': 14, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:12,868]\u001b[0m Trial 283 finished with value: 0.8814016172506739 and parameters: {'learning_rate': 0.05, 'num_leaves': 1201, 'lambda_l1': 0.0045330935052282795, 'lambda_l2': 2.731247062494503e-08, 'feature_fraction': 0.7159592208975389, 'bagging_fraction': 0.5181280637950303, 'bagging_freq': 4, 'min_data_in_leaf': 17, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:13,329]\u001b[0m Trial 284 finished with value: 0.9123989218328842 and parameters: {'learning_rate': 0.1, 'num_leaves': 1390, 'lambda_l1': 0.021517513335542717, 'lambda_l2': 5.013304992169755e-08, 'feature_fraction': 0.6876183537088097, 'bagging_fraction': 0.8406132113237111, 'bagging_freq': 5, 'min_data_in_leaf': 12, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:14,254]\u001b[0m Trial 285 finished with value: 0.9326145552560647 and parameters: {'learning_rate': 0.1, 'num_leaves': 668, 'lambda_l1': 0.0007513509110813574, 'lambda_l2': 1.119013260792544e-07, 'feature_fraction': 0.7524431284121681, 'bagging_fraction': 0.9990181818708814, 'bagging_freq': 5, 'min_data_in_leaf': 8, 'extra_trees': False}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:14,572]\u001b[0m Trial 286 finished with value: 0.9002695417789758 and parameters: {'learning_rate': 0.05, 'num_leaves': 731, 'lambda_l1': 0.000232436239409922, 'lambda_l2': 1.9377882233100414e-07, 'feature_fraction': 0.7595949923805757, 'bagging_fraction': 0.4544299304798114, 'bagging_freq': 6, 'min_data_in_leaf': 24, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:14,790]\u001b[0m Trial 287 finished with value: 0.894878706199461 and parameters: {'learning_rate': 0.1, 'num_leaves': 221, 'lambda_l1': 0.0071670735179239576, 'lambda_l2': 1.808813068712723e-08, 'feature_fraction': 0.8234087456801048, 'bagging_fraction': 0.8542539090671978, 'bagging_freq': 1, 'min_data_in_leaf': 65, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:15,402]\u001b[0m Trial 288 finished with value: 0.9123989218328841 and parameters: {'learning_rate': 0.1, 'num_leaves': 969, 'lambda_l1': 9.382494417261173e-05, 'lambda_l2': 2.632624431722624e-06, 'feature_fraction': 0.7921003057475919, 'bagging_fraction': 0.9308663275996885, 'bagging_freq': 4, 'min_data_in_leaf': 4, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:15,572]\u001b[0m Trial 289 finished with value: 0.8504043126684636 and parameters: {'learning_rate': 0.05, 'num_leaves': 1276, 'lambda_l1': 0.0022343977043568376, 'lambda_l2': 3.749286119716781e-08, 'feature_fraction': 0.3780291431116716, 'bagging_fraction': 0.3400823477312158, 'bagging_freq': 5, 'min_data_in_leaf': 16, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:15,848]\u001b[0m Trial 290 finished with value: 0.9123989218328842 and parameters: {'learning_rate': 0.1, 'num_leaves': 1086, 'lambda_l1': 0.00015592178178318693, 'lambda_l2': 7.032745016133079e-08, 'feature_fraction': 0.7779501662627405, 'bagging_fraction': 0.9457313448577015, 'bagging_freq': 5, 'min_data_in_leaf': 19, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:16,104]\u001b[0m Trial 291 finished with value: 0.9420485175202157 and parameters: {'learning_rate': 0.1, 'num_leaves': 1356, 'lambda_l1': 0.0012619922565893357, 'lambda_l2': 3.314848488470813e-07, 'feature_fraction': 0.7058801038030519, 'bagging_fraction': 0.6183484863049907, 'bagging_freq': 5, 'min_data_in_leaf': 13, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:16,308]\u001b[0m Trial 292 finished with value: 0.9191374663072777 and parameters: {'learning_rate': 0.1, 'num_leaves': 1437, 'lambda_l1': 0.0011986377440696954, 'lambda_l2': 4.580467256348007e-07, 'feature_fraction': 0.7092782452822568, 'bagging_fraction': 0.5807995212117703, 'bagging_freq': 5, 'min_data_in_leaf': 11, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:16,714]\u001b[0m Trial 293 finished with value: 0.9231805929919137 and parameters: {'learning_rate': 0.05, 'num_leaves': 1357, 'lambda_l1': 0.001603016455922193, 'lambda_l2': 3.117929688835187e-07, 'feature_fraction': 0.7236644473592062, 'bagging_fraction': 0.8687274314992782, 'bagging_freq': 5, 'min_data_in_leaf': 13, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:17,281]\u001b[0m Trial 294 finished with value: 0.9137466307277629 and parameters: {'learning_rate': 0.1, 'num_leaves': 1338, 'lambda_l1': 0.0012053213461011342, 'lambda_l2': 5.116410243156606e-07, 'feature_fraction': 0.7395993189696518, 'bagging_fraction': 0.6061144958603202, 'bagging_freq': 5, 'min_data_in_leaf': 8, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:17,649]\u001b[0m Trial 295 finished with value: 0.9123989218328842 and parameters: {'learning_rate': 0.1, 'num_leaves': 1398, 'lambda_l1': 0.0029334067141910244, 'lambda_l2': 2.880369362759608e-07, 'feature_fraction': 0.7022236619439585, 'bagging_fraction': 0.9826873800013407, 'bagging_freq': 4, 'min_data_in_leaf': 10, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:17,867]\u001b[0m Trial 296 finished with value: 0.9043126684636119 and parameters: {'learning_rate': 0.05, 'num_leaves': 1135, 'lambda_l1': 0.0008664582883823321, 'lambda_l2': 6.811790815600568e-07, 'feature_fraction': 0.8747842934378832, 'bagging_fraction': 0.6368848028138707, 'bagging_freq': 5, 'min_data_in_leaf': 14, 'extra_trees': True}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:53:18,396]\u001b[0m Trial 297 finished with value: 0.931266846361186 and parameters: {'learning_rate': 0.1, 'num_leaves': 1442, 'lambda_l1': 0.0043756936638539076, 'lambda_l2': 1.834872263007261e-07, 'feature_fraction': 0.8052906922122565, 'bagging_fraction': 0.8941281171147912, 'bagging_freq': 5, 'min_data_in_leaf': 12, 'extra_trees': False}. Best is trial 207 with value: 0.9595687331536389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_Optuna_LightGBM auc 0.925483 trained in 16.86 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-13 17:53:54,686]\u001b[0m A new study created in memory with name: no-name-355ffba7-008d-45b0-aaf7-98c32447fc98\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:53:54,772]\u001b[0m Trial 0 finished with value: 0.5 and parameters: {'eta': 0.1, 'max_depth': 10, 'lambda': 2.840098794801191e-06, 'alpha': 3.0773599420974e-06, 'colsample_bytree': 0.8613105322932351, 'subsample': 0.970697557159987, 'min_child_weight': 88}. Best is trial 0 with value: 0.5.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:53:54,835]\u001b[0m Trial 1 finished with value: 0.5 and parameters: {'eta': 0.1, 'max_depth': 6, 'lambda': 0.0011239983523033718, 'alpha': 0.0003370920325799477, 'colsample_bytree': 0.30963791485116204, 'subsample': 0.8409786428569279, 'min_child_weight': 89}. Best is trial 0 with value: 0.5.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna optimizes Xgboost with time budget 120 seconds eval_metric auc (maximize)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:53:54,901]\u001b[0m Trial 2 finished with value: 0.5 and parameters: {'eta': 0.025, 'max_depth': 12, 'lambda': 0.007284559400814385, 'alpha': 3.7568443272922285e-05, 'colsample_bytree': 0.8521111079458232, 'subsample': 0.521785288686571, 'min_child_weight': 57}. Best is trial 0 with value: 0.5.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:53:54,964]\u001b[0m Trial 3 finished with value: 0.5 and parameters: {'eta': 0.0125, 'max_depth': 9, 'lambda': 0.0219397550092062, 'alpha': 9.313843818151601e-07, 'colsample_bytree': 0.9474073492795716, 'subsample': 0.6094985332043311, 'min_child_weight': 91}. Best is trial 0 with value: 0.5.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:53:55,031]\u001b[0m Trial 4 finished with value: 0.5 and parameters: {'eta': 0.1, 'max_depth': 8, 'lambda': 0.0006306544535695586, 'alpha': 2.4542373674443895e-08, 'colsample_bytree': 0.6930031616587092, 'subsample': 0.5307679152313249, 'min_child_weight': 51}. Best is trial 0 with value: 0.5.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:53:55,097]\u001b[0m Trial 5 finished with value: 0.5 and parameters: {'eta': 0.025, 'max_depth': 8, 'lambda': 1.6184749347769107, 'alpha': 0.13023184627242293, 'colsample_bytree': 0.9944570362526675, 'subsample': 0.971161243095024, 'min_child_weight': 80}. Best is trial 0 with value: 0.5.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:53:55,207]\u001b[0m Trial 6 finished with value: 0.7607816711590297 and parameters: {'eta': 0.025, 'max_depth': 6, 'lambda': 3.053958747167197e-08, 'alpha': 0.00011610092352478581, 'colsample_bytree': 0.9874033288854154, 'subsample': 0.38675989158030105, 'min_child_weight': 12}. Best is trial 6 with value: 0.7607816711590297.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:53:55,265]\u001b[0m Trial 7 finished with value: 0.5 and parameters: {'eta': 0.0125, 'max_depth': 4, 'lambda': 1.2580177056809037, 'alpha': 5.63354594007783e-05, 'colsample_bytree': 0.6750961691306476, 'subsample': 0.3043459616730757, 'min_child_weight': 31}. Best is trial 6 with value: 0.7607816711590297.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:53:55,332]\u001b[0m Trial 8 finished with value: 0.7890835579514824 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 2.2310198991638318e-07, 'alpha': 0.0518287437382714, 'colsample_bytree': 0.8817049030135462, 'subsample': 0.7436080446029429, 'min_child_weight': 44}. Best is trial 8 with value: 0.7890835579514824.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:53:55,392]\u001b[0m Trial 9 finished with value: 0.5 and parameters: {'eta': 0.1, 'max_depth': 7, 'lambda': 0.000333454106732101, 'alpha': 0.000679053100205625, 'colsample_bytree': 0.8734414551369314, 'subsample': 0.33998094723335825, 'min_child_weight': 67}. Best is trial 8 with value: 0.7890835579514824.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:53:55,513]\u001b[0m Trial 10 finished with value: 0.7749326145552561 and parameters: {'eta': 0.05, 'max_depth': 2, 'lambda': 1.129968440457033e-08, 'alpha': 6.304300823136307, 'colsample_bytree': 0.46185862758929475, 'subsample': 0.7497811559951773, 'min_child_weight': 30}. Best is trial 8 with value: 0.7890835579514824.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:53:55,766]\u001b[0m Trial 11 finished with value: 0.7911051212938006 and parameters: {'eta': 0.05, 'max_depth': 4, 'lambda': 1.19848870238316e-08, 'alpha': 4.820120091270145, 'colsample_bytree': 0.42312181204885746, 'subsample': 0.7693252025845119, 'min_child_weight': 29}. Best is trial 11 with value: 0.7911051212938006.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:53:55,880]\u001b[0m Trial 12 finished with value: 0.7884097035040432 and parameters: {'eta': 0.05, 'max_depth': 3, 'lambda': 1.3478645009577105e-06, 'alpha': 0.07794658589717099, 'colsample_bytree': 0.5370434850232896, 'subsample': 0.7613394868395501, 'min_child_weight': 32}. Best is trial 11 with value: 0.7911051212938006.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:53:56,585]\u001b[0m Trial 13 finished with value: 0.8881401617250674 and parameters: {'eta': 0.05, 'max_depth': 5, 'lambda': 1.012157391890201e-06, 'alpha': 4.391422273046873, 'colsample_bytree': 0.34090158770393614, 'subsample': 0.8298019055729193, 'min_child_weight': 4}. Best is trial 13 with value: 0.8881401617250674.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:53:57,174]\u001b[0m Trial 14 finished with value: 0.8261455525606469 and parameters: {'eta': 0.05, 'max_depth': 4, 'lambda': 1.421034713381549e-05, 'alpha': 9.76374674877772, 'colsample_bytree': 0.3027389470410028, 'subsample': 0.8673028106254809, 'min_child_weight': 1}. Best is trial 13 with value: 0.8881401617250674.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:53:58,298]\u001b[0m Trial 15 finished with value: 0.9043126684636119 and parameters: {'eta': 0.05, 'max_depth': 5, 'lambda': 1.6889230193613195e-05, 'alpha': 0.5426593932901372, 'colsample_bytree': 0.30771130792393997, 'subsample': 0.8848959233331424, 'min_child_weight': 1}. Best is trial 15 with value: 0.9043126684636119.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:53:58,633]\u001b[0m Trial 16 finished with value: 0.921832884097035 and parameters: {'eta': 0.05, 'max_depth': 6, 'lambda': 3.638698336534541e-05, 'alpha': 0.003982091389564138, 'colsample_bytree': 0.3996974735296909, 'subsample': 0.868868692303179, 'min_child_weight': 10}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:53:58,953]\u001b[0m Trial 17 finished with value: 0.8975741239892183 and parameters: {'eta': 0.05, 'max_depth': 6, 'lambda': 4.5929134221659266e-05, 'alpha': 0.005834296870271335, 'colsample_bytree': 0.5618515183296624, 'subsample': 0.9927049847286739, 'min_child_weight': 17}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:53:59,191]\u001b[0m Trial 18 finished with value: 0.8692722371967655 and parameters: {'eta': 0.05, 'max_depth': 2, 'lambda': 4.971769156955919e-05, 'alpha': 0.005564550993937411, 'colsample_bytree': 0.41170651996799346, 'subsample': 0.8874417774165988, 'min_child_weight': 16}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:53:59,325]\u001b[0m Trial 19 finished with value: 0.8025606469002695 and parameters: {'eta': 0.0125, 'max_depth': 5, 'lambda': 0.05776092845761888, 'alpha': 0.41728125134311744, 'colsample_bytree': 0.5728970088683478, 'subsample': 0.6709819882966864, 'min_child_weight': 20}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:53:59,738]\u001b[0m Trial 20 finished with value: 0.8962264150943395 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 8.027310631123728e-06, 'alpha': 0.006400622629184841, 'colsample_bytree': 0.38234400006334596, 'subsample': 0.894142723576974, 'min_child_weight': 6}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:53:59,899]\u001b[0m Trial 21 finished with value: 0.8288409703504043 and parameters: {'eta': 0.05, 'max_depth': 6, 'lambda': 6.0631664512719715e-05, 'alpha': 0.005446281981498009, 'colsample_bytree': 0.49663580439770183, 'subsample': 0.9827118405019306, 'min_child_weight': 21}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:00,320]\u001b[0m Trial 22 finished with value: 0.9110512129380054 and parameters: {'eta': 0.05, 'max_depth': 7, 'lambda': 6.259511935893797e-05, 'alpha': 0.6466570587326982, 'colsample_bytree': 0.6023509586171804, 'subsample': 0.9283215023683418, 'min_child_weight': 8}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:00,704]\u001b[0m Trial 23 finished with value: 0.9110512129380054 and parameters: {'eta': 0.05, 'max_depth': 7, 'lambda': 0.0029642188538671964, 'alpha': 0.5936251126452762, 'colsample_bytree': 0.7501674779721342, 'subsample': 0.9212996298249481, 'min_child_weight': 9}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:00,829]\u001b[0m Trial 24 finished with value: 0.8126684636118598 and parameters: {'eta': 0.05, 'max_depth': 7, 'lambda': 0.0029709733627894257, 'alpha': 0.6946590488180994, 'colsample_bytree': 0.7584691449574507, 'subsample': 0.9265133103776917, 'min_child_weight': 43}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:01,108]\u001b[0m Trial 25 finished with value: 0.8921832884097034 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 0.115600284575868, 'alpha': 0.02189833135428973, 'colsample_bytree': 0.628042060793195, 'subsample': 0.8009441390913297, 'min_child_weight': 13}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:01,264]\u001b[0m Trial 26 finished with value: 0.7964959568733154 and parameters: {'eta': 0.05, 'max_depth': 7, 'lambda': 0.00017381525917335358, 'alpha': 1.0037680586683948, 'colsample_bytree': 0.7633460035815176, 'subsample': 0.6865559624966983, 'min_child_weight': 24}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:01,835]\u001b[0m Trial 27 finished with value: 0.9002695417789758 and parameters: {'eta': 0.025, 'max_depth': 9, 'lambda': 0.003183039996378005, 'alpha': 0.0012825628399365165, 'colsample_bytree': 0.7386255475653988, 'subsample': 0.9296570953610523, 'min_child_weight': 10}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:02,078]\u001b[0m Trial 28 finished with value: 0.8086253369272237 and parameters: {'eta': 0.0125, 'max_depth': 7, 'lambda': 0.19414727716817082, 'alpha': 0.19461194542323054, 'colsample_bytree': 0.5944143562715349, 'subsample': 0.931462436337593, 'min_child_weight': 36}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:02,161]\u001b[0m Trial 29 finished with value: 0.5 and parameters: {'eta': 0.1, 'max_depth': 8, 'lambda': 2.4112471988139384e-07, 'alpha': 1.4300081270960131e-05, 'colsample_bytree': 0.8085634555002872, 'subsample': 0.8237226362530321, 'min_child_weight': 65}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:02,243]\u001b[0m Trial 30 finished with value: 0.5 and parameters: {'eta': 0.05, 'max_depth': 10, 'lambda': 0.00017434688286047933, 'alpha': 2.1673431422716773, 'colsample_bytree': 0.49958067554371016, 'subsample': 0.6187620165835434, 'min_child_weight': 100}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:02,619]\u001b[0m Trial 31 finished with value: 0.9070080862533693 and parameters: {'eta': 0.05, 'max_depth': 5, 'lambda': 6.587456728187716e-06, 'alpha': 0.03379352965879635, 'colsample_bytree': 0.36620208614844585, 'subsample': 0.9117866478701359, 'min_child_weight': 7}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:03,081]\u001b[0m Trial 32 finished with value: 0.9097035040431267 and parameters: {'eta': 0.05, 'max_depth': 5, 'lambda': 6.686313263968537e-06, 'alpha': 0.03189317691776301, 'colsample_bytree': 0.3670762301440873, 'subsample': 0.9355845628747366, 'min_child_weight': 8}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:03,622]\u001b[0m Trial 33 finished with value: 0.9137466307277627 and parameters: {'eta': 0.05, 'max_depth': 6, 'lambda': 0.0012860734864847765, 'alpha': 0.01968064028250807, 'colsample_bytree': 0.45011969216907205, 'subsample': 0.950087733681735, 'min_child_weight': 9}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:03,748]\u001b[0m Trial 34 finished with value: 0.8389487870619945 and parameters: {'eta': 0.05, 'max_depth': 6, 'lambda': 0.001376420855378895, 'alpha': 0.0014641798244140053, 'colsample_bytree': 0.4575039071884039, 'subsample': 0.9895255302371968, 'min_child_weight': 25}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:03,998]\u001b[0m Trial 35 finished with value: 0.8692722371967655 and parameters: {'eta': 0.1, 'max_depth': 7, 'lambda': 0.012046014781787379, 'alpha': 0.014531835725536048, 'colsample_bytree': 0.6175791653571521, 'subsample': 0.8528694045907572, 'min_child_weight': 16}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:04,200]\u001b[0m Trial 36 finished with value: 0.8119946091644206 and parameters: {'eta': 0.025, 'max_depth': 8, 'lambda': 0.0008514945144472221, 'alpha': 0.1906476303589624, 'colsample_bytree': 0.714359885330918, 'subsample': 0.9558339636070018, 'min_child_weight': 40}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:04,634]\u001b[0m Trial 37 finished with value: 0.8921832884097035 and parameters: {'eta': 0.05, 'max_depth': 6, 'lambda': 0.02185925065738942, 'alpha': 1.6093663609777689, 'colsample_bytree': 0.5090668346843897, 'subsample': 0.5251760105943695, 'min_child_weight': 9}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:04,765]\u001b[0m Trial 38 finished with value: 0.7964959568733154 and parameters: {'eta': 0.0125, 'max_depth': 10, 'lambda': 0.0040082897654409606, 'alpha': 0.0003213118888425136, 'colsample_bytree': 0.6555617097527953, 'subsample': 0.444763905943915, 'min_child_weight': 14}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:04,987]\u001b[0m Trial 39 finished with value: 0.7668463611859838 and parameters: {'eta': 0.025, 'max_depth': 6, 'lambda': 7.872982713552176, 'alpha': 1.2413077532552405e-07, 'colsample_bytree': 0.43742755730601024, 'subsample': 0.7108201288927933, 'min_child_weight': 24}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:05,082]\u001b[0m Trial 40 finished with value: 0.7466307277628033 and parameters: {'eta': 0.1, 'max_depth': 9, 'lambda': 0.0002521870620837354, 'alpha': 0.15099601199625381, 'colsample_bytree': 0.9288516036731038, 'subsample': 0.8046145699744555, 'min_child_weight': 55}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:05,484]\u001b[0m Trial 41 finished with value: 0.9110512129380054 and parameters: {'eta': 0.05, 'max_depth': 5, 'lambda': 2.7303822278647967e-06, 'alpha': 0.013729669798282633, 'colsample_bytree': 0.352400585591189, 'subsample': 0.9544931489142593, 'min_child_weight': 8}. Best is trial 16 with value: 0.921832884097035.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:06,369]\u001b[0m Trial 42 finished with value: 0.9393530997304582 and parameters: {'eta': 0.05, 'max_depth': 7, 'lambda': 2.6613390582625458e-06, 'alpha': 0.002204003335061092, 'colsample_bytree': 0.8037619742946838, 'subsample': 0.954591327621212, 'min_child_weight': 2}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:06,927]\u001b[0m Trial 43 finished with value: 0.898921832884097 and parameters: {'eta': 0.05, 'max_depth': 4, 'lambda': 3.1488536726122667e-07, 'alpha': 0.002481171368765482, 'colsample_bytree': 0.8168712923252318, 'subsample': 0.9561535872559025, 'min_child_weight': 3}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:07,278]\u001b[0m Trial 44 finished with value: 0.8369272237196765 and parameters: {'eta': 0.05, 'max_depth': 5, 'lambda': 1.4173719244667763e-06, 'alpha': 0.0001263003306965376, 'colsample_bytree': 0.8052230924294711, 'subsample': 0.8577090620772847, 'min_child_weight': 19}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:07,635]\u001b[0m Trial 45 finished with value: 0.9083557951482479 and parameters: {'eta': 0.05, 'max_depth': 3, 'lambda': 6.480597056497374e-08, 'alpha': 0.0007705538486680759, 'colsample_bytree': 0.39769769702249747, 'subsample': 0.9571178253192459, 'min_child_weight': 13}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:08,278]\u001b[0m Trial 46 finished with value: 0.8773584905660378 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 2.9281080001611063e-06, 'alpha': 0.0024758660659468966, 'colsample_bytree': 0.3478432737595186, 'subsample': 0.5599990772959342, 'min_child_weight': 1}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:08,744]\u001b[0m Trial 47 finished with value: 0.9056603773584906 and parameters: {'eta': 0.05, 'max_depth': 7, 'lambda': 8.681650366689915e-05, 'alpha': 0.06395105225036163, 'colsample_bytree': 0.7023121728848626, 'subsample': 0.8918546791651925, 'min_child_weight': 11}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:10,274]\u001b[0m Trial 48 finished with value: 0.9123989218328842 and parameters: {'eta': 0.0125, 'max_depth': 6, 'lambda': 1.8746017934924884e-05, 'alpha': 0.011306809299523012, 'colsample_bytree': 0.8486447512280457, 'subsample': 0.99972965775926, 'min_child_weight': 5}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:10,412]\u001b[0m Trial 49 finished with value: 0.7075471698113208 and parameters: {'eta': 0.0125, 'max_depth': 6, 'lambda': 0.0005102165484735365, 'alpha': 0.0001146118282486312, 'colsample_bytree': 0.9338263948361601, 'subsample': 0.9969759211684501, 'min_child_weight': 69}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:10,566]\u001b[0m Trial 50 finished with value: 0.7762803234501348 and parameters: {'eta': 0.0125, 'max_depth': 8, 'lambda': 1.5584021669038944e-05, 'alpha': 1.116634399726969e-05, 'colsample_bytree': 0.84583201973923, 'subsample': 0.787191775933915, 'min_child_weight': 27}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:10,972]\u001b[0m Trial 51 finished with value: 0.8706199460916442 and parameters: {'eta': 0.0125, 'max_depth': 6, 'lambda': 3.157358036975058e-05, 'alpha': 0.01546803036847443, 'colsample_bytree': 0.4513553510164451, 'subsample': 0.9580832392387146, 'min_child_weight': 4}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:11,290]\u001b[0m Trial 52 finished with value: 0.8194070080862534 and parameters: {'eta': 0.0125, 'max_depth': 5, 'lambda': 4.687934067933256e-07, 'alpha': 0.013776392710243663, 'colsample_bytree': 0.8958005668541111, 'subsample': 0.9983873082344349, 'min_child_weight': 6}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:11,712]\u001b[0m Trial 53 finished with value: 0.9002695417789758 and parameters: {'eta': 0.05, 'max_depth': 7, 'lambda': 9.968473635210953e-05, 'alpha': 0.33416789662261576, 'colsample_bytree': 0.8351022505990572, 'subsample': 0.8952065134871074, 'min_child_weight': 12}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:12,016]\u001b[0m Trial 54 finished with value: 0.8315363881401617 and parameters: {'eta': 0.05, 'max_depth': 6, 'lambda': 0.0014018017848666739, 'alpha': 0.06204914987123102, 'colsample_bytree': 0.7890827365586986, 'subsample': 0.8707465917282576, 'min_child_weight': 20}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:16,094]\u001b[0m Trial 55 finished with value: 0.8800539083557951 and parameters: {'eta': 0.0125, 'max_depth': 7, 'lambda': 2.5901533371948375e-05, 'alpha': 2.8067322955895606, 'colsample_bytree': 0.9034639838221245, 'subsample': 0.9148926850470904, 'min_child_weight': 1}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:16,678]\u001b[0m Trial 56 finished with value: 0.8975741239892183 and parameters: {'eta': 0.025, 'max_depth': 4, 'lambda': 3.002260071137203e-06, 'alpha': 0.0005394121092556068, 'colsample_bytree': 0.8652528509731258, 'subsample': 0.96441390262266, 'min_child_weight': 16}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:17,187]\u001b[0m Trial 57 finished with value: 0.9016172506738545 and parameters: {'eta': 0.05, 'max_depth': 3, 'lambda': 7.413438833023425e-07, 'alpha': 0.004182772545121473, 'colsample_bytree': 0.4157052656639792, 'subsample': 0.8462162378559742, 'min_child_weight': 5}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:17,270]\u001b[0m Trial 58 finished with value: 0.5 and parameters: {'eta': 0.1, 'max_depth': 6, 'lambda': 3.5995115409045803e-06, 'alpha': 0.012167135451004247, 'colsample_bytree': 0.3314687063781577, 'subsample': 0.9432721010532099, 'min_child_weight': 81}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:17,754]\u001b[0m Trial 59 finished with value: 0.9137466307277627 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 0.00011609848431305191, 'alpha': 0.00018034984762317288, 'colsample_bytree': 0.9632863512105263, 'subsample': 0.9138216042163315, 'min_child_weight': 10}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:18,099]\u001b[0m Trial 60 finished with value: 0.8679245283018868 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 1.0270782736381276e-07, 'alpha': 0.00013165721080143076, 'colsample_bytree': 0.9758346664919605, 'subsample': 0.970378328413525, 'min_child_weight': 18}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:18,590]\u001b[0m Trial 61 finished with value: 0.9150943396226415 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 7.984226513617247e-06, 'alpha': 0.002799641097678442, 'colsample_bytree': 0.9670941868261028, 'subsample': 0.9000481408604388, 'min_child_weight': 8}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:19,094]\u001b[0m Trial 62 finished with value: 0.9231805929919138 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 1.0553227439036719e-05, 'alpha': 3.152667383116258e-05, 'colsample_bytree': 0.9664049408292081, 'subsample': 0.9084622427149133, 'min_child_weight': 11}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:19,500]\u001b[0m Trial 63 finished with value: 0.8975741239892183 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 7.839700841761763e-06, 'alpha': 1.989019987933192e-06, 'colsample_bytree': 0.9706597983292667, 'subsample': 0.9020874746965131, 'min_child_weight': 13}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:19,770]\u001b[0m Trial 64 finished with value: 0.8086253369272237 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 1.9330386182500708e-05, 'alpha': 6.92146015968213e-06, 'colsample_bytree': 0.9464806165365991, 'subsample': 0.8245657438303239, 'min_child_weight': 22}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:19,909]\u001b[0m Trial 65 finished with value: 0.8066037735849056 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 0.0004683953101048516, 'alpha': 3.525352052255909e-05, 'colsample_bytree': 0.999475662299379, 'subsample': 0.8727860438908225, 'min_child_weight': 33}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:20,605]\u001b[0m Trial 66 finished with value: 0.9137466307277629 and parameters: {'eta': 0.05, 'max_depth': 10, 'lambda': 0.0001231060732292249, 'alpha': 5.640155698174806e-05, 'colsample_bytree': 0.9113525854036968, 'subsample': 0.9780674088453314, 'min_child_weight': 4}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:20,975]\u001b[0m Trial 67 finished with value: 0.8557951482479784 and parameters: {'eta': 0.05, 'max_depth': 12, 'lambda': 0.00018926379791005788, 'alpha': 0.00022923633757952397, 'colsample_bytree': 0.9625397273644781, 'subsample': 0.7352215950863071, 'min_child_weight': 15}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:21,330]\u001b[0m Trial 68 finished with value: 0.9150943396226415 and parameters: {'eta': 0.05, 'max_depth': 10, 'lambda': 1.5584809096316573e-06, 'alpha': 2.6043979320455165e-05, 'colsample_bytree': 0.9075204766461202, 'subsample': 0.9116299598101406, 'min_child_weight': 10}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:22,013]\u001b[0m Trial 69 finished with value: 0.9097035040431267 and parameters: {'eta': 0.05, 'max_depth': 10, 'lambda': 1.0967195374785777e-06, 'alpha': 4.832539401012501e-05, 'colsample_bytree': 0.8949034173437406, 'subsample': 0.8759387997471798, 'min_child_weight': 4}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:22,463]\u001b[0m Trial 70 finished with value: 0.921832884097035 and parameters: {'eta': 0.05, 'max_depth': 10, 'lambda': 9.767862211940082e-06, 'alpha': 2.9843091330882468e-05, 'colsample_bytree': 0.9166568555941966, 'subsample': 0.9766769199760849, 'min_child_weight': 10}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:22,895]\u001b[0m Trial 71 finished with value: 0.9258760107816711 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 1.0234833619982362e-05, 'alpha': 1.9618469850428083e-05, 'colsample_bytree': 0.9121129889821019, 'subsample': 0.976669711746212, 'min_child_weight': 11}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:23,928]\u001b[0m Trial 72 finished with value: 0.9123989218328842 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 1.0068394709563768e-05, 'alpha': 2.526426503594679e-05, 'colsample_bytree': 0.8749044245568576, 'subsample': 0.9840329022418206, 'min_child_weight': 3}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:24,340]\u001b[0m Trial 73 finished with value: 0.8867924528301887 and parameters: {'eta': 0.05, 'max_depth': 10, 'lambda': 4.380377840980861e-05, 'alpha': 2.427254682141749e-06, 'colsample_bytree': 0.9150148080108363, 'subsample': 0.9742202427875267, 'min_child_weight': 17}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:24,804]\u001b[0m Trial 74 finished with value: 0.917789757412399 and parameters: {'eta': 0.05, 'max_depth': 12, 'lambda': 5.0629022469187344e-06, 'alpha': 8.092368451662067e-05, 'colsample_bytree': 0.9254202060680253, 'subsample': 0.9360268125740345, 'min_child_weight': 11}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:25,171]\u001b[0m Trial 75 finished with value: 0.8261455525606469 and parameters: {'eta': 0.05, 'max_depth': 12, 'lambda': 1.9781383088045536e-06, 'alpha': 5.16428677967357e-06, 'colsample_bytree': 0.9437302881184646, 'subsample': 0.9141946178919185, 'min_child_weight': 22}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:25,679]\u001b[0m Trial 76 finished with value: 0.9150943396226415 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 4.3918884274614024e-06, 'alpha': 2.0540942606526348e-05, 'colsample_bytree': 0.9848156037459165, 'subsample': 0.9314458425870582, 'min_child_weight': 11}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:26,001]\u001b[0m Trial 77 finished with value: 0.807277628032345 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 3.967911137827688e-06, 'alpha': 1.0132344426013846e-06, 'colsample_bytree': 0.9912917621346378, 'subsample': 0.9352546592196265, 'min_child_weight': 28}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:26,651]\u001b[0m Trial 78 finished with value: 0.917789757412399 and parameters: {'eta': 0.05, 'max_depth': 12, 'lambda': 8.923171585775531e-07, 'alpha': 6.0493276531604356e-05, 'colsample_bytree': 0.9278367270912034, 'subsample': 0.889756215371333, 'min_child_weight': 8}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:27,180]\u001b[0m Trial 79 finished with value: 0.8881401617250674 and parameters: {'eta': 0.025, 'max_depth': 12, 'lambda': 6.618968694432244e-07, 'alpha': 7.853636625769432e-05, 'colsample_bytree': 0.9254890832032778, 'subsample': 0.8412245994532014, 'min_child_weight': 13}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:27,408]\u001b[0m Trial 80 finished with value: 0.8814016172506739 and parameters: {'eta': 0.1, 'max_depth': 12, 'lambda': 1.5734314580097506e-07, 'alpha': 1.3617325581906323e-05, 'colsample_bytree': 0.8830691923419566, 'subsample': 0.9436719868015235, 'min_child_weight': 18}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:28,098]\u001b[0m Trial 81 finished with value: 0.9191374663072777 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 1.1458450892681257e-05, 'alpha': 0.0006707650721350631, 'colsample_bytree': 0.9582076874712363, 'subsample': 0.8857826484007835, 'min_child_weight': 7}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:28,746]\u001b[0m Trial 82 finished with value: 0.9191374663072776 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 1.091960451420715e-05, 'alpha': 0.0004172364802238288, 'colsample_bytree': 0.9590882579971816, 'subsample': 0.8889695169474483, 'min_child_weight': 7}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:29,094]\u001b[0m Trial 83 finished with value: 0.9002695417789757 and parameters: {'eta': 0.05, 'max_depth': 12, 'lambda': 1.1832677048364494e-05, 'alpha': 0.0008356103006943093, 'colsample_bytree': 0.9374498972574651, 'subsample': 0.8838730233471925, 'min_child_weight': 14}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:29,749]\u001b[0m Trial 84 finished with value: 0.9218328840970351 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 3.412368604585674e-05, 'alpha': 0.0003119466898802355, 'colsample_bytree': 0.9538497526840402, 'subsample': 0.8594758472003493, 'min_child_weight': 7}. Best is trial 42 with value: 0.9393530997304582.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:30,624]\u001b[0m Trial 85 finished with value: 0.940700808625337 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 2.5706407546907786e-05, 'alpha': 0.0003353740968295744, 'colsample_bytree': 0.9573024525751012, 'subsample': 0.7977851778312689, 'min_child_weight': 1}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:31,201]\u001b[0m Trial 86 finished with value: 0.8706199460916443 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 3.164522208346802e-05, 'alpha': 0.0014341053418848106, 'colsample_bytree': 0.9560473030534681, 'subsample': 0.8119359152224439, 'min_child_weight': 2}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:31,319]\u001b[0m Trial 87 finished with value: 0.7021563342318059 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 5.761488589539172e-05, 'alpha': 0.0004923105962074748, 'colsample_bytree': 0.9522352107570902, 'subsample': 0.7714725235602999, 'min_child_weight': 49}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:32,686]\u001b[0m Trial 88 finished with value: 0.8867924528301887 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 1.3853372208940001e-05, 'alpha': 0.00035783244410015724, 'colsample_bytree': 0.9857707099302407, 'subsample': 0.8422027933625714, 'min_child_weight': 1}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:33,220]\u001b[0m Trial 89 finished with value: 0.9137466307277627 and parameters: {'eta': 0.05, 'max_depth': 10, 'lambda': 2.0650834317224637e-06, 'alpha': 0.0009799813918338013, 'colsample_bytree': 0.879897068186284, 'subsample': 0.8622428958385961, 'min_child_weight': 6}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:33,699]\u001b[0m Trial 90 finished with value: 0.9110512129380054 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 2.5450564876549404e-05, 'alpha': 0.0002379019245896285, 'colsample_bytree': 0.8337410455542884, 'subsample': 0.7808881163345018, 'min_child_weight': 7}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:34,305]\u001b[0m Trial 91 finished with value: 0.9191374663072777 and parameters: {'eta': 0.05, 'max_depth': 12, 'lambda': 5.627240769717474e-06, 'alpha': 0.000392369601246505, 'colsample_bytree': 0.9989531956937423, 'subsample': 0.8842092846817932, 'min_child_weight': 7}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:35,057]\u001b[0m Trial 92 finished with value: 0.9272237196765499 and parameters: {'eta': 0.05, 'max_depth': 10, 'lambda': 5.326828669879324e-06, 'alpha': 0.0017156517765002752, 'colsample_bytree': 0.9906387336019458, 'subsample': 0.828206321207586, 'min_child_weight': 5}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:35,996]\u001b[0m Trial 93 finished with value: 0.9177897574123989 and parameters: {'eta': 0.05, 'max_depth': 10, 'lambda': 4.049135114244509e-05, 'alpha': 0.007233974872750391, 'colsample_bytree': 0.9835932454174103, 'subsample': 0.8308863829073043, 'min_child_weight': 3}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:36,330]\u001b[0m Trial 94 finished with value: 0.8760107816711591 and parameters: {'eta': 0.05, 'max_depth': 10, 'lambda': 6.984766136682051e-06, 'alpha': 0.001553420388908967, 'colsample_bytree': 0.9983278774188193, 'subsample': 0.8101480944355952, 'min_child_weight': 15}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:36,878]\u001b[0m Trial 95 finished with value: 0.9231805929919137 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 5.184094966533112e-06, 'alpha': 0.003989279366180746, 'colsample_bytree': 0.6703352475298898, 'subsample': 0.8590422344673517, 'min_child_weight': 6}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:37,255]\u001b[0m Trial 96 finished with value: 0.8638814016172507 and parameters: {'eta': 0.025, 'max_depth': 11, 'lambda': 7.214178157580946e-05, 'alpha': 0.003916531324382961, 'colsample_bytree': 0.6800293349846024, 'subsample': 0.8547097573071785, 'min_child_weight': 5}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:37,653]\u001b[0m Trial 97 finished with value: 0.9016172506738545 and parameters: {'eta': 0.05, 'max_depth': 12, 'lambda': 1.9822685235815268e-05, 'alpha': 0.0012121163154786123, 'colsample_bytree': 0.5252134967066723, 'subsample': 0.6402320391979377, 'min_child_weight': 10}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:38,299]\u001b[0m Trial 98 finished with value: 0.9137466307277629 and parameters: {'eta': 0.1, 'max_depth': 10, 'lambda': 2.3641848958343204e-06, 'alpha': 0.0022754735169514505, 'colsample_bytree': 0.48285905118658445, 'subsample': 0.7909745094659731, 'min_child_weight': 1}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:38,808]\u001b[0m Trial 99 finished with value: 0.8962264150943396 and parameters: {'eta': 0.05, 'max_depth': 10, 'lambda': 4.703943073165974e-06, 'alpha': 0.00021757122855470593, 'colsample_bytree': 0.7297296379549434, 'subsample': 0.5760571303420781, 'min_child_weight': 5}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:39,012]\u001b[0m Trial 100 finished with value: 0.8099730458221024 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 2.6295108598936208e-05, 'alpha': 6.837279171033105e-06, 'colsample_bytree': 0.7816495167439913, 'subsample': 0.4096168199757316, 'min_child_weight': 12}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:39,656]\u001b[0m Trial 101 finished with value: 0.921832884097035 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 6.559550674619579e-06, 'alpha': 0.007980694009952122, 'colsample_bytree': 0.9736042035234559, 'subsample': 0.8652639445036002, 'min_child_weight': 7}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:40,086]\u001b[0m Trial 102 finished with value: 0.9056603773584906 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 5.793472183158058e-06, 'alpha': 0.0038878755963829476, 'colsample_bytree': 0.5730867630326845, 'subsample': 0.7541484559896141, 'min_child_weight': 9}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:40,703]\u001b[0m Trial 103 finished with value: 0.8989218328840971 and parameters: {'eta': 0.05, 'max_depth': 12, 'lambda': 1.7170243951453406e-06, 'alpha': 0.007258858508180922, 'colsample_bytree': 0.63514922292982, 'subsample': 0.8335777420382442, 'min_child_weight': 6}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:41,680]\u001b[0m Trial 104 finished with value: 0.9083557951482479 and parameters: {'eta': 0.05, 'max_depth': 10, 'lambda': 1.6604980782665307e-05, 'alpha': 0.008873538738816009, 'colsample_bytree': 0.9775625682358104, 'subsample': 0.8672564796777327, 'min_child_weight': 3}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:42,054]\u001b[0m Trial 105 finished with value: 0.9056603773584906 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 4.2175123988886475e-07, 'alpha': 0.0017860336801338484, 'colsample_bytree': 0.9394164054154548, 'subsample': 0.8534085294978104, 'min_child_weight': 12}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:42,636]\u001b[0m Trial 106 finished with value: 0.921832884097035 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 9.931583107360716e-06, 'alpha': 0.03081779171154676, 'colsample_bytree': 0.9729779971240031, 'subsample': 0.8186609379031167, 'min_child_weight': 9}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:42,983]\u001b[0m Trial 107 finished with value: 0.8584905660377359 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 4.6104998813972914e-05, 'alpha': 0.021883908213508396, 'colsample_bytree': 0.8952439206916079, 'subsample': 0.8178863568863455, 'min_child_weight': 16}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:43,387]\u001b[0m Trial 108 finished with value: 0.9245283018867925 and parameters: {'eta': 0.05, 'max_depth': 10, 'lambda': 3.348029511496968e-06, 'alpha': 0.1097255499351576, 'colsample_bytree': 0.9169732932585745, 'subsample': 0.8036199220398519, 'min_child_weight': 9}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:43,812]\u001b[0m Trial 109 finished with value: 0.8962264150943396 and parameters: {'eta': 0.05, 'max_depth': 10, 'lambda': 8.738720765752536e-06, 'alpha': 0.12172493616376955, 'colsample_bytree': 0.8612056335056516, 'subsample': 0.7266874071207703, 'min_child_weight': 3}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:44,276]\u001b[0m Trial 110 finished with value: 0.9272237196765498 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 1.1306296531176676e-06, 'alpha': 0.10612941803115855, 'colsample_bytree': 0.9203635722244851, 'subsample': 0.8055043308854244, 'min_child_weight': 10}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:44,655]\u001b[0m Trial 111 finished with value: 0.9231805929919138 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 3.0888000044955515e-06, 'alpha': 0.03689018563247591, 'colsample_bytree': 0.9217297490937811, 'subsample': 0.7994238737573718, 'min_child_weight': 9}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:45,007]\u001b[0m Trial 112 finished with value: 0.8867924528301887 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 2.813918453667486e-06, 'alpha': 0.0937385347564073, 'colsample_bytree': 0.9200760797505336, 'subsample': 0.7972517422735915, 'min_child_weight': 14}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:45,097]\u001b[0m Trial 113 finished with value: 0.5 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 5.826323318424546e-07, 'alpha': 0.044520380608459774, 'colsample_bytree': 0.9395622086334344, 'subsample': 0.776750809996507, 'min_child_weight': 60}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:45,673]\u001b[0m Trial 114 finished with value: 0.9218328840970351 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 2.715981277337761e-06, 'alpha': 0.034147886355139614, 'colsample_bytree': 0.9718825906382978, 'subsample': 0.7955919962114294, 'min_child_weight': 9}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:46,038]\u001b[0m Trial 115 finished with value: 0.8840970350404312 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 1.0435829254387646e-06, 'alpha': 0.25415628364221005, 'colsample_bytree': 0.9064902586531893, 'subsample': 0.752045043633613, 'min_child_weight': 11}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:46,241]\u001b[0m Trial 116 finished with value: 0.8153638814016173 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 1.435648897632671e-06, 'alpha': 1.5373666614672847e-07, 'colsample_bytree': 0.8875853178635965, 'subsample': 0.7003233709313532, 'min_child_weight': 19}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:46,327]\u001b[0m Trial 117 finished with value: 0.5 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 3.6407207294677573e-06, 'alpha': 0.09432206539529753, 'colsample_bytree': 0.8592769974485641, 'subsample': 0.7994705115770784, 'min_child_weight': 100}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:47,117]\u001b[0m Trial 118 finished with value: 0.9083557951482479 and parameters: {'eta': 0.025, 'max_depth': 9, 'lambda': 3.8118019809309596e-06, 'alpha': 0.039327550204438164, 'colsample_bytree': 0.9502220262738817, 'subsample': 0.7609023926307333, 'min_child_weight': 1}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:47,722]\u001b[0m Trial 119 finished with value: 0.9285714285714286 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 3.816823184468633e-07, 'alpha': 0.021207650864406798, 'colsample_bytree': 0.9707263159850344, 'subsample': 0.8225194330586655, 'min_child_weight': 5}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:48,260]\u001b[0m Trial 120 finished with value: 0.9245283018867925 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 2.723397126767932e-07, 'alpha': 0.022842761057919287, 'colsample_bytree': 0.9364623521525814, 'subsample': 0.7863460491373788, 'min_child_weight': 5}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:48,869]\u001b[0m Trial 121 finished with value: 0.9258760107816713 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 3.970129364340636e-08, 'alpha': 0.024287109699330463, 'colsample_bytree': 0.946598651112982, 'subsample': 0.7895269989208982, 'min_child_weight': 5}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:49,394]\u001b[0m Trial 122 finished with value: 0.9056603773584906 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 2.6155356463536103e-08, 'alpha': 0.024165001261392226, 'colsample_bytree': 0.9328527839301975, 'subsample': 0.8361367943655003, 'min_child_weight': 5}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:50,020]\u001b[0m Trial 123 finished with value: 0.9164420485175202 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 3.025008383944477e-07, 'alpha': 0.04661219647375148, 'colsample_bytree': 0.9201273820417916, 'subsample': 0.7845093901964192, 'min_child_weight': 4}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:50,432]\u001b[0m Trial 124 finished with value: 0.9204851752021563 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 4.3407758763914927e-07, 'alpha': 0.06859976411291613, 'colsample_bytree': 0.968420882916986, 'subsample': 0.7338232541737463, 'min_child_weight': 9}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:50,995]\u001b[0m Trial 125 finished with value: 0.9110512129380054 and parameters: {'eta': 0.1, 'max_depth': 8, 'lambda': 5.63648154499295e-08, 'alpha': 0.1566627496649445, 'colsample_bytree': 0.9488532450231751, 'subsample': 0.7698264898312245, 'min_child_weight': 3}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:51,635]\u001b[0m Trial 126 finished with value: 0.8827493261455526 and parameters: {'eta': 0.05, 'max_depth': 7, 'lambda': 1.2815754967888347e-07, 'alpha': 0.2681084609688956, 'colsample_bytree': 0.9000187156224206, 'subsample': 0.8096202053884456, 'min_child_weight': 1}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:52,172]\u001b[0m Trial 127 finished with value: 0.9218328840970351 and parameters: {'eta': 0.05, 'max_depth': 7, 'lambda': 1.8654720634007792e-07, 'alpha': 0.018004776877595385, 'colsample_bytree': 0.9438471005705097, 'subsample': 0.8448395187975646, 'min_child_weight': 5}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:52,265]\u001b[0m Trial 128 finished with value: 0.5 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 1.570044478698582e-08, 'alpha': 0.10913202052755727, 'colsample_bytree': 0.9123889460856265, 'subsample': 0.829744873200108, 'min_child_weight': 92}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:52,553]\u001b[0m Trial 129 finished with value: 0.8800539083557952 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 7.979362155155538e-07, 'alpha': 0.0623288449460223, 'colsample_bytree': 0.9847478107316725, 'subsample': 0.7995970607425454, 'min_child_weight': 13}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:53,141]\u001b[0m Trial 130 finished with value: 0.8908355795148247 and parameters: {'eta': 0.05, 'max_depth': 7, 'lambda': 4.745593756501324e-08, 'alpha': 0.015829318679061885, 'colsample_bytree': 0.9321008716299435, 'subsample': 0.7216749850891477, 'min_child_weight': 5}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:53,785]\u001b[0m Trial 131 finished with value: 0.9016172506738545 and parameters: {'eta': 0.05, 'max_depth': 7, 'lambda': 1.9711250174677052e-07, 'alpha': 0.022701838987825955, 'colsample_bytree': 0.9591117594290193, 'subsample': 0.8426342230104696, 'min_child_weight': 5}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:54,225]\u001b[0m Trial 132 finished with value: 0.9056603773584906 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 1.2713260146599682e-06, 'alpha': 0.004564134223653916, 'colsample_bytree': 0.9682743507294215, 'subsample': 0.7879281080794129, 'min_child_weight': 9}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:54,750]\u001b[0m Trial 133 finished with value: 0.9353099730458222 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 2.048860958074839e-06, 'alpha': 0.4531305673759726, 'colsample_bytree': 0.9524288501251855, 'subsample': 0.7420947487722962, 'min_child_weight': 7}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:55,151]\u001b[0m Trial 134 finished with value: 0.9016172506738545 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 2.0417312860774002e-06, 'alpha': 0.4034789773650981, 'colsample_bytree': 0.986949290271711, 'subsample': 0.7457999110428069, 'min_child_weight': 11}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:55,511]\u001b[0m Trial 135 finished with value: 0.9083557951482479 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 9.434148223116703e-08, 'alpha': 1.4455720677625479, 'colsample_bytree': 0.9467271237365301, 'subsample': 0.7627358149683381, 'min_child_weight': 3}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:55,825]\u001b[0m Trial 136 finished with value: 0.853099730458221 and parameters: {'eta': 0.0125, 'max_depth': 7, 'lambda': 3.4510122214422946e-07, 'alpha': 0.011124494455103405, 'colsample_bytree': 0.8781581784174495, 'subsample': 0.8113207131881928, 'min_child_weight': 7}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:55,973]\u001b[0m Trial 137 finished with value: 0.7944743935309972 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 2.6412539377515987e-06, 'alpha': 0.7891406468493384, 'colsample_bytree': 0.9258986939471534, 'subsample': 0.49637135479514344, 'min_child_weight': 15}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:56,358]\u001b[0m Trial 138 finished with value: 0.9123989218328841 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 6.681139936141249e-07, 'alpha': 0.03238458170302479, 'colsample_bytree': 0.9070045019908488, 'subsample': 0.7829261500004069, 'min_child_weight': 8}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:56,452]\u001b[0m Trial 139 finished with value: 0.5 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 9.29324572931059e-07, 'alpha': 0.05038245312872751, 'colsample_bytree': 0.9632535058560232, 'subsample': 0.6662413567086227, 'min_child_weight': 74}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:56,843]\u001b[0m Trial 140 finished with value: 0.889487870619946 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 1.360005781209396e-06, 'alpha': 0.1911008395234568, 'colsample_bytree': 0.996316141039942, 'subsample': 0.7978329096126112, 'min_child_weight': 12}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:57,487]\u001b[0m Trial 141 finished with value: 0.9353099730458222 and parameters: {'eta': 0.05, 'max_depth': 7, 'lambda': 2.4983821799372027e-07, 'alpha': 0.017592420166573038, 'colsample_bytree': 0.9424524108283255, 'subsample': 0.8223744569923296, 'min_child_weight': 5}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:58,011]\u001b[0m Trial 142 finished with value: 0.8935309973045823 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 8.594857028153336e-08, 'alpha': 0.031732152770218035, 'colsample_bytree': 0.9786514767068514, 'subsample': 0.8188974752049053, 'min_child_weight': 2}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:58,647]\u001b[0m Trial 143 finished with value: 0.9150943396226415 and parameters: {'eta': 0.05, 'max_depth': 7, 'lambda': 2.2794058235255222e-07, 'alpha': 0.0029921013125593404, 'colsample_bytree': 0.9423479950176167, 'subsample': 0.7744377459327719, 'min_child_weight': 5}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:54:59,216]\u001b[0m Trial 144 finished with value: 0.9123989218328841 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 5.144594976740303e-07, 'alpha': 0.006053308909503512, 'colsample_bytree': 0.8920799203258546, 'subsample': 0.8259336362366645, 'min_child_weight': 6}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:00,029]\u001b[0m Trial 145 finished with value: 0.9191374663072777 and parameters: {'eta': 0.05, 'max_depth': 7, 'lambda': 1.9130600734524366e-08, 'alpha': 0.015236111540938126, 'colsample_bytree': 0.9352701278464306, 'subsample': 0.8467994345003844, 'min_child_weight': 3}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:00,432]\u001b[0m Trial 146 finished with value: 0.9204851752021563 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 2.1299865011063966e-06, 'alpha': 0.09360766965596597, 'colsample_bytree': 0.9617047656739489, 'subsample': 0.8064102832491052, 'min_child_weight': 9}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:00,599]\u001b[0m Trial 147 finished with value: 0.7628032345013477 and parameters: {'eta': 0.025, 'max_depth': 10, 'lambda': 4.8299948547470505e-06, 'alpha': 0.010437686761261604, 'colsample_bytree': 0.9186929888069099, 'subsample': 0.3023846444705994, 'min_child_weight': 7}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:02,075]\u001b[0m Trial 148 finished with value: 0.9258760107816711 and parameters: {'eta': 0.05, 'max_depth': 10, 'lambda': 0.7591407473305526, 'alpha': 0.4733264473214956, 'colsample_bytree': 0.8366872567543523, 'subsample': 0.8271986426224083, 'min_child_weight': 1}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:03,046]\u001b[0m Trial 149 finished with value: 0.9002695417789758 and parameters: {'eta': 0.1, 'max_depth': 10, 'lambda': 1.1557351281295014, 'alpha': 0.38349808377794214, 'colsample_bytree': 0.7827095318956336, 'subsample': 0.8176556295872892, 'min_child_weight': 1}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:03,937]\u001b[0m Trial 150 finished with value: 0.9110512129380054 and parameters: {'eta': 0.05, 'max_depth': 10, 'lambda': 1.7209789525289596, 'alpha': 0.6384641219453587, 'colsample_bytree': 0.8722727282384576, 'subsample': 0.7681779477703174, 'min_child_weight': 3}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:04,361]\u001b[0m Trial 151 finished with value: 0.9191374663072777 and parameters: {'eta': 0.05, 'max_depth': 7, 'lambda': 4.149621127771776e-08, 'alpha': 0.24268716275243138, 'colsample_bytree': 0.7679474927230007, 'subsample': 0.8310098330262907, 'min_child_weight': 5}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:04,904]\u001b[0m Trial 152 finished with value: 0.9137466307277629 and parameters: {'eta': 0.05, 'max_depth': 10, 'lambda': 1.7587809385844486e-05, 'alpha': 9.766333647470027e-06, 'colsample_bytree': 0.8214095065048382, 'subsample': 0.8574767740073431, 'min_child_weight': 7}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:05,440]\u001b[0m Trial 153 finished with value: 0.9070080862533694 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 7.232088410279497e-06, 'alpha': 1.288025713177871, 'colsample_bytree': 0.9502920874654316, 'subsample': 0.8711881895765093, 'min_child_weight': 11}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:06,268]\u001b[0m Trial 154 finished with value: 0.8679245283018868 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 4.0897386712951454e-06, 'alpha': 1.7532418517533466e-05, 'colsample_bytree': 0.9299099337458894, 'subsample': 0.823511530073471, 'min_child_weight': 1}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:06,588]\u001b[0m Trial 155 finished with value: 0.9245283018867925 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 0.040428060940463334, 'alpha': 0.134343668401425, 'colsample_bytree': 0.6598447589636671, 'subsample': 0.7995450002601306, 'min_child_weight': 9}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:06,852]\u001b[0m Trial 156 finished with value: 0.8881401617250674 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 0.08494365463662651, 'alpha': 0.1561885749148454, 'colsample_bytree': 0.6077327490893331, 'subsample': 0.7868446633963807, 'min_child_weight': 13}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:07,229]\u001b[0m Trial 157 finished with value: 0.9056603773584906 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 0.21902147829491822, 'alpha': 0.47448172705257113, 'colsample_bytree': 0.6669163451777758, 'subsample': 0.8065035381817569, 'min_child_weight': 10}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:07,998]\u001b[0m Trial 158 finished with value: 0.9043126684636118 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 3.931328401376382, 'alpha': 0.058774598401888895, 'colsample_bytree': 0.6857668246016478, 'subsample': 0.7581370035294646, 'min_child_weight': 4}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:08,100]\u001b[0m Trial 159 finished with value: 0.8133423180592992 and parameters: {'eta': 0.05, 'max_depth': 10, 'lambda': 0.2948286766780623, 'alpha': 2.95688829494677, 'colsample_bytree': 0.7221863550985217, 'subsample': 0.7431063708147768, 'min_child_weight': 37}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:08,203]\u001b[0m Trial 160 finished with value: 0.7944743935309972 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 2.687765513757454e-07, 'alpha': 0.1574206322377812, 'colsample_bytree': 0.8457041535741117, 'subsample': 0.7942910100123879, 'min_child_weight': 47}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:08,736]\u001b[0m Trial 161 finished with value: 0.9029649595687332 and parameters: {'eta': 0.05, 'max_depth': 7, 'lambda': 0.011616150412576529, 'alpha': 0.020560702783553216, 'colsample_bytree': 0.6542982902691162, 'subsample': 0.840898849812983, 'min_child_weight': 6}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:09,263]\u001b[0m Trial 162 finished with value: 0.9177897574123989 and parameters: {'eta': 0.05, 'max_depth': 7, 'lambda': 1.8699637923154817e-07, 'alpha': 0.018102799721920373, 'colsample_bytree': 0.7056841424041559, 'subsample': 0.8488160679206329, 'min_child_weight': 8}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:09,561]\u001b[0m Trial 163 finished with value: 0.8942048517520216 and parameters: {'eta': 0.05, 'max_depth': 7, 'lambda': 0.6359288706658665, 'alpha': 0.07412691550404277, 'colsample_bytree': 0.749116289065038, 'subsample': 0.8312975980742933, 'min_child_weight': 4}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:09,983]\u001b[0m Trial 164 finished with value: 0.9231805929919138 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 1.7476741130453425e-06, 'alpha': 0.0020391347006040294, 'colsample_bytree': 0.9549672972592855, 'subsample': 0.9063398691613616, 'min_child_weight': 8}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:10,394]\u001b[0m Trial 165 finished with value: 0.9164420485175202 and parameters: {'eta': 0.05, 'max_depth': 10, 'lambda': 1.8029894619531642e-06, 'alpha': 0.0009438558509608327, 'colsample_bytree': 0.6323816073286789, 'subsample': 0.9499837774933331, 'min_child_weight': 8}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:11,392]\u001b[0m Trial 166 finished with value: 0.9110512129380054 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 9.99309189768976e-07, 'alpha': 0.002579579401951143, 'colsample_bytree': 0.666646665109378, 'subsample': 0.7778994966081473, 'min_child_weight': 1}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:12,614]\u001b[0m Trial 167 finished with value: 0.9029649595687332 and parameters: {'eta': 0.0125, 'max_depth': 11, 'lambda': 3.4698463110991183e-06, 'alpha': 0.005461603237781387, 'colsample_bytree': 0.9052162540007895, 'subsample': 0.91087203516236, 'min_child_weight': 10}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:13,559]\u001b[0m Trial 168 finished with value: 0.9191374663072777 and parameters: {'eta': 0.05, 'max_depth': 10, 'lambda': 1.3934998078595844e-06, 'alpha': 0.9427487647667473, 'colsample_bytree': 0.9189703364246807, 'subsample': 0.8147335035178275, 'min_child_weight': 3}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:13,918]\u001b[0m Trial 169 finished with value: 0.8814016172506738 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 5.6970879484171976e-06, 'alpha': 0.0013394527807357771, 'colsample_bytree': 0.9543817076806782, 'subsample': 0.8056349115822825, 'min_child_weight': 14}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:14,680]\u001b[0m Trial 170 finished with value: 0.9002695417789758 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 0.002002681382786911, 'alpha': 0.001867310052938223, 'colsample_bytree': 0.9832863713687924, 'subsample': 0.9638623248071905, 'min_child_weight': 6}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:15,183]\u001b[0m Trial 171 finished with value: 0.9164420485175202 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 1.0094863763182186e-08, 'alpha': 0.0007708452000132946, 'colsample_bytree': 0.938926408658155, 'subsample': 0.8646009795619161, 'min_child_weight': 7}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:15,610]\u001b[0m Trial 172 finished with value: 0.9083557951482479 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 2.8136626106997733e-06, 'alpha': 1.1474359636173301e-08, 'colsample_bytree': 0.9568750191540089, 'subsample': 0.8772201213517851, 'min_child_weight': 12}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:16,076]\u001b[0m Trial 173 finished with value: 0.9164420485175202 and parameters: {'eta': 0.05, 'max_depth': 9, 'lambda': 2.028811662291269e-06, 'alpha': 0.03414243810206423, 'colsample_bytree': 0.9722716004670156, 'subsample': 0.7851677074675258, 'min_child_weight': 9}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:17,071]\u001b[0m Trial 174 finished with value: 0.9191374663072777 and parameters: {'eta': 0.05, 'max_depth': 11, 'lambda': 1.2416530596041113e-05, 'alpha': 0.0029717560887115298, 'colsample_bytree': 0.8019160796761515, 'subsample': 0.9292145045724869, 'min_child_weight': 3}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:17,688]\u001b[0m Trial 175 finished with value: 0.9312668463611861 and parameters: {'eta': 0.05, 'max_depth': 7, 'lambda': 0.04294460030158973, 'alpha': 0.02386523553224534, 'colsample_bytree': 0.939916639286234, 'subsample': 0.8253064229079401, 'min_child_weight': 5}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:18,221]\u001b[0m Trial 176 finished with value: 0.9204851752021563 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 0.4512668812136287, 'alpha': 0.009448596066764434, 'colsample_bytree': 0.9322487815470252, 'subsample': 0.829626018055504, 'min_child_weight': 6}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:18,844]\u001b[0m Trial 177 finished with value: 0.9299191374663073 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 5.113076061154115e-07, 'alpha': 0.08882912371761388, 'colsample_bytree': 0.8941427641729378, 'subsample': 0.9033204066715176, 'min_child_weight': 4}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:19,691]\u001b[0m Trial 178 finished with value: 0.9285714285714286 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 0.03639155005536366, 'alpha': 0.11900432708148072, 'colsample_bytree': 0.8976945479921595, 'subsample': 0.9819365251295733, 'min_child_weight': 4}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:21,246]\u001b[0m Trial 179 finished with value: 0.898921832884097 and parameters: {'eta': 0.025, 'max_depth': 8, 'lambda': 0.038943089815095096, 'alpha': 0.1259464234790527, 'colsample_bytree': 0.8886728932019707, 'subsample': 0.9848054159985128, 'min_child_weight': 2}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:22,809]\u001b[0m Trial 180 finished with value: 0.9083557951482479 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 0.018117933918778726, 'alpha': 0.29383435626082455, 'colsample_bytree': 0.8999069958262416, 'subsample': 0.9670496112579766, 'min_child_weight': 1}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:23,447]\u001b[0m Trial 181 finished with value: 0.9272237196765499 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 0.09020369866806882, 'alpha': 0.0848970633384534, 'colsample_bytree': 0.914657302975813, 'subsample': 0.9883687374760503, 'min_child_weight': 5}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:24,182]\u001b[0m Trial 182 finished with value: 0.9258760107816711 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 0.03151769385127088, 'alpha': 0.08087963596463262, 'colsample_bytree': 0.9127440651880994, 'subsample': 0.9697003525697071, 'min_child_weight': 4}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:24,969]\u001b[0m Trial 183 finished with value: 0.9070080862533693 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 0.034298497843720986, 'alpha': 0.08581684654522251, 'colsample_bytree': 0.8665063072718566, 'subsample': 0.9947321653961422, 'min_child_weight': 4}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:25,638]\u001b[0m Trial 184 finished with value: 0.9245283018867925 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 0.10456697041331942, 'alpha': 0.18549057153122514, 'colsample_bytree': 0.9165926943337578, 'subsample': 0.97757877907761, 'min_child_weight': 4}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:26,541]\u001b[0m Trial 185 finished with value: 0.9123989218328842 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 0.06536685737152655, 'alpha': 0.11230499494898903, 'colsample_bytree': 0.9136381476448433, 'subsample': 0.978763315706307, 'min_child_weight': 4}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:28,142]\u001b[0m Trial 186 finished with value: 0.9043126684636118 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 0.032520390553634725, 'alpha': 0.17326880218212504, 'colsample_bytree': 0.8898970789907752, 'subsample': 0.9868107438993379, 'min_child_weight': 1}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:28,674]\u001b[0m Trial 187 finished with value: 0.9272237196765499 and parameters: {'eta': 0.1, 'max_depth': 8, 'lambda': 0.16450823200769288, 'alpha': 0.23294593101305255, 'colsample_bytree': 0.9038279004871344, 'subsample': 0.9553318955315955, 'min_child_weight': 3}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:29,448]\u001b[0m Trial 188 finished with value: 0.9231805929919138 and parameters: {'eta': 0.1, 'max_depth': 8, 'lambda': 0.07057906850649902, 'alpha': 0.3077083480500367, 'colsample_bytree': 0.881367029332606, 'subsample': 0.9486712956274346, 'min_child_weight': 3}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:29,962]\u001b[0m Trial 189 finished with value: 0.9164420485175202 and parameters: {'eta': 0.1, 'max_depth': 7, 'lambda': 0.12718918234547064, 'alpha': 0.5644579015101043, 'colsample_bytree': 0.9046393965189509, 'subsample': 0.9764735902680265, 'min_child_weight': 5}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:30,785]\u001b[0m Trial 190 finished with value: 0.9123989218328841 and parameters: {'eta': 0.1, 'max_depth': 8, 'lambda': 0.050702225321570774, 'alpha': 0.05176224601580047, 'colsample_bytree': 0.8512702282440774, 'subsample': 0.9650229411820144, 'min_child_weight': 1}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:31,281]\u001b[0m Trial 191 finished with value: 0.9353099730458222 and parameters: {'eta': 0.1, 'max_depth': 8, 'lambda': 0.11488893014727868, 'alpha': 0.2038350954990766, 'colsample_bytree': 0.9142176429645557, 'subsample': 0.9604266415976808, 'min_child_weight': 5}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:31,728]\u001b[0m Trial 192 finished with value: 0.9285714285714286 and parameters: {'eta': 0.1, 'max_depth': 8, 'lambda': 0.09302506566355827, 'alpha': 0.22835503780426394, 'colsample_bytree': 0.9015908302615103, 'subsample': 0.9485855780650058, 'min_child_weight': 5}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:32,094]\u001b[0m Trial 193 finished with value: 0.9218328840970351 and parameters: {'eta': 0.1, 'max_depth': 8, 'lambda': 0.023288117362016948, 'alpha': 0.23035673442536167, 'colsample_bytree': 0.8986540858857583, 'subsample': 0.9572612925180516, 'min_child_weight': 6}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:32,619]\u001b[0m Trial 194 finished with value: 0.9150943396226415 and parameters: {'eta': 0.1, 'max_depth': 7, 'lambda': 0.2202838435449723, 'alpha': 0.20926619366832333, 'colsample_bytree': 0.9169799718661967, 'subsample': 0.9503294326556384, 'min_child_weight': 3}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:33,123]\u001b[0m Trial 195 finished with value: 0.9164420485175202 and parameters: {'eta': 0.1, 'max_depth': 8, 'lambda': 0.13430490705154313, 'alpha': 0.40103806426928046, 'colsample_bytree': 0.9298594388192893, 'subsample': 0.997641657625565, 'min_child_weight': 4}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:33,570]\u001b[0m Trial 196 finished with value: 0.9097035040431267 and parameters: {'eta': 0.1, 'max_depth': 8, 'lambda': 0.12594876466015298, 'alpha': 0.07630628915214724, 'colsample_bytree': 0.8722417213128925, 'subsample': 0.9675120344363975, 'min_child_weight': 3}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:34,042]\u001b[0m Trial 197 finished with value: 0.9110512129380054 and parameters: {'eta': 0.1, 'max_depth': 8, 'lambda': 0.0982227712065494, 'alpha': 0.5871552199966492, 'colsample_bytree': 0.9077360640413645, 'subsample': 0.928411014421226, 'min_child_weight': 5}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:34,428]\u001b[0m Trial 198 finished with value: 0.9083557951482479 and parameters: {'eta': 0.1, 'max_depth': 7, 'lambda': 0.042431657581803874, 'alpha': 0.08244670381293806, 'colsample_bytree': 0.8354826873078939, 'subsample': 0.9509500286450454, 'min_child_weight': 8}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:35,254]\u001b[0m Trial 199 finished with value: 0.921832884097035 and parameters: {'eta': 0.1, 'max_depth': 8, 'lambda': 0.006669042032828116, 'alpha': 0.1415061523796011, 'colsample_bytree': 0.8939056989601011, 'subsample': 0.9387979813912146, 'min_child_weight': 1}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:35,715]\u001b[0m Trial 200 finished with value: 0.9164420485175203 and parameters: {'eta': 0.1, 'max_depth': 7, 'lambda': 0.016889004323217674, 'alpha': 0.3214723055809592, 'colsample_bytree': 0.9392215214633267, 'subsample': 0.9867379066837554, 'min_child_weight': 6}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:36,144]\u001b[0m Trial 201 finished with value: 0.917789757412399 and parameters: {'eta': 0.1, 'max_depth': 8, 'lambda': 0.057520589612296044, 'alpha': 0.12335586210018194, 'colsample_bytree': 0.9224051123828981, 'subsample': 0.9669942388764208, 'min_child_weight': 5}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:36,515]\u001b[0m Trial 202 finished with value: 0.9285714285714286 and parameters: {'eta': 0.1, 'max_depth': 8, 'lambda': 0.19574961268794744, 'alpha': 0.05698391826221615, 'colsample_bytree': 0.8847432473649066, 'subsample': 0.9440953580306877, 'min_child_weight': 6}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:37,053]\u001b[0m Trial 203 finished with value: 0.9029649595687332 and parameters: {'eta': 0.1, 'max_depth': 8, 'lambda': 0.16062828879307475, 'alpha': 0.06369047848337582, 'colsample_bytree': 0.8871592728714844, 'subsample': 0.9771885287924285, 'min_child_weight': 3}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:37,410]\u001b[0m Trial 204 finished with value: 0.9150943396226416 and parameters: {'eta': 0.1, 'max_depth': 7, 'lambda': 0.4177447035378501, 'alpha': 0.0518387233448859, 'colsample_bytree': 0.8635650522538448, 'subsample': 0.9425534129835335, 'min_child_weight': 7}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:38,006]\u001b[0m Trial 205 finished with value: 0.9056603773584906 and parameters: {'eta': 0.1, 'max_depth': 8, 'lambda': 0.0805488412029389, 'alpha': 0.19178877181497628, 'colsample_bytree': 0.9057164539194773, 'subsample': 0.9962067196111246, 'min_child_weight': 3}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:38,370]\u001b[0m Trial 206 finished with value: 0.921832884097035 and parameters: {'eta': 0.1, 'max_depth': 8, 'lambda': 0.21306439401418206, 'alpha': 0.11387888918342068, 'colsample_bytree': 0.9180593292607634, 'subsample': 0.9249655092285102, 'min_child_weight': 7}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:38,607]\u001b[0m Trial 207 finished with value: 0.8962264150943396 and parameters: {'eta': 0.1, 'max_depth': 8, 'lambda': 0.029262595080879295, 'alpha': 0.08806253286405193, 'colsample_bytree': 0.8805680029045427, 'subsample': 0.962683428858474, 'min_child_weight': 10}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:39,000]\u001b[0m Trial 208 finished with value: 0.8463611859838275 and parameters: {'eta': 0.0125, 'max_depth': 8, 'lambda': 0.3476728837289289, 'alpha': 0.024327809616385934, 'colsample_bytree': 0.9422069391455001, 'subsample': 0.9449729069952842, 'min_child_weight': 5}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:39,313]\u001b[0m Trial 209 finished with value: 0.9218328840970351 and parameters: {'eta': 0.1, 'max_depth': 7, 'lambda': 0.8728210550637041, 'alpha': 0.04482812708897042, 'colsample_bytree': 0.891380486015844, 'subsample': 0.9555167342799747, 'min_child_weight': 9}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:40,144]\u001b[0m Trial 210 finished with value: 0.8692722371967655 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 0.05048015173699018, 'alpha': 0.22587288343702086, 'colsample_bytree': 0.9021641635105794, 'subsample': 0.32767676791881545, 'min_child_weight': 1}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:40,672]\u001b[0m Trial 211 finished with value: 0.931266846361186 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 4.273214240737524e-07, 'alpha': 0.027165328893302032, 'colsample_bytree': 0.930019171287044, 'subsample': 0.8172040655524274, 'min_child_weight': 7}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:41,157]\u001b[0m Trial 212 finished with value: 0.9204851752021564 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 0.1714892034567444, 'alpha': 0.04004760551907222, 'colsample_bytree': 0.9316250283009978, 'subsample': 0.8155833836208264, 'min_child_weight': 7}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:41,765]\u001b[0m Trial 213 finished with value: 0.9137466307277627 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 3.0473883672347983, 'alpha': 0.1183798651991431, 'colsample_bytree': 0.9209230329820384, 'subsample': 0.8019259707078567, 'min_child_weight': 8}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:42,246]\u001b[0m Trial 214 finished with value: 0.9150943396226415 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 7.566710010119055e-07, 'alpha': 0.025216123306610157, 'colsample_bytree': 0.9444236341869764, 'subsample': 0.9217117904462178, 'min_child_weight': 5}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:42,948]\u001b[0m Trial 215 finished with value: 0.9110512129380054 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 0.10072391573009004, 'alpha': 0.4449134547711131, 'colsample_bytree': 0.9144932014379319, 'subsample': 0.9787248667699041, 'min_child_weight': 4}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:43,756]\u001b[0m Trial 216 finished with value: 0.9083557951482479 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 4.6002967145392294e-07, 'alpha': 0.2886101594434362, 'colsample_bytree': 0.9271301470924556, 'subsample': 0.9815981035279207, 'min_child_weight': 3}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:44,575]\u001b[0m Trial 217 finished with value: 0.9231805929919138 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 0.2662901414265995, 'alpha': 0.01169231278317321, 'colsample_bytree': 0.9480960621845949, 'subsample': 0.9992063754499129, 'min_child_weight': 5}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:45,026]\u001b[0m Trial 218 finished with value: 0.9164420485175202 and parameters: {'eta': 0.05, 'max_depth': 7, 'lambda': 0.0573178331299697, 'alpha': 0.06552899770125158, 'colsample_bytree': 0.9055486879216902, 'subsample': 0.8247748293699946, 'min_child_weight': 11}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:45,947]\u001b[0m Trial 219 finished with value: 0.894878706199461 and parameters: {'eta': 0.025, 'max_depth': 8, 'lambda': 0.07978341214762047, 'alpha': 0.19237007243245896, 'colsample_bytree': 0.8745005168990657, 'subsample': 0.9400691416720259, 'min_child_weight': 1}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:46,471]\u001b[0m Trial 220 finished with value: 0.9056603773584906 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 3.1223461954625855e-07, 'alpha': 0.028513064007956064, 'colsample_bytree': 0.9597123659693061, 'subsample': 0.9604632554828504, 'min_child_weight': 7}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:47,010]\u001b[0m Trial 221 finished with value: 0.9070080862533693 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 1.1848439367527699e-07, 'alpha': 0.05027686233824397, 'colsample_bytree': 0.9332292543897772, 'subsample': 0.7917353816898579, 'min_child_weight': 6}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:47,847]\u001b[0m Trial 222 finished with value: 0.9164420485175202 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 6.3589037261865e-07, 'alpha': 0.015020334274581505, 'colsample_bytree': 0.9134164749051481, 'subsample': 0.9695505906937927, 'min_child_weight': 3}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:48,257]\u001b[0m Trial 223 finished with value: 0.9204851752021563 and parameters: {'eta': 0.05, 'max_depth': 7, 'lambda': 0.1161682207591493, 'alpha': 0.14622906090027413, 'colsample_bytree': 0.8958121952713707, 'subsample': 0.9815858807814065, 'min_child_weight': 9}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:49,231]\u001b[0m Trial 224 finished with value: 0.9070080862533693 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 3.760572572938556e-07, 'alpha': 0.07831570410356412, 'colsample_bytree': 0.9256592521225204, 'subsample': 0.958451426305289, 'min_child_weight': 4}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:49,818]\u001b[0m Trial 225 finished with value: 0.9272237196765498 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 0.16653535429081837, 'alpha': 5.867216173201165e-07, 'colsample_bytree': 0.9404290619607969, 'subsample': 0.8395785060322077, 'min_child_weight': 6}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:50,293]\u001b[0m Trial 226 finished with value: 0.9123989218328842 and parameters: {'eta': 0.05, 'max_depth': 2, 'lambda': 0.17129508647191452, 'alpha': 0.03247337305653503, 'colsample_bytree': 0.938139649986669, 'subsample': 0.8330666423856168, 'min_child_weight': 6}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:50,785]\u001b[0m Trial 227 finished with value: 0.8402964959568733 and parameters: {'eta': 0.05, 'max_depth': 8, 'lambda': 0.5581067526995195, 'alpha': 1.0017483131857183, 'colsample_bytree': 0.9143676618500656, 'subsample': 0.8215898536261472, 'min_child_weight': 2}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:51,076]\u001b[0m Trial 228 finished with value: 0.9339622641509435 and parameters: {'eta': 0.1, 'max_depth': 7, 'lambda': 0.014392207411099226, 'alpha': 0.09825567660179944, 'colsample_bytree': 0.9695582928864337, 'subsample': 0.8083094048983862, 'min_child_weight': 8}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:51,542]\u001b[0m Trial 229 finished with value: 0.9326145552560647 and parameters: {'eta': 0.1, 'max_depth': 7, 'lambda': 0.011064151913165106, 'alpha': 1.217209703714586e-07, 'colsample_bytree': 0.9739866420448201, 'subsample': 0.8184846036805362, 'min_child_weight': 6}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:52,010]\u001b[0m Trial 230 finished with value: 0.9258760107816713 and parameters: {'eta': 0.1, 'max_depth': 6, 'lambda': 0.023531584328337334, 'alpha': 1.4693783153359178e-07, 'colsample_bytree': 0.9681046850904811, 'subsample': 0.84068019450884, 'min_child_weight': 7}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:52,569]\u001b[0m Trial 231 finished with value: 0.9204851752021563 and parameters: {'eta': 0.1, 'max_depth': 6, 'lambda': 0.006037133981963991, 'alpha': 6.12357254250352e-08, 'colsample_bytree': 0.976406066019033, 'subsample': 0.8412281748652474, 'min_child_weight': 6}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:53,036]\u001b[0m Trial 232 finished with value: 0.9326145552560647 and parameters: {'eta': 0.1, 'max_depth': 7, 'lambda': 0.012474130981588432, 'alpha': 5.855526908728692e-07, 'colsample_bytree': 0.9869210512578225, 'subsample': 0.8166295025724454, 'min_child_weight': 7}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:53,344]\u001b[0m Trial 233 finished with value: 0.9231805929919138 and parameters: {'eta': 0.1, 'max_depth': 6, 'lambda': 0.013197697566489416, 'alpha': 1.184530469263401e-07, 'colsample_bytree': 0.9864633491330814, 'subsample': 0.8143238152194241, 'min_child_weight': 8}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:53,892]\u001b[0m Trial 234 finished with value: 0.9164420485175202 and parameters: {'eta': 0.1, 'max_depth': 7, 'lambda': 0.009804566739404766, 'alpha': 5.947077715169246e-07, 'colsample_bytree': 0.968923360921318, 'subsample': 0.8482668165258344, 'min_child_weight': 3}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:54,007]\u001b[0m Trial 235 finished with value: 0.7466307277628033 and parameters: {'eta': 0.1, 'max_depth': 7, 'lambda': 0.017523695629628612, 'alpha': 1.0627779215796374e-06, 'colsample_bytree': 0.987058826573443, 'subsample': 0.8160899793292373, 'min_child_weight': 57}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:54,377]\u001b[0m Trial 236 finished with value: 0.9299191374663073 and parameters: {'eta': 0.1, 'max_depth': 7, 'lambda': 0.026511392782280357, 'alpha': 2.867017985552781e-07, 'colsample_bytree': 0.9932953294090964, 'subsample': 0.8433115712313889, 'min_child_weight': 6}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "\u001b[32m[I 2021-08-13 17:55:54,950]\u001b[0m Trial 237 finished with value: 0.908355795148248 and parameters: {'eta': 0.1, 'max_depth': 7, 'lambda': 0.021769336465006155, 'alpha': 2.937786679212829e-07, 'colsample_bytree': 0.9680912150870334, 'subsample': 0.8314663838388643, 'min_child_weight': 6}. Best is trial 85 with value: 0.940700808625337.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_Optuna_Xgboost auc 0.861304 trained in 23.94 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-13 17:56:33,875]\u001b[0m A new study created in memory with name: no-name-70969cf3-7c81-4088-87a8-192c53a6b1af\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna optimizes CatBoost with time budget 120 seconds eval_metric auc (maximize)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-13 17:56:39,466]\u001b[0m Trial 0 finished with value: 0.8679245283018868 and parameters: {'learning_rate': 0.1, 'depth': 8, 'l2_leaf_reg': 7.7997800836072235, 'random_strength': 2.7259260601004898, 'rsm': 0.34881782962878705, 'min_data_in_leaf': 81}. Best is trial 0 with value: 0.8679245283018868.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:56:41,402]\u001b[0m Trial 1 finished with value: 0.8921832884097034 and parameters: {'learning_rate': 0.05, 'depth': 6, 'l2_leaf_reg': 6.834661005427845, 'random_strength': 7.127020272701981, 'rsm': 0.43322567931135547, 'min_data_in_leaf': 57}. Best is trial 1 with value: 0.8921832884097034.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:56:42,243]\u001b[0m Trial 2 finished with value: 0.8342318059299192 and parameters: {'learning_rate': 0.2, 'depth': 9, 'l2_leaf_reg': 3.648923350415333, 'random_strength': 6.1539617881809745, 'rsm': 0.16784311747867892, 'min_data_in_leaf': 37}. Best is trial 1 with value: 0.8921832884097034.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:56:47,267]\u001b[0m Trial 3 finished with value: 0.9164420485175202 and parameters: {'learning_rate': 0.05, 'depth': 8, 'l2_leaf_reg': 3.168429538076496, 'random_strength': 5.6809865305797045, 'rsm': 0.8822146506051032, 'min_data_in_leaf': 44}. Best is trial 3 with value: 0.9164420485175202.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:56:48,772]\u001b[0m Trial 4 finished with value: 0.8854447439353099 and parameters: {'learning_rate': 0.05, 'depth': 7, 'l2_leaf_reg': 2.1879991775303185, 'random_strength': 9.248676286906974, 'rsm': 0.49792667986375894, 'min_data_in_leaf': 91}. Best is trial 3 with value: 0.9164420485175202.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:56:49,082]\u001b[0m Trial 5 finished with value: 0.8423180592991913 and parameters: {'learning_rate': 0.1, 'depth': 7, 'l2_leaf_reg': 5.946288336866495, 'random_strength': 5.333101634654404, 'rsm': 0.13899165642532316, 'min_data_in_leaf': 57}. Best is trial 3 with value: 0.9164420485175202.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:56:50,346]\u001b[0m Trial 6 finished with value: 0.9245283018867925 and parameters: {'learning_rate': 0.1, 'depth': 6, 'l2_leaf_reg': 5.659489836041009, 'random_strength': 0.06764062983238726, 'rsm': 0.6556975379238673, 'min_data_in_leaf': 92}. Best is trial 6 with value: 0.9245283018867925.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:56:55,770]\u001b[0m Trial 7 finished with value: 0.9056603773584906 and parameters: {'learning_rate': 0.1, 'depth': 8, 'l2_leaf_reg': 2.8525810751490956, 'random_strength': 6.2491670568099424, 'rsm': 0.5302844161036071, 'min_data_in_leaf': 20}. Best is trial 6 with value: 0.9245283018867925.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:02,928]\u001b[0m Trial 8 finished with value: 0.866576819407008 and parameters: {'learning_rate': 0.2, 'depth': 9, 'l2_leaf_reg': 1.2395146105995811, 'random_strength': 1.1938089880686749, 'rsm': 0.7646707505290121, 'min_data_in_leaf': 59}. Best is trial 6 with value: 0.9245283018867925.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:03,998]\u001b[0m Trial 9 finished with value: 0.7951482479784366 and parameters: {'learning_rate': 0.05, 'depth': 9, 'l2_leaf_reg': 4.167593702673152, 'random_strength': 5.358516629957641, 'rsm': 0.10558766492841647, 'min_data_in_leaf': 31}. Best is trial 6 with value: 0.9245283018867925.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:04,209]\u001b[0m Trial 10 finished with value: 0.8928571428571428 and parameters: {'learning_rate': 0.1, 'depth': 3, 'l2_leaf_reg': 9.911963296739815, 'random_strength': 0.3347970170504029, 'rsm': 0.7164918656185764, 'min_data_in_leaf': 4}. Best is trial 6 with value: 0.9245283018867925.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:05,825]\u001b[0m Trial 11 finished with value: 0.9272237196765498 and parameters: {'learning_rate': 0.05, 'depth': 4, 'l2_leaf_reg': 0.47798893667296616, 'random_strength': 3.3833310011892364, 'rsm': 0.9683057858638483, 'min_data_in_leaf': 77}. Best is trial 11 with value: 0.9272237196765498.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:07,219]\u001b[0m Trial 12 finished with value: 0.9299191374663073 and parameters: {'learning_rate': 0.1, 'depth': 4, 'l2_leaf_reg': 0.25403904633187346, 'random_strength': 2.971268695537766, 'rsm': 0.9830959398575527, 'min_data_in_leaf': 77}. Best is trial 12 with value: 0.9299191374663073.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:08,342]\u001b[0m Trial 13 finished with value: 0.9110512129380054 and parameters: {'learning_rate': 0.05, 'depth': 3, 'l2_leaf_reg': 0.28695323805051576, 'random_strength': 3.270761905767126, 'rsm': 0.9921189946174719, 'min_data_in_leaf': 70}. Best is trial 12 with value: 0.9299191374663073.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:09,401]\u001b[0m Trial 14 finished with value: 0.9150943396226416 and parameters: {'learning_rate': 0.2, 'depth': 4, 'l2_leaf_reg': 0.18272508279217214, 'random_strength': 3.2837120717276673, 'rsm': 0.9952611730146825, 'min_data_in_leaf': 75}. Best is trial 12 with value: 0.9299191374663073.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:10,796]\u001b[0m Trial 15 finished with value: 0.9110512129380054 and parameters: {'learning_rate': 0.05, 'depth': 4, 'l2_leaf_reg': 1.404405143392601, 'random_strength': 1.9506173875479333, 'rsm': 0.8675586930291345, 'min_data_in_leaf': 96}. Best is trial 12 with value: 0.9299191374663073.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:11,104]\u001b[0m Trial 16 finished with value: 0.8557951482479784 and parameters: {'learning_rate': 0.1, 'depth': 2, 'l2_leaf_reg': 1.8099431794037502, 'random_strength': 3.819811954996628, 'rsm': 0.869273456215566, 'min_data_in_leaf': 68}. Best is trial 12 with value: 0.9299191374663073.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:11,949]\u001b[0m Trial 17 finished with value: 0.9258760107816713 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 0.19961495716924743, 'random_strength': 4.345334659591927, 'rsm': 0.6295497398915594, 'min_data_in_leaf': 82}. Best is trial 12 with value: 0.9299191374663073.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:12,532]\u001b[0m Trial 18 finished with value: 0.8800539083557952 and parameters: {'learning_rate': 0.05, 'depth': 4, 'l2_leaf_reg': 4.381213880329777, 'random_strength': 1.9292589368056445, 'rsm': 0.7698163010966759, 'min_data_in_leaf': 100}. Best is trial 12 with value: 0.9299191374663073.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:12,924]\u001b[0m Trial 19 finished with value: 0.8598382749326146 and parameters: {'learning_rate': 0.2, 'depth': 2, 'l2_leaf_reg': 1.2168678351274202, 'random_strength': 8.349249835905592, 'rsm': 0.9302022334248801, 'min_data_in_leaf': 82}. Best is trial 12 with value: 0.9299191374663073.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:14,495]\u001b[0m Trial 20 finished with value: 0.9016172506738545 and parameters: {'learning_rate': 0.05, 'depth': 5, 'l2_leaf_reg': 2.533137177969286, 'random_strength': 4.461260009709926, 'rsm': 0.8108584283237494, 'min_data_in_leaf': 64}. Best is trial 12 with value: 0.9299191374663073.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:15,899]\u001b[0m Trial 21 finished with value: 0.9097035040431267 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 0.12607384298116056, 'random_strength': 4.471498242958894, 'rsm': 0.3056746638321901, 'min_data_in_leaf': 83}. Best is trial 12 with value: 0.9299191374663073.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:16,977]\u001b[0m Trial 22 finished with value: 0.9137466307277629 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 0.9060245683476194, 'random_strength': 2.3364616536253484, 'rsm': 0.6212608206078378, 'min_data_in_leaf': 75}. Best is trial 12 with value: 0.9299191374663073.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:17,443]\u001b[0m Trial 23 finished with value: 0.8827493261455526 and parameters: {'learning_rate': 0.1, 'depth': 3, 'l2_leaf_reg': 0.7166233552499751, 'random_strength': 4.027164286788361, 'rsm': 0.6404442445612201, 'min_data_in_leaf': 84}. Best is trial 12 with value: 0.9299191374663073.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:19,079]\u001b[0m Trial 24 finished with value: 0.9070080862533694 and parameters: {'learning_rate': 0.1, 'depth': 4, 'l2_leaf_reg': 2.1598326172126066, 'random_strength': 1.3162374836132373, 'rsm': 0.9314196497872308, 'min_data_in_leaf': 49}. Best is trial 12 with value: 0.9299191374663073.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:20,210]\u001b[0m Trial 25 finished with value: 0.9056603773584906 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 1.7617042271842105, 'random_strength': 2.786867582469479, 'rsm': 0.7055677455018313, 'min_data_in_leaf': 89}. Best is trial 12 with value: 0.9299191374663073.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:22,185]\u001b[0m Trial 26 finished with value: 0.8827493261455526 and parameters: {'learning_rate': 0.1, 'depth': 6, 'l2_leaf_reg': 0.7333227958067866, 'random_strength': 4.628002551581724, 'rsm': 0.8141186748693624, 'min_data_in_leaf': 74}. Best is trial 12 with value: 0.9299191374663073.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:23,084]\u001b[0m Trial 27 finished with value: 0.9150943396226415 and parameters: {'learning_rate': 0.05, 'depth': 3, 'l2_leaf_reg': 0.022500775465766787, 'random_strength': 3.439696958532771, 'rsm': 0.9331827199363211, 'min_data_in_leaf': 67}. Best is trial 12 with value: 0.9299191374663073.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:24,027]\u001b[0m Trial 28 finished with value: 0.9097035040431267 and parameters: {'learning_rate': 0.1, 'depth': 4, 'l2_leaf_reg': 9.250673139022663, 'random_strength': 1.185034328050281, 'rsm': 0.5794477752135797, 'min_data_in_leaf': 78}. Best is trial 12 with value: 0.9299191374663073.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:25,591]\u001b[0m Trial 29 finished with value: 0.8854447439353099 and parameters: {'learning_rate': 0.2, 'depth': 7, 'l2_leaf_reg': 7.745860965962327, 'random_strength': 2.827844778521193, 'rsm': 0.28277169681749215, 'min_data_in_leaf': 87}. Best is trial 12 with value: 0.9299191374663073.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:26,088]\u001b[0m Trial 30 finished with value: 0.9258760107816713 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 3.5652441548485028, 'random_strength': 6.708027948418464, 'rsm': 0.38974274706914225, 'min_data_in_leaf': 62}. Best is trial 12 with value: 0.9299191374663073.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:26,844]\u001b[0m Trial 31 finished with value: 0.8935309973045822 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 3.4482660316378424, 'random_strength': 8.09907721752617, 'rsm': 0.4256163548512911, 'min_data_in_leaf': 63}. Best is trial 12 with value: 0.9299191374663073.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:28,484]\u001b[0m Trial 32 finished with value: 0.8652291105121294 and parameters: {'learning_rate': 0.1, 'depth': 6, 'l2_leaf_reg': 4.982948517877663, 'random_strength': 7.1219779097957305, 'rsm': 0.41553385056768966, 'min_data_in_leaf': 51}. Best is trial 12 with value: 0.9299191374663073.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:28,858]\u001b[0m Trial 33 finished with value: 0.8962264150943398 and parameters: {'learning_rate': 0.1, 'depth': 4, 'l2_leaf_reg': 0.7261578320685482, 'random_strength': 6.773180827739019, 'rsm': 0.2126106514258354, 'min_data_in_leaf': 71}. Best is trial 12 with value: 0.9299191374663073.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:29,626]\u001b[0m Trial 34 finished with value: 0.8975741239892184 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 6.498468210351397, 'random_strength': 6.248915258889861, 'rsm': 0.36936724884286815, 'min_data_in_leaf': 78}. Best is trial 12 with value: 0.9299191374663073.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:30,012]\u001b[0m Trial 35 finished with value: 0.894878706199461 and parameters: {'learning_rate': 0.05, 'depth': 3, 'l2_leaf_reg': 2.62393525949138, 'random_strength': 7.821270168676114, 'rsm': 0.48488476155695226, 'min_data_in_leaf': 60}. Best is trial 12 with value: 0.9299191374663073.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:30,881]\u001b[0m Trial 36 finished with value: 0.9339622641509434 and parameters: {'learning_rate': 0.1, 'depth': 4, 'l2_leaf_reg': 1.7421670336215103, 'random_strength': 5.613145582823337, 'rsm': 0.34833551155108716, 'min_data_in_leaf': 49}. Best is trial 36 with value: 0.9339622641509434.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:31,157]\u001b[0m Trial 37 finished with value: 0.9164420485175202 and parameters: {'learning_rate': 0.05, 'depth': 4, 'l2_leaf_reg': 1.814114016694802, 'random_strength': 5.059337049472666, 'rsm': 0.23398331893077573, 'min_data_in_leaf': 40}. Best is trial 36 with value: 0.9339622641509434.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:31,492]\u001b[0m Trial 38 finished with value: 0.894878706199461 and parameters: {'learning_rate': 0.1, 'depth': 2, 'l2_leaf_reg': 0.6281276769101882, 'random_strength': 3.948897370324695, 'rsm': 0.4563868231012046, 'min_data_in_leaf': 31}. Best is trial 36 with value: 0.9339622641509434.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:32,696]\u001b[0m Trial 39 finished with value: 0.8989218328840971 and parameters: {'learning_rate': 0.2, 'depth': 6, 'l2_leaf_reg': 3.435733434344826, 'random_strength': 5.798980301290417, 'rsm': 0.3631688765632643, 'min_data_in_leaf': 54}. Best is trial 36 with value: 0.9339622641509434.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:33,036]\u001b[0m Trial 40 finished with value: 0.8800539083557951 and parameters: {'learning_rate': 0.1, 'depth': 3, 'l2_leaf_reg': 4.357333771742843, 'random_strength': 9.51402047804788, 'rsm': 0.29920593993249667, 'min_data_in_leaf': 44}. Best is trial 36 with value: 0.9339622641509434.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:34,020]\u001b[0m Trial 41 finished with value: 0.9326145552560647 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 1.318425807325784, 'random_strength': 5.820095527797375, 'rsm': 0.38025555645194126, 'min_data_in_leaf': 93}. Best is trial 36 with value: 0.9339622641509434.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:35,096]\u001b[0m Trial 42 finished with value: 0.950134770889488 and parameters: {'learning_rate': 0.1, 'depth': 4, 'l2_leaf_reg': 2.9761803947658567, 'random_strength': 5.702451600143675, 'rsm': 0.548256504400775, 'min_data_in_leaf': 93}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:35,369]\u001b[0m Trial 43 finished with value: 0.9204851752021563 and parameters: {'learning_rate': 0.1, 'depth': 4, 'l2_leaf_reg': 1.503366502350518, 'random_strength': 5.559524937677374, 'rsm': 0.5422410922649827, 'min_data_in_leaf': 94}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:35,991]\u001b[0m Trial 44 finished with value: 0.9420485175202156 and parameters: {'learning_rate': 0.1, 'depth': 4, 'l2_leaf_reg': 2.292669473595875, 'random_strength': 4.940891212182023, 'rsm': 0.5067334432480681, 'min_data_in_leaf': 99}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:36,217]\u001b[0m Trial 45 finished with value: 0.9393530997304583 and parameters: {'learning_rate': 0.1, 'depth': 3, 'l2_leaf_reg': 2.963789294145684, 'random_strength': 5.037518005207602, 'rsm': 0.4895696702092456, 'min_data_in_leaf': 98}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:36,457]\u001b[0m Trial 46 finished with value: 0.8652291105121294 and parameters: {'learning_rate': 0.1, 'depth': 3, 'l2_leaf_reg': 2.966408888678788, 'random_strength': 5.064608879153496, 'rsm': 0.5105349651189411, 'min_data_in_leaf': 99}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:36,786]\u001b[0m Trial 47 finished with value: 0.8706199460916443 and parameters: {'learning_rate': 0.1, 'depth': 3, 'l2_leaf_reg': 2.428549758527545, 'random_strength': 6.107007162718291, 'rsm': 0.5763675967573947, 'min_data_in_leaf': 90}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:37,128]\u001b[0m Trial 48 finished with value: 0.866576819407008 and parameters: {'learning_rate': 0.1, 'depth': 2, 'l2_leaf_reg': 3.0323411605493207, 'random_strength': 5.802459435638395, 'rsm': 0.46776715306358063, 'min_data_in_leaf': 95}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:39,298]\u001b[0m Trial 49 finished with value: 0.908355795148248 and parameters: {'learning_rate': 0.1, 'depth': 7, 'l2_leaf_reg': 1.851467930654666, 'random_strength': 5.224463871837185, 'rsm': 0.33097771315370644, 'min_data_in_leaf': 15}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:39,734]\u001b[0m Trial 50 finished with value: 0.8584905660377358 and parameters: {'learning_rate': 0.1, 'depth': 4, 'l2_leaf_reg': 3.984922316244421, 'random_strength': 6.5667670719731595, 'rsm': 0.5784122896660272, 'min_data_in_leaf': 100}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:39,948]\u001b[0m Trial 51 finished with value: 0.8483827493261455 and parameters: {'learning_rate': 0.1, 'depth': 4, 'l2_leaf_reg': 1.1332489946012088, 'random_strength': 4.865505018376134, 'rsm': 0.5055319341855449, 'min_data_in_leaf': 92}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:40,381]\u001b[0m Trial 52 finished with value: 0.9218328840970351 and parameters: {'learning_rate': 0.1, 'depth': 3, 'l2_leaf_reg': 2.3134504965828415, 'random_strength': 7.504371762161963, 'rsm': 0.4028960480797568, 'min_data_in_leaf': 87}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:40,790]\u001b[0m Trial 53 finished with value: 0.8881401617250674 and parameters: {'learning_rate': 0.1, 'depth': 4, 'l2_leaf_reg': 1.4190816015066203, 'random_strength': 5.61766154252647, 'rsm': 0.4402997667214976, 'min_data_in_leaf': 93}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:41,083]\u001b[0m Trial 54 finished with value: 0.9164420485175202 and parameters: {'learning_rate': 0.1, 'depth': 3, 'l2_leaf_reg': 2.0797436040979287, 'random_strength': 5.951889376046031, 'rsm': 0.24249428243538884, 'min_data_in_leaf': 97}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:42,114]\u001b[0m Trial 55 finished with value: 0.9056603773584906 and parameters: {'learning_rate': 0.2, 'depth': 5, 'l2_leaf_reg': 4.910673024401987, 'random_strength': 8.696991167600109, 'rsm': 0.6776680293111573, 'min_data_in_leaf': 87}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:42,614]\u001b[0m Trial 56 finished with value: 0.9191374663072777 and parameters: {'learning_rate': 0.1, 'depth': 4, 'l2_leaf_reg': 2.733451658279727, 'random_strength': 7.233269971747679, 'rsm': 0.34019860154804304, 'min_data_in_leaf': 33}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:43,250]\u001b[0m Trial 57 finished with value: 0.9231805929919138 and parameters: {'learning_rate': 0.1, 'depth': 4, 'l2_leaf_reg': 1.0708811359677286, 'random_strength': 4.798327237345052, 'rsm': 0.5362240683653117, 'min_data_in_leaf': 96}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:44,183]\u001b[0m Trial 58 finished with value: 0.8827493261455526 and parameters: {'learning_rate': 0.1, 'depth': 6, 'l2_leaf_reg': 1.5390990908015745, 'random_strength': 4.268574109536761, 'rsm': 0.17228577380202753, 'min_data_in_leaf': 90}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:44,972]\u001b[0m Trial 59 finished with value: 0.944743935309973 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 3.89913535544581, 'random_strength': 6.475064695985213, 'rsm': 0.47656240257872595, 'min_data_in_leaf': 100}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:46,442]\u001b[0m Trial 60 finished with value: 0.9043126684636119 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 3.8148204469646814, 'random_strength': 5.3776492991960465, 'rsm': 0.6003662732591316, 'min_data_in_leaf': 100}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:47,411]\u001b[0m Trial 61 finished with value: 0.950134770889488 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 3.087601510590643, 'random_strength': 6.476680040162735, 'rsm': 0.4780008297223657, 'min_data_in_leaf': 85}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:49,187]\u001b[0m Trial 62 finished with value: 0.8854447439353099 and parameters: {'learning_rate': 0.1, 'depth': 6, 'l2_leaf_reg': 3.2397326171600414, 'random_strength': 6.539267050265408, 'rsm': 0.4775845568631955, 'min_data_in_leaf': 97}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:50,614]\u001b[0m Trial 63 finished with value: 0.8706199460916442 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 4.669843999801792, 'random_strength': 6.299076041008764, 'rsm': 0.5148266729932341, 'min_data_in_leaf': 85}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:51,020]\u001b[0m Trial 64 finished with value: 0.8652291105121294 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 3.1251491355467547, 'random_strength': 7.008111822803828, 'rsm': 0.4390421621022787, 'min_data_in_leaf': 93}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:51,459]\u001b[0m Trial 65 finished with value: 0.9326145552560647 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 3.977364367308217, 'random_strength': 5.459265941979423, 'rsm': 0.38703943565022414, 'min_data_in_leaf': 80}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:52,541]\u001b[0m Trial 66 finished with value: 0.8773584905660378 and parameters: {'learning_rate': 0.2, 'depth': 5, 'l2_leaf_reg': 5.451065091414697, 'random_strength': 5.445771681593415, 'rsm': 0.5543100357562541, 'min_data_in_leaf': 80}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:52,988]\u001b[0m Trial 67 finished with value: 0.8692722371967655 and parameters: {'learning_rate': 0.1, 'depth': 4, 'l2_leaf_reg': 3.9984849457435176, 'random_strength': 6.345777259843516, 'rsm': 0.46405605864508354, 'min_data_in_leaf': 45}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:55,117]\u001b[0m Trial 68 finished with value: 0.8800539083557952 and parameters: {'learning_rate': 0.1, 'depth': 6, 'l2_leaf_reg': 2.738361711780728, 'random_strength': 5.968044085195158, 'rsm': 0.4937971876034634, 'min_data_in_leaf': 90}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:55,613]\u001b[0m Trial 69 finished with value: 0.8652291105121294 and parameters: {'learning_rate': 0.1, 'depth': 4, 'l2_leaf_reg': 3.5532625729042024, 'random_strength': 4.1875531811829765, 'rsm': 0.4089437420954841, 'min_data_in_leaf': 84}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:55,855]\u001b[0m Trial 70 finished with value: 0.894878706199461 and parameters: {'learning_rate': 0.1, 'depth': 3, 'l2_leaf_reg': 5.2713349201491555, 'random_strength': 7.439497205115473, 'rsm': 0.5602375144569497, 'min_data_in_leaf': 81}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:56,767]\u001b[0m Trial 71 finished with value: 0.9353099730458221 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 2.1146540776183516, 'random_strength': 4.656978855944884, 'rsm': 0.3779926858208607, 'min_data_in_leaf': 96}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:57,296]\u001b[0m Trial 72 finished with value: 0.8908355795148248 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 2.1010109164001762, 'random_strength': 4.670597905341465, 'rsm': 0.32877264058750755, 'min_data_in_leaf': 97}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:57:57,930]\u001b[0m Trial 73 finished with value: 0.9299191374663074 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 2.4829099496368463, 'random_strength': 3.6256673889552102, 'rsm': 0.37093495343485217, 'min_data_in_leaf': 94}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:00,259]\u001b[0m Trial 74 finished with value: 0.9083557951482479 and parameters: {'learning_rate': 0.1, 'depth': 6, 'l2_leaf_reg': 3.257814393584666, 'random_strength': 5.27490872735542, 'rsm': 0.4444913696011274, 'min_data_in_leaf': 88}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:03,066]\u001b[0m Trial 75 finished with value: 0.9083557951482479 and parameters: {'learning_rate': 0.1, 'depth': 8, 'l2_leaf_reg': 4.485443243626251, 'random_strength': 5.044746711499007, 'rsm': 0.26669199321855064, 'min_data_in_leaf': 98}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:04,034]\u001b[0m Trial 76 finished with value: 0.9218328840970351 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 1.8773723893884544, 'random_strength': 5.806850233275526, 'rsm': 0.5288031222138411, 'min_data_in_leaf': 92}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:04,483]\u001b[0m Trial 77 finished with value: 0.8975741239892183 and parameters: {'learning_rate': 0.1, 'depth': 4, 'l2_leaf_reg': 2.224188002434612, 'random_strength': 6.862666148609456, 'rsm': 0.4218635501636544, 'min_data_in_leaf': 48}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:05,754]\u001b[0m Trial 78 finished with value: 0.8921832884097035 and parameters: {'learning_rate': 0.05, 'depth': 5, 'l2_leaf_reg': 2.6162269426827858, 'random_strength': 6.526085000092311, 'rsm': 0.6021282970126269, 'min_data_in_leaf': 57}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:07,208]\u001b[0m Trial 79 finished with value: 0.8975741239892183 and parameters: {'learning_rate': 0.2, 'depth': 6, 'l2_leaf_reg': 3.8459956938216413, 'random_strength': 4.494855744968296, 'rsm': 0.3944629563260125, 'min_data_in_leaf': 85}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:15,043]\u001b[0m Trial 80 finished with value: 0.8679245283018867 and parameters: {'learning_rate': 0.1, 'depth': 9, 'l2_leaf_reg': 2.8908483475140487, 'random_strength': 6.113104777974524, 'rsm': 0.3501015382703836, 'min_data_in_leaf': 40}. Best is trial 42 with value: 0.950134770889488.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:15,657]\u001b[0m Trial 81 finished with value: 0.954177897574124 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 4.276893155046264, 'random_strength': 5.607364880472886, 'rsm': 0.3771449842004404, 'min_data_in_leaf': 95}. Best is trial 81 with value: 0.954177897574124.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:16,742]\u001b[0m Trial 82 finished with value: 0.9339622641509435 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 4.222224398736463, 'random_strength': 5.570126066288464, 'rsm': 0.3155228643137358, 'min_data_in_leaf': 100}. Best is trial 81 with value: 0.954177897574124.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:17,216]\u001b[0m Trial 83 finished with value: 0.8827493261455526 and parameters: {'learning_rate': 0.1, 'depth': 4, 'l2_leaf_reg': 4.653832620211935, 'random_strength': 4.883089018848241, 'rsm': 0.30378404796621694, 'min_data_in_leaf': 100}. Best is trial 81 with value: 0.954177897574124.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:17,765]\u001b[0m Trial 84 finished with value: 0.8854447439353099 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 4.169426912629405, 'random_strength': 5.134421706075871, 'rsm': 0.26865555752518344, 'min_data_in_leaf': 95}. Best is trial 81 with value: 0.954177897574124.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:18,579]\u001b[0m Trial 85 finished with value: 0.9204851752021563 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 5.926087621173222, 'random_strength': 5.668829967508256, 'rsm': 0.4895824002975143, 'min_data_in_leaf': 98}. Best is trial 81 with value: 0.954177897574124.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:18,882]\u001b[0m Trial 86 finished with value: 0.898921832884097 and parameters: {'learning_rate': 0.1, 'depth': 4, 'l2_leaf_reg': 3.4109399917552268, 'random_strength': 3.7872709283904165, 'rsm': 0.4595015493119762, 'min_data_in_leaf': 91}. Best is trial 81 with value: 0.954177897574124.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:20,092]\u001b[0m Trial 87 finished with value: 0.9204851752021563 and parameters: {'learning_rate': 0.1, 'depth': 6, 'l2_leaf_reg': 3.669001547134875, 'random_strength': 4.106438191606129, 'rsm': 0.3175339720881668, 'min_data_in_leaf': 96}. Best is trial 81 with value: 0.954177897574124.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:20,380]\u001b[0m Trial 88 finished with value: 0.9164420485175203 and parameters: {'learning_rate': 0.1, 'depth': 2, 'l2_leaf_reg': 4.1496725198748, 'random_strength': 4.690087226148424, 'rsm': 0.3538068835684093, 'min_data_in_leaf': 100}. Best is trial 81 with value: 0.954177897574124.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:21,015]\u001b[0m Trial 89 finished with value: 0.9164420485175202 and parameters: {'learning_rate': 0.05, 'depth': 3, 'l2_leaf_reg': 3.127593805196769, 'random_strength': 6.115567375855775, 'rsm': 0.4266034697130321, 'min_data_in_leaf': 23}. Best is trial 81 with value: 0.954177897574124.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:21,840]\u001b[0m Trial 90 finished with value: 0.9029649595687331 and parameters: {'learning_rate': 0.1, 'depth': 4, 'l2_leaf_reg': 2.8633453294694085, 'random_strength': 6.402046626435882, 'rsm': 0.6108183832035856, 'min_data_in_leaf': 53}. Best is trial 81 with value: 0.954177897574124.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:23,260]\u001b[0m Trial 91 finished with value: 0.9231805929919137 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 1.715144734289084, 'random_strength': 5.813174053481464, 'rsm': 0.3744029524307458, 'min_data_in_leaf': 94}. Best is trial 81 with value: 0.954177897574124.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:23,810]\u001b[0m Trial 92 finished with value: 0.9043126684636119 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 2.4026475870209585, 'random_strength': 5.293170614376498, 'rsm': 0.2931626970087509, 'min_data_in_leaf': 91}. Best is trial 81 with value: 0.954177897574124.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:24,695]\u001b[0m Trial 93 finished with value: 0.9097035040431267 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 3.781631647116842, 'random_strength': 5.513930060407338, 'rsm': 0.4034664217114759, 'min_data_in_leaf': 88}. Best is trial 81 with value: 0.954177897574124.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:25,504]\u001b[0m Trial 94 finished with value: 0.9487870619946093 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 4.802824513138255, 'random_strength': 5.518994964758289, 'rsm': 0.5245641762551471, 'min_data_in_leaf': 98}. Best is trial 81 with value: 0.954177897574124.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:27,603]\u001b[0m Trial 95 finished with value: 0.9097035040431267 and parameters: {'learning_rate': 0.1, 'depth': 6, 'l2_leaf_reg': 5.122760773081872, 'random_strength': 4.531278282870328, 'rsm': 0.5149976407479188, 'min_data_in_leaf': 98}. Best is trial 81 with value: 0.954177897574124.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:28,277]\u001b[0m Trial 96 finished with value: 0.917789757412399 and parameters: {'learning_rate': 0.1, 'depth': 4, 'l2_leaf_reg': 4.893023640248798, 'random_strength': 4.989079445693167, 'rsm': 0.5658280839597609, 'min_data_in_leaf': 95}. Best is trial 81 with value: 0.954177897574124.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:29,624]\u001b[0m Trial 97 finished with value: 0.9029649595687331 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 4.301363072618235, 'random_strength': 6.70865170859139, 'rsm': 0.5332830513363097, 'min_data_in_leaf': 97}. Best is trial 81 with value: 0.954177897574124.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:30,231]\u001b[0m Trial 98 finished with value: 0.9097035040431267 and parameters: {'learning_rate': 0.2, 'depth': 4, 'l2_leaf_reg': 4.7408243721565295, 'random_strength': 5.985220032868657, 'rsm': 0.4757738961081612, 'min_data_in_leaf': 100}. Best is trial 81 with value: 0.954177897574124.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:31,271]\u001b[0m Trial 99 finished with value: 0.8989218328840971 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 1.974328757762585, 'random_strength': 5.583098859812409, 'rsm': 0.49992867592832024, 'min_data_in_leaf': 89}. Best is trial 81 with value: 0.954177897574124.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:32,378]\u001b[0m Trial 100 finished with value: 0.9245283018867925 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 3.296076493561556, 'random_strength': 4.3910330161091675, 'rsm': 0.5931913929042963, 'min_data_in_leaf': 86}. Best is trial 81 with value: 0.954177897574124.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:33,186]\u001b[0m Trial 101 finished with value: 0.9299191374663074 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 3.8931907839333997, 'random_strength': 5.316888243414074, 'rsm': 0.4536910865449491, 'min_data_in_leaf': 92}. Best is trial 81 with value: 0.954177897574124.\u001b[0m\n",
      "\u001b[32m[I 2021-08-13 17:58:35,789]\u001b[0m Trial 102 finished with value: 0.9029649595687332 and parameters: {'learning_rate': 0.1, 'depth': 5, 'l2_leaf_reg': 1.2652639776974146, 'random_strength': 5.714885807113744, 'rsm': 0.6350416801873408, 'min_data_in_leaf': 95}. Best is trial 81 with value: 0.954177897574124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3_Optuna_CatBoost auc 0.908223 trained in 19.74 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble auc 0.935225 trained in 0.83 seconds\n",
      "Skip stack because no parameters were generated.\n",
      "Skip ensemble_stacked because no parameters were generated.\n",
      "AutoML fit time: 469.88 seconds\n",
      "AutoML best model: Ensemble\n",
      "------------------------------------\n",
      "\u001b[1mRunning time:\u001b[0m 7.83 minutes.\n",
      "Start time: 2021-08-13, 17:51:16\n",
      "End time: 2021-08-13, 17:59:06\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "# Creating the AutoML object:\n",
    "model4c = AutoML(mode=\"Optuna\", total_time_limit=2*60, optuna_time_budget=2*60, # Search complexity parameters\n",
    "                 algorithms=[\"CatBoost\", \"LightGBM\", \"Xgboost\"], eval_metric=\"auc\" # Estimation parameters\n",
    "                 )\n",
    "\n",
    "# Running the search:\n",
    "model4c.fit(X_train, y_train)\n",
    "\n",
    "# Total elapsed time:\n",
    "end_time = datetime.now()\n",
    "mljar_time = running_time(start_time=start_time, end_time=end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csp_shmjP87J"
   },
   "source": [
    "Explain mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 88466,
     "status": "ok",
     "timestamp": 1628877927421,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "hP20VkQlPCKG",
    "outputId": "03aad3cf-924c-4e63-f9d7-57eeaedfa7d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: AutoML_11\n",
      "The task is binary_classification with evaluation metric auc\n",
      "AutoML will use algorithms: ['Baseline', 'Linear', 'Decision Tree', 'Random Forest', 'Xgboost', 'Neural Network']\n",
      "AutoML will ensemble availabe models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'ensemble']\n",
      "* Step simple_algorithms will try to check up to 3 models\n",
      "1_Baseline auc 0.5 trained in 2.37 seconds\n",
      "2_DecisionTree auc 0.69377 trained in 8.13 seconds\n",
      "3_Linear auc 0.832653 trained in 7.03 seconds\n",
      "* Step default_algorithms will try to check up to 3 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:104: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_Default_Xgboost auc 0.849194 trained in 11.18 seconds\n",
      "5_Default_NeuralNetwork auc 0.879055 trained in 3.27 seconds\n",
      "6_Default_RandomForest auc 0.841676 trained in 20.97 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble auc 0.888292 trained in 0.8 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning:\n",
      "\n",
      "An input array is constant; the correlation coefficient is not defined.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML fit time: 88.12 seconds\n",
      "AutoML best model: Ensemble\n",
      "------------------------------------\n",
      "\u001b[1mRunning time:\u001b[0m 1.47 minutes.\n",
      "Start time: 2021-08-13, 18:03:54\n",
      "End time: 2021-08-13, 18:05:22\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "# Creating the AutoML object:\n",
    "model4d = AutoML(mode=\"Explain\", total_time_limit=2*60, # Search complexity parameters\n",
    "                 eval_metric='auc' # Estimation metrics\n",
    "                 )\n",
    "\n",
    "# Running the search:\n",
    "model4d.fit(X_train, y_train)\n",
    "\n",
    "# Total elapsed time:\n",
    "end_time = datetime.now()\n",
    "mljar_time = running_time(start_time=start_time, end_time=end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctAvNpq9phNI"
   },
   "source": [
    "#### Assessing the outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2njq4ysQp1rC"
   },
   "source": [
    "ML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1UNbZDkoL6pTLjylPvqsgZrjBZUzXoU5R"
    },
    "executionInfo": {
     "elapsed": 3814,
     "status": "ok",
     "timestamp": 1628879100729,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "AZmK5nasp2y-",
    "outputId": "2d2bc9a0-d11b-4f8c-ff06-fdbce68277ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model4a.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwpMhHHcptM5"
   },
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1318,
     "status": "ok",
     "timestamp": 1628878981014,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "gNpvRAVAuawz",
    "outputId": "c1a48a15-c6bf-41c8-cd7b-469098f5d272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform mode:\n",
      "Test ROC-AUC: 0.9279.\n",
      "\n",
      "Compete mode:\n",
      "Test ROC-AUC: 0.9290.\n",
      "\n",
      "Optuna mode:\n",
      "Test ROC-AUC: 0.9535.\n",
      "\n",
      "Explain mode:\n",
      "Test ROC-AUC: 0.8974.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in [model4a, model4b, model4c, model4d]:\n",
    "  print(f'{m.mode} mode:\\nTest ROC-AUC: {roc_auc_score(y_test, [p[1] for p in m.predict_proba(X_test)]):.4f}.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gq0aeF7mz5TO"
   },
   "source": [
    "<a id='pycaret'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sysFERNtcP5a"
   },
   "source": [
    "### PyCaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YhpcmffR8yyY"
   },
   "outputs": [],
   "source": [
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbvJwHWXjiG9"
   },
   "outputs": [],
   "source": [
    "# Creating a dataframe with training data:\n",
    "df_train = pd.DataFrame(X_train, columns=[f'feat_{i+1}' for i in range(X.shape[1])])\n",
    "df_train['y'] = y_train\n",
    "\n",
    "# Creating a dataframe with test data:\n",
    "df_test = pd.DataFrame(X_test, columns=[f'feat_{i+1}' for i in range(X.shape[1])])\n",
    "df_test['y'] = y_test\n",
    "\n",
    "# Concatenating both training and test data:\n",
    "df = pd.concat([df_train, df_test], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-qizCjaiasK"
   },
   "source": [
    "#### AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "56685960eb3a4d4fa57181d3b34cf699",
      "fbf6fc97e45f48ddafc07ca9211f63bc",
      "78c0868febcf4636aa86509bc4930a0d",
      "fb1e3467b3224c9b8bb39cc5fc83ac03",
      "d3ab5c887cea4890bf9ca9b0a9584624",
      "6c74a71fae484e998c490624737d37f9"
     ]
    },
    "executionInfo": {
     "elapsed": 9609,
     "status": "ok",
     "timestamp": 1628964570558,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "XrTUkOsqiWYN",
    "outputId": "6b39f6c3-205b-42d0-fb48-b8706bfcaefa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>session_id</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Target</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Target Type</td>\n",
       "      <td>Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Label Encoded</td>\n",
       "      <td>0: 0, 1: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Original Data</td>\n",
       "      <td>(670, 51)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Missing Values</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Numeric Features</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Categorical Features</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ordinal Features</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>High Cardinality Features</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>High Cardinality Method</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Transformed Train Set</td>\n",
       "      <td>(670, 50)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Transformed Test Set</td>\n",
       "      <td>(330, 50)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Shuffle Train-Test</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Stratify Train-Test</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fold Generator</td>\n",
       "      <td>StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fold Number</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CPU Jobs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Use GPU</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Log Experiment</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Experiment Name</td>\n",
       "      <td>clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>USI</td>\n",
       "      <td>2859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Imputation Type</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Iterative Imputation Iteration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Numeric Imputer</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Iterative Imputation Numeric Model</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Categorical Imputer</td>\n",
       "      <td>constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Iterative Imputation Categorical Model</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Unknown Categoricals Handling</td>\n",
       "      <td>least_frequent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Normalize</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Normalize Method</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Transformation</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Transformation Method</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>PCA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>PCA Method</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PCA Components</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Ignore Low Variance</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Combine Rare Levels</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Rare Level Threshold</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Numeric Binning</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Remove Outliers</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Outliers Threshold</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Remove Multicollinearity</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Multicollinearity Threshold</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Remove Perfect Collinearity</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Clustering</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Clustering Iteration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Polynomial Features</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Polynomial Degree</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Trignometry Features</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Polynomial Threshold</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Group Features</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Feature Selection</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Feature Selection Method</td>\n",
       "      <td>classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Features Selection Threshold</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Feature Interaction</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Feature Ratio</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Interaction Threshold</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Fix Imbalance</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Fix Imbalance Method</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Description             Value\n",
       "0                               session_id               123\n",
       "1                                   Target                 y\n",
       "2                              Target Type            Binary\n",
       "3                            Label Encoded        0: 0, 1: 1\n",
       "4                            Original Data         (670, 51)\n",
       "5                           Missing Values             False\n",
       "6                         Numeric Features                50\n",
       "7                     Categorical Features                 0\n",
       "8                         Ordinal Features             False\n",
       "9                High Cardinality Features             False\n",
       "10                 High Cardinality Method              None\n",
       "11                   Transformed Train Set         (670, 50)\n",
       "12                    Transformed Test Set         (330, 50)\n",
       "13                      Shuffle Train-Test              True\n",
       "14                     Stratify Train-Test             False\n",
       "15                          Fold Generator   StratifiedKFold\n",
       "16                             Fold Number                10\n",
       "17                                CPU Jobs                -1\n",
       "18                                 Use GPU             False\n",
       "19                          Log Experiment             False\n",
       "20                         Experiment Name  clf-default-name\n",
       "21                                     USI              2859\n",
       "22                         Imputation Type            simple\n",
       "23          Iterative Imputation Iteration              None\n",
       "24                         Numeric Imputer              mean\n",
       "25      Iterative Imputation Numeric Model              None\n",
       "26                     Categorical Imputer          constant\n",
       "27  Iterative Imputation Categorical Model              None\n",
       "28           Unknown Categoricals Handling    least_frequent\n",
       "29                               Normalize             False\n",
       "30                        Normalize Method              None\n",
       "31                          Transformation             False\n",
       "32                   Transformation Method              None\n",
       "33                                     PCA             False\n",
       "34                              PCA Method              None\n",
       "35                          PCA Components              None\n",
       "36                     Ignore Low Variance             False\n",
       "37                     Combine Rare Levels             False\n",
       "38                    Rare Level Threshold              None\n",
       "39                         Numeric Binning             False\n",
       "40                         Remove Outliers             False\n",
       "41                      Outliers Threshold              None\n",
       "42                Remove Multicollinearity             False\n",
       "43             Multicollinearity Threshold              None\n",
       "44             Remove Perfect Collinearity              True\n",
       "45                              Clustering             False\n",
       "46                    Clustering Iteration              None\n",
       "47                     Polynomial Features             False\n",
       "48                       Polynomial Degree              None\n",
       "49                    Trignometry Features             False\n",
       "50                    Polynomial Threshold              None\n",
       "51                          Group Features             False\n",
       "52                       Feature Selection             False\n",
       "53                Feature Selection Method           classic\n",
       "54            Features Selection Threshold              None\n",
       "55                     Feature Interaction             False\n",
       "56                           Feature Ratio             False\n",
       "57                   Interaction Threshold              None\n",
       "58                           Fix Imbalance             False\n",
       "59                    Fix Imbalance Method             SMOTE"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Describing and pre-processing the data:\n",
    "setup = setup(data=df_train, test_data=df_test, target='y', session_id=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483,
     "referenced_widgets": [
      "ddf0f6ee6ad6484a92094951f89da6b6",
      "3396824c000f466d91c83abf92a558eb",
      "98216c6f6f4c4b57b893358512dd2a44"
     ]
    },
    "executionInfo": {
     "elapsed": 51855,
     "status": "ok",
     "timestamp": 1628965120565,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "6aLnRU1mjuHp",
    "outputId": "e6d6b5b7-e7b9-476b-9cd4-48381028a8f7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "      <th>TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>K Neighbors Classifier</td>\n",
       "      <td>0.9030</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.5527</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.6892</td>\n",
       "      <td>0.6392</td>\n",
       "      <td>0.6802</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qda</th>\n",
       "      <td>Quadratic Discriminant Analysis</td>\n",
       "      <td>0.8836</td>\n",
       "      <td>0.9210</td>\n",
       "      <td>0.5242</td>\n",
       "      <td>0.8589</td>\n",
       "      <td>0.6408</td>\n",
       "      <td>0.5783</td>\n",
       "      <td>0.6081</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightgbm</th>\n",
       "      <td>Light Gradient Boosting Machine</td>\n",
       "      <td>0.8791</td>\n",
       "      <td>0.9131</td>\n",
       "      <td>0.4890</td>\n",
       "      <td>0.8753</td>\n",
       "      <td>0.6183</td>\n",
       "      <td>0.5555</td>\n",
       "      <td>0.5925</td>\n",
       "      <td>0.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>Extreme Gradient Boosting</td>\n",
       "      <td>0.8761</td>\n",
       "      <td>0.9007</td>\n",
       "      <td>0.4676</td>\n",
       "      <td>0.8950</td>\n",
       "      <td>0.6010</td>\n",
       "      <td>0.5387</td>\n",
       "      <td>0.5835</td>\n",
       "      <td>1.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbc</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.8612</td>\n",
       "      <td>0.8914</td>\n",
       "      <td>0.4379</td>\n",
       "      <td>0.7868</td>\n",
       "      <td>0.5515</td>\n",
       "      <td>0.4824</td>\n",
       "      <td>0.5141</td>\n",
       "      <td>0.682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lda</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>0.8522</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.4951</td>\n",
       "      <td>0.6978</td>\n",
       "      <td>0.5629</td>\n",
       "      <td>0.4829</td>\n",
       "      <td>0.4986</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.8478</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4011</td>\n",
       "      <td>0.7242</td>\n",
       "      <td>0.5014</td>\n",
       "      <td>0.4270</td>\n",
       "      <td>0.4570</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.8403</td>\n",
       "      <td>0.8631</td>\n",
       "      <td>0.5242</td>\n",
       "      <td>0.6421</td>\n",
       "      <td>0.5637</td>\n",
       "      <td>0.4708</td>\n",
       "      <td>0.4805</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.8358</td>\n",
       "      <td>0.8912</td>\n",
       "      <td>0.2220</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.3449</td>\n",
       "      <td>0.2951</td>\n",
       "      <td>0.3898</td>\n",
       "      <td>0.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.8328</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>0.5170</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>0.5529</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>0.4710</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>Ada Boost Classifier</td>\n",
       "      <td>0.8239</td>\n",
       "      <td>0.7915</td>\n",
       "      <td>0.4670</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.5240</td>\n",
       "      <td>0.4188</td>\n",
       "      <td>0.4288</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>SVM - Linear Kernel</td>\n",
       "      <td>0.8224</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5522</td>\n",
       "      <td>0.5874</td>\n",
       "      <td>0.5573</td>\n",
       "      <td>0.4488</td>\n",
       "      <td>0.4557</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>Extra Trees Classifier</td>\n",
       "      <td>0.8149</td>\n",
       "      <td>0.9132</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.2082</td>\n",
       "      <td>0.1698</td>\n",
       "      <td>0.2728</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.7806</td>\n",
       "      <td>0.6698</td>\n",
       "      <td>0.4808</td>\n",
       "      <td>0.4814</td>\n",
       "      <td>0.4772</td>\n",
       "      <td>0.3391</td>\n",
       "      <td>0.3415</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
       "knn                K Neighbors Classifier    0.9030  0.9281  0.5527  0.9625   \n",
       "qda       Quadratic Discriminant Analysis    0.8836  0.9210  0.5242  0.8589   \n",
       "lightgbm  Light Gradient Boosting Machine    0.8791  0.9131  0.4890  0.8753   \n",
       "xgboost         Extreme Gradient Boosting    0.8761  0.9007  0.4676  0.8950   \n",
       "gbc          Gradient Boosting Classifier    0.8612  0.8914  0.4379  0.7868   \n",
       "lda          Linear Discriminant Analysis    0.8522  0.8562  0.4951  0.6978   \n",
       "ridge                    Ridge Classifier    0.8478  0.0000  0.4011  0.7242   \n",
       "lr                    Logistic Regression    0.8403  0.8631  0.5242  0.6421   \n",
       "rf               Random Forest Classifier    0.8358  0.8912  0.2220  0.9000   \n",
       "nb                            Naive Bayes    0.8328  0.8652  0.5170  0.6435   \n",
       "ada                  Ada Boost Classifier    0.8239  0.7915  0.4670  0.6147   \n",
       "svm                   SVM - Linear Kernel    0.8224  0.0000  0.5522  0.5874   \n",
       "et                 Extra Trees Classifier    0.8149  0.9132  0.1220  0.8500   \n",
       "dt               Decision Tree Classifier    0.7806  0.6698  0.4808  0.4814   \n",
       "\n",
       "              F1   Kappa     MCC  TT (Sec)  \n",
       "knn       0.6892  0.6392  0.6802     0.118  \n",
       "qda       0.6408  0.5783  0.6081     0.016  \n",
       "lightgbm  0.6183  0.5555  0.5925     0.316  \n",
       "xgboost   0.6010  0.5387  0.5835     1.920  \n",
       "gbc       0.5515  0.4824  0.5141     0.682  \n",
       "lda       0.5629  0.4829  0.4986     0.018  \n",
       "ridge     0.5014  0.4270  0.4570     0.012  \n",
       "lr        0.5637  0.4708  0.4805     0.029  \n",
       "rf        0.3449  0.2951  0.3898     0.636  \n",
       "nb        0.5529  0.4561  0.4710     0.014  \n",
       "ada       0.5240  0.4188  0.4288     0.219  \n",
       "svm       0.5573  0.4488  0.4557     0.020  \n",
       "et        0.2082  0.1698  0.2728     0.470  \n",
       "dt        0.4772  0.3391  0.3415     0.035  "
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "# Searching across a collection of different ML algorithms:\n",
    "best_models = compare_models(\n",
    "    budget_time=2, # Search complexity parameters\n",
    "    n_select=5 # Estimation parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421,
     "referenced_widgets": [
      "4a8e6c74114745bb881988ced547cd4c",
      "5bf16a3bfb0d498e8353383b06548936",
      "d2edf90c71644202a5d2c07f5f816f3f"
     ]
    },
    "executionInfo": {
     "elapsed": 4477,
     "status": "ok",
     "timestamp": 1628966443910,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "CipVn70I4vvj",
    "outputId": "d35199bb-c3f1-4588-ed55-3c6c78cf4cb1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8955</td>\n",
       "      <td>0.8551</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6127</td>\n",
       "      <td>0.6646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8657</td>\n",
       "      <td>0.8908</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>0.4678</td>\n",
       "      <td>0.5525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8806</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.6364</td>\n",
       "      <td>0.5712</td>\n",
       "      <td>0.6032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8507</td>\n",
       "      <td>0.8673</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>0.4640</td>\n",
       "      <td>0.4900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9403</td>\n",
       "      <td>0.9811</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.7982</td>\n",
       "      <td>0.8150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9254</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.6429</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7826</td>\n",
       "      <td>0.7401</td>\n",
       "      <td>0.7664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8806</td>\n",
       "      <td>0.9528</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.5427</td>\n",
       "      <td>0.6102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9254</td>\n",
       "      <td>0.9319</td>\n",
       "      <td>0.6429</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7826</td>\n",
       "      <td>0.7401</td>\n",
       "      <td>0.7664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.9589</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>0.9536</td>\n",
       "      <td>0.9547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8806</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>0.3846</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.5788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.9030</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.5527</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.6892</td>\n",
       "      <td>0.6392</td>\n",
       "      <td>0.6802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.1693</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.1377</td>\n",
       "      <td>0.1543</td>\n",
       "      <td>0.1350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "0       0.8955  0.8551  0.5000  1.0000  0.6667  0.6127  0.6646\n",
       "1       0.8657  0.8908  0.3571  1.0000  0.5263  0.4678  0.5525\n",
       "2       0.8806  0.9744  0.5000  0.8750  0.6364  0.5712  0.6032\n",
       "3       0.8507  0.8673  0.4286  0.7500  0.5455  0.4640  0.4900\n",
       "4       0.9403  0.9811  0.7143  1.0000  0.8333  0.7982  0.8150\n",
       "5       0.9254  0.9474  0.6429  1.0000  0.7826  0.7401  0.7664\n",
       "6       0.8806  0.9528  0.4286  1.0000  0.6000  0.5427  0.6102\n",
       "7       0.9254  0.9319  0.6429  1.0000  0.7826  0.7401  0.7664\n",
       "8       0.9851  0.9589  0.9286  1.0000  0.9630  0.9536  0.9547\n",
       "9       0.8806  0.9209  0.3846  1.0000  0.5556  0.5019  0.5788\n",
       "Mean    0.9030  0.9281  0.5527  0.9625  0.6892  0.6392  0.6802\n",
       "SD      0.0385  0.0417  0.1693  0.0800  0.1377  0.1543  0.1350"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training the best model:\n",
    "# model5 = stack_models(estimator_list=best_models) # For training a model stacking.\n",
    "model5 = create_model('knn') # If only one model is expected to be trained.\n",
    "\n",
    "# Total elapsed time:\n",
    "end_time = datetime.now()\n",
    "pycaret_time = running_time(start_time=start_time, end_time=end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421,
     "referenced_widgets": [
      "b56b6df53ae2453a81744f948a72d955",
      "a24fad00bc714937aebf5e332c3a2698",
      "6ef24b5b813445f88178978ab4720dd8"
     ]
    },
    "executionInfo": {
     "elapsed": 7853,
     "status": "ok",
     "timestamp": 1628966454632,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "aT5vZRrWmHq0",
    "outputId": "d5ecadbe-e27f-4c01-b578-2f5fb3df6650"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8955</td>\n",
       "      <td>0.9151</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6127</td>\n",
       "      <td>0.6646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8657</td>\n",
       "      <td>0.9077</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>0.4678</td>\n",
       "      <td>0.5525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8955</td>\n",
       "      <td>0.9677</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6127</td>\n",
       "      <td>0.6646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9104</td>\n",
       "      <td>0.9023</td>\n",
       "      <td>0.6429</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.6973</td>\n",
       "      <td>0.7119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9254</td>\n",
       "      <td>0.9892</td>\n",
       "      <td>0.6429</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.7826</td>\n",
       "      <td>0.7401</td>\n",
       "      <td>0.7664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8955</td>\n",
       "      <td>0.9535</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6127</td>\n",
       "      <td>0.6646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8657</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>0.4678</td>\n",
       "      <td>0.5525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9104</td>\n",
       "      <td>0.9582</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.7273</td>\n",
       "      <td>0.6784</td>\n",
       "      <td>0.7165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9403</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.7982</td>\n",
       "      <td>0.8150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8657</td>\n",
       "      <td>0.9658</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4706</td>\n",
       "      <td>0.4174</td>\n",
       "      <td>0.5136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.8970</td>\n",
       "      <td>0.9528</td>\n",
       "      <td>0.5093</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.6616</td>\n",
       "      <td>0.6105</td>\n",
       "      <td>0.6622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.1299</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.1138</td>\n",
       "      <td>0.1193</td>\n",
       "      <td>0.0926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall  Prec.      F1   Kappa     MCC\n",
       "0       0.8955  0.9151  0.5000   1.00  0.6667  0.6127  0.6646\n",
       "1       0.8657  0.9077  0.3571   1.00  0.5263  0.4678  0.5525\n",
       "2       0.8955  0.9677  0.5000   1.00  0.6667  0.6127  0.6646\n",
       "3       0.9104  0.9023  0.6429   0.90  0.7500  0.6973  0.7119\n",
       "4       0.9254  0.9892  0.6429   1.00  0.7826  0.7401  0.7664\n",
       "5       0.8955  0.9535  0.5000   1.00  0.6667  0.6127  0.6646\n",
       "6       0.8657  0.9744  0.3571   1.00  0.5263  0.4678  0.5525\n",
       "7       0.9104  0.9582  0.5714   1.00  0.7273  0.6784  0.7165\n",
       "8       0.9403  0.9946  0.7143   1.00  0.8333  0.7982  0.8150\n",
       "9       0.8657  0.9658  0.3077   1.00  0.4706  0.4174  0.5136\n",
       "Mean    0.8970  0.9528  0.5093   0.99  0.6616  0.6105  0.6622\n",
       "SD      0.0245  0.0316  0.1299   0.03  0.1138  0.1193  0.0926"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fine tuning hyperparameters:\n",
    "model5 = tune_model(model5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z3lqaNT2nhQo"
   },
   "outputs": [],
   "source": [
    "# Training the final model (including the hold-out data):\n",
    "final_model5 = finalize_model(model5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRQWrQAam1jn"
   },
   "source": [
    "#### Assessing the outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKfheZIum8Cv"
   },
   "source": [
    "ML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1362,
     "status": "ok",
     "timestamp": 1628966501978,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "4FRa6N2UnfLe",
    "outputId": "c1ea04c4-27f3-456f-c2a4-d171d22d5569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=None,\n",
       "          steps=[('dtypes',\n",
       "                  DataTypes_Auto_infer(categorical_features=[],\n",
       "                                       display_types=True, features_todrop=[],\n",
       "                                       id_columns=[],\n",
       "                                       ml_usecase='classification',\n",
       "                                       numerical_features=[], target='y',\n",
       "                                       time_features=[])),\n",
       "                 ('imputer',\n",
       "                  Simple_Imputer(categorical_strategy='not_available',\n",
       "                                 fill_value_categorical=None,\n",
       "                                 fill_value_numerical=None,\n",
       "                                 numeric_strategy='...\n",
       "                 ('fix_perfect', Remove_100(target='y')),\n",
       "                 ('clean_names', Clean_Colum_Names()),\n",
       "                 ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),\n",
       "                 ('dfs', 'passthrough'), ('pca', 'passthrough'),\n",
       "                 ['trained_model',\n",
       "                  KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                       metric='minkowski', metric_params=None,\n",
       "                                       n_jobs=-1, n_neighbors=9, p=2,\n",
       "                                       weights='distance')]],\n",
       "          verbose=False), 'ML_pipeline.pkl')"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving and presenting the selected ML pipeline:\n",
    "save_model(final_model5, 'ML_pipeline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTo_NB7mnBCM"
   },
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376,
     "referenced_widgets": [
      "a4ecb9c223994b00b8d45631dcb8f417",
      "ab5fc125b0ad46888a848b3d7b763de5",
      "86ce0edfdaf6479084ca3c93d5633395"
     ]
    },
    "executionInfo": {
     "elapsed": 1221,
     "status": "ok",
     "timestamp": 1628966665698,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "cfEzcCHKmLe1",
    "outputId": "85e38611-a30c-4f19-fb6d-6d89d72862d8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the model evaluation on test data:\n",
    "plot_model(model5, plot='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "executionInfo": {
     "elapsed": 993,
     "status": "ok",
     "timestamp": 1628966671135,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "BlnIHPmQnFWl",
    "outputId": "63d5da68-514d-43c8-bff4-5092ceea64e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K Neighbors Classifier</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.9808</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>0.6596</td>\n",
       "      <td>0.6096</td>\n",
       "      <td>0.6551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy     AUC  ...      F1   Kappa     MCC\n",
       "0  K Neighbors Classifier     0.903  0.9808  ...  0.6596  0.6096  0.6551\n",
       "\n",
       "[1 rows x 8 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>feat_11</th>\n",
       "      <th>feat_12</th>\n",
       "      <th>feat_13</th>\n",
       "      <th>feat_14</th>\n",
       "      <th>feat_15</th>\n",
       "      <th>feat_16</th>\n",
       "      <th>feat_17</th>\n",
       "      <th>feat_18</th>\n",
       "      <th>feat_19</th>\n",
       "      <th>feat_20</th>\n",
       "      <th>feat_21</th>\n",
       "      <th>feat_22</th>\n",
       "      <th>feat_23</th>\n",
       "      <th>feat_24</th>\n",
       "      <th>feat_25</th>\n",
       "      <th>feat_26</th>\n",
       "      <th>feat_27</th>\n",
       "      <th>feat_28</th>\n",
       "      <th>feat_29</th>\n",
       "      <th>feat_30</th>\n",
       "      <th>feat_31</th>\n",
       "      <th>feat_32</th>\n",
       "      <th>feat_33</th>\n",
       "      <th>feat_34</th>\n",
       "      <th>feat_35</th>\n",
       "      <th>feat_36</th>\n",
       "      <th>feat_37</th>\n",
       "      <th>feat_38</th>\n",
       "      <th>feat_39</th>\n",
       "      <th>feat_40</th>\n",
       "      <th>feat_41</th>\n",
       "      <th>feat_42</th>\n",
       "      <th>feat_43</th>\n",
       "      <th>feat_44</th>\n",
       "      <th>feat_45</th>\n",
       "      <th>feat_46</th>\n",
       "      <th>feat_47</th>\n",
       "      <th>feat_48</th>\n",
       "      <th>feat_49</th>\n",
       "      <th>feat_50</th>\n",
       "      <th>y</th>\n",
       "      <th>Label</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.380290</td>\n",
       "      <td>0.213745</td>\n",
       "      <td>-9.505847</td>\n",
       "      <td>2.122735</td>\n",
       "      <td>-1.042708</td>\n",
       "      <td>0.322209</td>\n",
       "      <td>1.831327</td>\n",
       "      <td>-1.157639</td>\n",
       "      <td>1.202228</td>\n",
       "      <td>-0.075633</td>\n",
       "      <td>-4.938150</td>\n",
       "      <td>1.258512</td>\n",
       "      <td>-0.589892</td>\n",
       "      <td>-5.706656</td>\n",
       "      <td>-0.713745</td>\n",
       "      <td>1.820787</td>\n",
       "      <td>0.508783</td>\n",
       "      <td>1.153366</td>\n",
       "      <td>-0.387771</td>\n",
       "      <td>-1.262240</td>\n",
       "      <td>-1.005049</td>\n",
       "      <td>-0.027546</td>\n",
       "      <td>5.316667</td>\n",
       "      <td>2.400906</td>\n",
       "      <td>0.181192</td>\n",
       "      <td>-1.690562</td>\n",
       "      <td>-5.184087</td>\n",
       "      <td>2.837069</td>\n",
       "      <td>-2.675719</td>\n",
       "      <td>-0.849684</td>\n",
       "      <td>1.043973</td>\n",
       "      <td>0.163270</td>\n",
       "      <td>1.870893</td>\n",
       "      <td>-1.636382</td>\n",
       "      <td>-1.528038</td>\n",
       "      <td>-0.673189</td>\n",
       "      <td>-4.842166</td>\n",
       "      <td>3.480405</td>\n",
       "      <td>-1.720307</td>\n",
       "      <td>2.038251</td>\n",
       "      <td>0.888897</td>\n",
       "      <td>0.498252</td>\n",
       "      <td>-0.539198</td>\n",
       "      <td>-0.203556</td>\n",
       "      <td>-0.084834</td>\n",
       "      <td>6.907939</td>\n",
       "      <td>1.209549</td>\n",
       "      <td>0.908968</td>\n",
       "      <td>-0.451763</td>\n",
       "      <td>-0.958133</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.270285</td>\n",
       "      <td>-0.555652</td>\n",
       "      <td>-6.148746</td>\n",
       "      <td>-0.353340</td>\n",
       "      <td>1.136440</td>\n",
       "      <td>0.505821</td>\n",
       "      <td>-0.488214</td>\n",
       "      <td>-1.147030</td>\n",
       "      <td>-0.929316</td>\n",
       "      <td>-0.383940</td>\n",
       "      <td>-3.027857</td>\n",
       "      <td>0.731455</td>\n",
       "      <td>-0.364095</td>\n",
       "      <td>-0.091905</td>\n",
       "      <td>-1.253906</td>\n",
       "      <td>0.222838</td>\n",
       "      <td>-0.161734</td>\n",
       "      <td>-0.274312</td>\n",
       "      <td>-0.775829</td>\n",
       "      <td>-0.592615</td>\n",
       "      <td>-1.079373</td>\n",
       "      <td>1.357608</td>\n",
       "      <td>0.994147</td>\n",
       "      <td>-0.465819</td>\n",
       "      <td>-1.595467</td>\n",
       "      <td>0.063064</td>\n",
       "      <td>1.321019</td>\n",
       "      <td>-0.019779</td>\n",
       "      <td>-0.027984</td>\n",
       "      <td>-0.063238</td>\n",
       "      <td>-0.741417</td>\n",
       "      <td>-0.635407</td>\n",
       "      <td>0.192465</td>\n",
       "      <td>-0.490168</td>\n",
       "      <td>-0.562547</td>\n",
       "      <td>-0.177801</td>\n",
       "      <td>-0.597065</td>\n",
       "      <td>-1.258879</td>\n",
       "      <td>-1.824665</td>\n",
       "      <td>1.662766</td>\n",
       "      <td>-3.140311</td>\n",
       "      <td>1.012426</td>\n",
       "      <td>3.021468</td>\n",
       "      <td>-1.152343</td>\n",
       "      <td>1.204406</td>\n",
       "      <td>-0.742105</td>\n",
       "      <td>-0.645620</td>\n",
       "      <td>-0.106996</td>\n",
       "      <td>3.495588</td>\n",
       "      <td>0.078815</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.285024</td>\n",
       "      <td>-0.405893</td>\n",
       "      <td>-12.307508</td>\n",
       "      <td>-2.088221</td>\n",
       "      <td>-0.669185</td>\n",
       "      <td>-1.664515</td>\n",
       "      <td>0.825946</td>\n",
       "      <td>-1.069601</td>\n",
       "      <td>0.622722</td>\n",
       "      <td>-0.368631</td>\n",
       "      <td>-0.897684</td>\n",
       "      <td>0.381207</td>\n",
       "      <td>-1.146404</td>\n",
       "      <td>2.303180</td>\n",
       "      <td>0.349426</td>\n",
       "      <td>-5.250026</td>\n",
       "      <td>0.398961</td>\n",
       "      <td>-0.708565</td>\n",
       "      <td>-0.397713</td>\n",
       "      <td>0.884871</td>\n",
       "      <td>4.172642</td>\n",
       "      <td>0.508798</td>\n",
       "      <td>1.871817</td>\n",
       "      <td>-0.877581</td>\n",
       "      <td>-1.720001</td>\n",
       "      <td>0.616470</td>\n",
       "      <td>-4.692108</td>\n",
       "      <td>-1.922057</td>\n",
       "      <td>-5.401732</td>\n",
       "      <td>-0.521882</td>\n",
       "      <td>0.823851</td>\n",
       "      <td>-0.123907</td>\n",
       "      <td>-3.089183</td>\n",
       "      <td>-4.159323</td>\n",
       "      <td>1.431444</td>\n",
       "      <td>-0.136700</td>\n",
       "      <td>-0.288447</td>\n",
       "      <td>3.165990</td>\n",
       "      <td>-3.165029</td>\n",
       "      <td>0.877105</td>\n",
       "      <td>-2.869649</td>\n",
       "      <td>-0.842497</td>\n",
       "      <td>-3.250650</td>\n",
       "      <td>-0.437531</td>\n",
       "      <td>0.666608</td>\n",
       "      <td>3.620124</td>\n",
       "      <td>0.294584</td>\n",
       "      <td>-0.120705</td>\n",
       "      <td>0.164219</td>\n",
       "      <td>-0.199294</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.270900</td>\n",
       "      <td>-0.484589</td>\n",
       "      <td>3.039466</td>\n",
       "      <td>0.691496</td>\n",
       "      <td>0.999677</td>\n",
       "      <td>0.756989</td>\n",
       "      <td>0.805805</td>\n",
       "      <td>2.280787</td>\n",
       "      <td>-0.446359</td>\n",
       "      <td>-0.209551</td>\n",
       "      <td>1.423794</td>\n",
       "      <td>0.576930</td>\n",
       "      <td>-0.072499</td>\n",
       "      <td>-3.946236</td>\n",
       "      <td>1.911024</td>\n",
       "      <td>-2.911615</td>\n",
       "      <td>-0.627855</td>\n",
       "      <td>0.060474</td>\n",
       "      <td>0.380624</td>\n",
       "      <td>-0.394970</td>\n",
       "      <td>4.186686</td>\n",
       "      <td>2.142110</td>\n",
       "      <td>1.263637</td>\n",
       "      <td>-1.058491</td>\n",
       "      <td>-2.310400</td>\n",
       "      <td>1.024868</td>\n",
       "      <td>1.345330</td>\n",
       "      <td>3.158161</td>\n",
       "      <td>-5.225286</td>\n",
       "      <td>-0.140216</td>\n",
       "      <td>0.941779</td>\n",
       "      <td>-0.611091</td>\n",
       "      <td>-0.423179</td>\n",
       "      <td>7.411006</td>\n",
       "      <td>-0.215364</td>\n",
       "      <td>-1.628074</td>\n",
       "      <td>-5.177483</td>\n",
       "      <td>2.215448</td>\n",
       "      <td>-3.126388</td>\n",
       "      <td>1.421848</td>\n",
       "      <td>-16.127605</td>\n",
       "      <td>-0.731870</td>\n",
       "      <td>1.892064</td>\n",
       "      <td>-0.545574</td>\n",
       "      <td>-0.147459</td>\n",
       "      <td>-4.855564</td>\n",
       "      <td>1.877338</td>\n",
       "      <td>-0.608890</td>\n",
       "      <td>3.002701</td>\n",
       "      <td>1.427930</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.339525</td>\n",
       "      <td>-0.630327</td>\n",
       "      <td>5.608542</td>\n",
       "      <td>-2.071267</td>\n",
       "      <td>-0.515902</td>\n",
       "      <td>-1.195632</td>\n",
       "      <td>-0.658256</td>\n",
       "      <td>-2.363575</td>\n",
       "      <td>-0.132016</td>\n",
       "      <td>-0.316895</td>\n",
       "      <td>-0.912888</td>\n",
       "      <td>-1.598590</td>\n",
       "      <td>-0.181239</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>2.241705</td>\n",
       "      <td>-2.225162</td>\n",
       "      <td>2.420235</td>\n",
       "      <td>1.569808</td>\n",
       "      <td>-0.903580</td>\n",
       "      <td>0.425026</td>\n",
       "      <td>-5.640684</td>\n",
       "      <td>1.306243</td>\n",
       "      <td>3.330173</td>\n",
       "      <td>-5.248729</td>\n",
       "      <td>2.934073</td>\n",
       "      <td>0.484684</td>\n",
       "      <td>1.949750</td>\n",
       "      <td>1.252337</td>\n",
       "      <td>1.577172</td>\n",
       "      <td>0.524432</td>\n",
       "      <td>0.189251</td>\n",
       "      <td>-0.456670</td>\n",
       "      <td>0.887139</td>\n",
       "      <td>1.850475</td>\n",
       "      <td>-0.638268</td>\n",
       "      <td>1.514134</td>\n",
       "      <td>2.674031</td>\n",
       "      <td>1.941562</td>\n",
       "      <td>5.187185</td>\n",
       "      <td>-1.007152</td>\n",
       "      <td>12.640871</td>\n",
       "      <td>1.399762</td>\n",
       "      <td>-2.366852</td>\n",
       "      <td>-0.172350</td>\n",
       "      <td>-0.752125</td>\n",
       "      <td>-3.644310</td>\n",
       "      <td>1.058802</td>\n",
       "      <td>-1.252482</td>\n",
       "      <td>2.244712</td>\n",
       "      <td>-0.657245</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>2.852523</td>\n",
       "      <td>-1.484606</td>\n",
       "      <td>3.566598</td>\n",
       "      <td>-0.778894</td>\n",
       "      <td>-1.567678</td>\n",
       "      <td>0.196810</td>\n",
       "      <td>-0.145717</td>\n",
       "      <td>-0.874744</td>\n",
       "      <td>-1.881989</td>\n",
       "      <td>0.879343</td>\n",
       "      <td>1.391844</td>\n",
       "      <td>0.911093</td>\n",
       "      <td>0.074456</td>\n",
       "      <td>0.083665</td>\n",
       "      <td>-0.411648</td>\n",
       "      <td>0.139309</td>\n",
       "      <td>-0.131840</td>\n",
       "      <td>-0.170346</td>\n",
       "      <td>0.275634</td>\n",
       "      <td>0.863156</td>\n",
       "      <td>-0.813451</td>\n",
       "      <td>2.003062</td>\n",
       "      <td>1.632391</td>\n",
       "      <td>0.460052</td>\n",
       "      <td>-1.993912</td>\n",
       "      <td>-0.348978</td>\n",
       "      <td>-0.654426</td>\n",
       "      <td>3.557042</td>\n",
       "      <td>-0.877634</td>\n",
       "      <td>1.727209</td>\n",
       "      <td>0.590334</td>\n",
       "      <td>0.114764</td>\n",
       "      <td>1.505226</td>\n",
       "      <td>-1.230940</td>\n",
       "      <td>-1.489889</td>\n",
       "      <td>-0.744747</td>\n",
       "      <td>-6.876840</td>\n",
       "      <td>-2.540174</td>\n",
       "      <td>3.392121</td>\n",
       "      <td>3.184397</td>\n",
       "      <td>-4.362971</td>\n",
       "      <td>0.051928</td>\n",
       "      <td>-2.624253</td>\n",
       "      <td>-1.696794</td>\n",
       "      <td>0.463059</td>\n",
       "      <td>-0.778493</td>\n",
       "      <td>-0.080581</td>\n",
       "      <td>1.986588</td>\n",
       "      <td>0.685494</td>\n",
       "      <td>-0.687032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>3.787459</td>\n",
       "      <td>1.195321</td>\n",
       "      <td>1.894811</td>\n",
       "      <td>-0.785813</td>\n",
       "      <td>-0.200243</td>\n",
       "      <td>-1.131469</td>\n",
       "      <td>-0.509460</td>\n",
       "      <td>1.498220</td>\n",
       "      <td>0.120043</td>\n",
       "      <td>0.531977</td>\n",
       "      <td>5.577908</td>\n",
       "      <td>-0.481344</td>\n",
       "      <td>0.743656</td>\n",
       "      <td>3.989586</td>\n",
       "      <td>-0.728171</td>\n",
       "      <td>3.221226</td>\n",
       "      <td>-0.235332</td>\n",
       "      <td>-0.941600</td>\n",
       "      <td>1.012800</td>\n",
       "      <td>-0.668517</td>\n",
       "      <td>-2.110015</td>\n",
       "      <td>-0.359471</td>\n",
       "      <td>0.660834</td>\n",
       "      <td>-1.003479</td>\n",
       "      <td>-0.185759</td>\n",
       "      <td>1.315244</td>\n",
       "      <td>0.485466</td>\n",
       "      <td>2.612069</td>\n",
       "      <td>3.765413</td>\n",
       "      <td>-0.740290</td>\n",
       "      <td>-1.515944</td>\n",
       "      <td>-1.510934</td>\n",
       "      <td>8.030663</td>\n",
       "      <td>-0.416719</td>\n",
       "      <td>-0.397987</td>\n",
       "      <td>1.498830</td>\n",
       "      <td>0.086496</td>\n",
       "      <td>3.071477</td>\n",
       "      <td>5.570899</td>\n",
       "      <td>6.055131</td>\n",
       "      <td>10.718780</td>\n",
       "      <td>-0.689077</td>\n",
       "      <td>0.997857</td>\n",
       "      <td>0.107303</td>\n",
       "      <td>3.342051</td>\n",
       "      <td>0.310167</td>\n",
       "      <td>-1.474025</td>\n",
       "      <td>-2.624177</td>\n",
       "      <td>3.201933</td>\n",
       "      <td>0.180944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>5.426734</td>\n",
       "      <td>-0.387396</td>\n",
       "      <td>5.575695</td>\n",
       "      <td>-0.282743</td>\n",
       "      <td>1.538898</td>\n",
       "      <td>0.788893</td>\n",
       "      <td>-0.795995</td>\n",
       "      <td>0.222434</td>\n",
       "      <td>-0.069472</td>\n",
       "      <td>-1.382642</td>\n",
       "      <td>5.577200</td>\n",
       "      <td>-2.011959</td>\n",
       "      <td>0.886258</td>\n",
       "      <td>-5.463463</td>\n",
       "      <td>-0.131143</td>\n",
       "      <td>-1.426666</td>\n",
       "      <td>1.291590</td>\n",
       "      <td>2.215984</td>\n",
       "      <td>-1.090136</td>\n",
       "      <td>0.154016</td>\n",
       "      <td>-1.369384</td>\n",
       "      <td>1.443138</td>\n",
       "      <td>5.342295</td>\n",
       "      <td>-5.955364</td>\n",
       "      <td>-2.049592</td>\n",
       "      <td>1.373562</td>\n",
       "      <td>-4.320312</td>\n",
       "      <td>-1.934764</td>\n",
       "      <td>-2.449403</td>\n",
       "      <td>0.898841</td>\n",
       "      <td>-0.308261</td>\n",
       "      <td>-0.716763</td>\n",
       "      <td>-0.283791</td>\n",
       "      <td>3.549912</td>\n",
       "      <td>0.909488</td>\n",
       "      <td>5.711638</td>\n",
       "      <td>-0.724319</td>\n",
       "      <td>0.385456</td>\n",
       "      <td>3.398767</td>\n",
       "      <td>2.037808</td>\n",
       "      <td>15.346337</td>\n",
       "      <td>1.175828</td>\n",
       "      <td>-3.189634</td>\n",
       "      <td>0.732441</td>\n",
       "      <td>0.506175</td>\n",
       "      <td>-3.221834</td>\n",
       "      <td>-0.050399</td>\n",
       "      <td>-0.861953</td>\n",
       "      <td>2.534723</td>\n",
       "      <td>-0.701800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1.853199</td>\n",
       "      <td>1.502160</td>\n",
       "      <td>-9.888805</td>\n",
       "      <td>0.532252</td>\n",
       "      <td>-0.536861</td>\n",
       "      <td>0.629124</td>\n",
       "      <td>-1.039366</td>\n",
       "      <td>-1.233141</td>\n",
       "      <td>-0.549257</td>\n",
       "      <td>0.245284</td>\n",
       "      <td>-3.443524</td>\n",
       "      <td>-1.169201</td>\n",
       "      <td>0.889148</td>\n",
       "      <td>-2.366264</td>\n",
       "      <td>0.799727</td>\n",
       "      <td>-2.687201</td>\n",
       "      <td>-0.086449</td>\n",
       "      <td>0.820164</td>\n",
       "      <td>1.615644</td>\n",
       "      <td>-1.072984</td>\n",
       "      <td>2.045970</td>\n",
       "      <td>-0.685519</td>\n",
       "      <td>-1.096184</td>\n",
       "      <td>4.322662</td>\n",
       "      <td>-1.944020</td>\n",
       "      <td>0.120266</td>\n",
       "      <td>-0.621290</td>\n",
       "      <td>-2.498353</td>\n",
       "      <td>-0.817944</td>\n",
       "      <td>0.289723</td>\n",
       "      <td>0.602294</td>\n",
       "      <td>-1.201563</td>\n",
       "      <td>0.705180</td>\n",
       "      <td>0.390254</td>\n",
       "      <td>-0.689462</td>\n",
       "      <td>1.486693</td>\n",
       "      <td>0.179581</td>\n",
       "      <td>-3.937164</td>\n",
       "      <td>-4.058079</td>\n",
       "      <td>-0.952364</td>\n",
       "      <td>0.371099</td>\n",
       "      <td>-1.651282</td>\n",
       "      <td>-0.679676</td>\n",
       "      <td>1.185845</td>\n",
       "      <td>-0.233695</td>\n",
       "      <td>2.231892</td>\n",
       "      <td>-0.060917</td>\n",
       "      <td>-0.293551</td>\n",
       "      <td>-0.509820</td>\n",
       "      <td>-0.478678</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>-5.601229</td>\n",
       "      <td>0.956900</td>\n",
       "      <td>8.224011</td>\n",
       "      <td>0.064406</td>\n",
       "      <td>0.126972</td>\n",
       "      <td>-1.098581</td>\n",
       "      <td>0.663317</td>\n",
       "      <td>0.784655</td>\n",
       "      <td>0.042769</td>\n",
       "      <td>1.460944</td>\n",
       "      <td>-1.291432</td>\n",
       "      <td>0.810610</td>\n",
       "      <td>0.650180</td>\n",
       "      <td>2.029318</td>\n",
       "      <td>0.249493</td>\n",
       "      <td>-2.784294</td>\n",
       "      <td>1.231130</td>\n",
       "      <td>2.291004</td>\n",
       "      <td>-1.425812</td>\n",
       "      <td>-1.764947</td>\n",
       "      <td>3.056001</td>\n",
       "      <td>-1.092207</td>\n",
       "      <td>-4.023193</td>\n",
       "      <td>2.312960</td>\n",
       "      <td>-1.138817</td>\n",
       "      <td>1.417332</td>\n",
       "      <td>8.102072</td>\n",
       "      <td>4.864938</td>\n",
       "      <td>-0.873979</td>\n",
       "      <td>0.552495</td>\n",
       "      <td>-1.403786</td>\n",
       "      <td>0.325914</td>\n",
       "      <td>-1.530880</td>\n",
       "      <td>1.564970</td>\n",
       "      <td>-0.435188</td>\n",
       "      <td>-2.563419</td>\n",
       "      <td>-7.492729</td>\n",
       "      <td>6.641538</td>\n",
       "      <td>-4.028310</td>\n",
       "      <td>-3.786784</td>\n",
       "      <td>-23.346018</td>\n",
       "      <td>-0.181172</td>\n",
       "      <td>-2.200317</td>\n",
       "      <td>1.324294</td>\n",
       "      <td>0.216635</td>\n",
       "      <td>0.886473</td>\n",
       "      <td>0.569916</td>\n",
       "      <td>0.350651</td>\n",
       "      <td>-2.951883</td>\n",
       "      <td>0.704342</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feat_1    feat_2     feat_3    feat_4  ...   feat_50  y  Label   Score\n",
       "0   -2.380290  0.213745  -9.505847  2.122735  ... -0.958133  1      1  0.8894\n",
       "1   -1.270285 -0.555652  -6.148746 -0.353340  ...  0.078815  0      0  0.7521\n",
       "2    3.285024 -0.405893 -12.307508 -2.088221  ... -0.199294  1      0  0.5532\n",
       "3    1.270900 -0.484589   3.039466  0.691496  ...  1.427930  0      0  1.0000\n",
       "4   -1.339525 -0.630327   5.608542 -2.071267  ... -0.657245  1      0  0.6477\n",
       "..        ...       ...        ...       ...  ...       ... ..    ...     ...\n",
       "325  2.852523 -1.484606   3.566598 -0.778894  ... -0.687032  0      0  1.0000\n",
       "326  3.787459  1.195321   1.894811 -0.785813  ...  0.180944  0      0  1.0000\n",
       "327  5.426734 -0.387396   5.575695 -0.282743  ... -0.701800  0      0  1.0000\n",
       "328  1.853199  1.502160  -9.888805  0.532252  ... -0.478678  0      0  1.0000\n",
       "329 -5.601229  0.956900   8.224011  0.064406  ...  0.704342  0      0  1.0000\n",
       "\n",
       "[330 rows x 53 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions on test data:\n",
    "predict_model(model5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SNWvN2Mz5TT"
   },
   "source": [
    "<a id='autokeras'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PU3l1xhqnO80"
   },
   "source": [
    "### AutoKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zt-C9nKn_KZb"
   },
   "outputs": [],
   "source": [
    "from autokeras import StructuredDataClassifier\n",
    "# from keras_tuner import Objective\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z08VP_SSnQ2n"
   },
   "source": [
    "#### AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19439,
     "status": "ok",
     "timestamp": 1629055558298,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "1jpIF3-a_-gw",
    "outputId": "e1c60ada-82aa-41be-cd74-6a144be0aa00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 04s]\n",
      "val_accuracy: 0.7947368621826172\n",
      "\n",
      "Best val_accuracy So Far: 0.7947368621826172\n",
      "Total elapsed time: 00h 00m 12s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/10\n",
      "21/21 [==============================] - 1s 2ms/step - loss: 0.5838 - accuracy: 0.7254\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7925\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7955\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8090\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8418\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3080 - accuracy: 0.8776\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2674 - accuracy: 0.8985\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2310 - accuracy: 0.9179\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1994 - accuracy: 0.9388\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1715 - accuracy: 0.9418\n",
      "INFO:tensorflow:Assets written to: ./structured_data_classifier/best_model/assets\n",
      "------------------------------------\n",
      "\u001b[1mRunning time:\u001b[0m 0.32 minutes.\n",
      "Start time: 2021-08-15, 19:25:32\n",
      "End time: 2021-08-15, 19:25:51\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "# Creating the AutoML object:\n",
    "model6 = StructuredDataClassifier(max_trials=3, # Search complexity parameters\n",
    "                                  overwrite=True # Outputs management parameters\n",
    "                                  )\n",
    "# model6 = StructuredDataClassifier(max_trials=3, # Search complexity parameters\n",
    "#                                   metrics=[roc_auc], objective=Objective('val_roc_auc', direction='max'), # Estimation parameters\n",
    "#                                   overwrite=True # Outputs management parameters\n",
    "#                                   )\n",
    "\n",
    "# Running the search:\n",
    "model6.fit(x=X_train, y=y_train, epochs=10, validation_split=0.3)\n",
    "\n",
    "# Total elapsed time:\n",
    "end_time = datetime.now()\n",
    "autokeras_time = running_time(start_time=start_time, end_time=end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q68mSGTjnUnW"
   },
   "source": [
    "#### Assessing the outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkUdAgeMnYW3"
   },
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2492,
     "status": "ok",
     "timestamp": 1629055717120,
     "user": {
      "displayName": "Matheus Rosso",
      "photoUrl": "",
      "userId": "07497572953789637511"
     },
     "user_tz": 180
    },
    "id": "sRdNtHvlnXmX",
    "outputId": "798f5854-121e-4750-c1c7-d350ce21f5ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step\n",
      "Test ROC-AUC: 0.7375.\n",
      "\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3006 - accuracy: 0.8758\n",
      "val_accuracy: [0.30056077241897583, 0.8757575750350952].\n"
     ]
    }
   ],
   "source": [
    "print(f'Test ROC-AUC: {roc_auc_score(y_test, model6.predict(X_test)):.4f}.\\n')\n",
    "print(f'{model6.objective.name}: {model6.evaluate(X_test, y_test)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9tKfDYLz5Tg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "N35WcM6pXFtj"
   ],
   "name": "AutoML - Tutorials.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0e84817599224e368ac57f58841fe231": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_62958e68fe6d4be88db9df858628e7a7",
       "IPY_MODEL_53f0a06f36f24c62ba66a1075b02bde8"
      ],
      "layout": "IPY_MODEL_32736d014182465ab2c7f54e95ae5020"
     }
    },
    "180feac02c5d48399ae9fb2339fc6d05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "32736d014182465ab2c7f54e95ae5020": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3396824c000f466d91c83abf92a558eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3ba789c85c85469ebacb7c3939b71a0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4a8e6c74114745bb881988ced547cd4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Processing: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d2edf90c71644202a5d2c07f5f816f3f",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5bf16a3bfb0d498e8353383b06548936",
      "value": 4
     }
    },
    "53f0a06f36f24c62ba66a1075b02bde8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a836b54fe0d7439d8027cd9bdec7bc31",
      "placeholder": "​",
      "style": "IPY_MODEL_180feac02c5d48399ae9fb2339fc6d05",
      "value": " 300/300 [33:43&lt;00:00,  2.62s/pipeline]"
     }
    },
    "56685960eb3a4d4fa57181d3b34cf699": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Processing: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_78c0868febcf4636aa86509bc4930a0d",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fbf6fc97e45f48ddafc07ca9211f63bc",
      "value": 3
     }
    },
    "5bf16a3bfb0d498e8353383b06548936": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "62958e68fe6d4be88db9df858628e7a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Optimization Progress: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e303117ca8c643b39d0335c42571e466",
      "max": 300,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3ba789c85c85469ebacb7c3939b71a0c",
      "value": 300
     }
    },
    "6c74a71fae484e998c490624737d37f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "6ef24b5b813445f88178978ab4720dd8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78c0868febcf4636aa86509bc4930a0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86ce0edfdaf6479084ca3c93d5633395": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98216c6f6f4c4b57b893358512dd2a44": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a24fad00bc714937aebf5e332c3a2698": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a4ecb9c223994b00b8d45631dcb8f417": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Processing: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86ce0edfdaf6479084ca3c93d5633395",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ab5fc125b0ad46888a848b3d7b763de5",
      "value": 5
     }
    },
    "a836b54fe0d7439d8027cd9bdec7bc31": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab5fc125b0ad46888a848b3d7b763de5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b56b6df53ae2453a81744f948a72d955": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Processing: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ef24b5b813445f88178978ab4720dd8",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a24fad00bc714937aebf5e332c3a2698",
      "value": 7
     }
    },
    "d2edf90c71644202a5d2c07f5f816f3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3ab5c887cea4890bf9ca9b0a9584624": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ddf0f6ee6ad6484a92094951f89da6b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Processing: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98216c6f6f4c4b57b893358512dd2a44",
      "max": 74,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3396824c000f466d91c83abf92a558eb",
      "value": 74
     }
    },
    "e303117ca8c643b39d0335c42571e466": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb1e3467b3224c9b8bb39cc5fc83ac03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_6c74a71fae484e998c490624737d37f9",
      "placeholder": "​",
      "style": "IPY_MODEL_d3ab5c887cea4890bf9ca9b0a9584624",
      "value": "Following data types have been inferred automatically, if they are correct press enter to continue or type 'quit' otherwise."
     }
    },
    "fbf6fc97e45f48ddafc07ca9211f63bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
